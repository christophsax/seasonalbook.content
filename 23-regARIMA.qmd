# regARIMA Model {#sec-regarima}

```{r}
#| results: "asis"
#| echo: false
source("_common.R")
status("polishing", "2023-11-20", section = "regARIMA Model")  # drafting, polishing, complete
```


<!--

Style Guide ?

X-13
X-13ARIMA-SEATS
Titles in sentence style





 -->

An ARIMA model with external regressors (regARIMA) lies at the heart of many of the procedures in X-13. As we have seen in chapter FIXME, regARIMA consists of several interacting specs. Some of the these specs will be further detailed in later chapters (Outlier, Trading Days).

Like most statistical modeling in X-13, the process to find the best model is iterative. Analysts use statistical tools and their expertise to fine-tune the regARIMA model. This iterative process is visualized in the flow chart below.

```{mermaid}
%%| label: fig-arima-interact
%%| fig-cap: "Interaction between regARIMA, diagnostics and seasonal adjustment"

flowchart TD
  A[RegARIMA Modeling] --> B(Model Comparison / Diagnostics)
  B --> A
  A --> C[Seasonal Adjustment]
  C --> D[Seasonal Adjustment Diagnostics]
  D --> C
  D --> A
```

Once a satisfiying regARIMA has been found, one proceeds to the seasonal adjustment step. The regARIMA model is crucial in forecasting the time series for applying symmetric filters and extracting components, whether using SEATS or X-11 for seasonal adjustment. In addition, in SEATS, the ARIMA model is also used to derive trend, seasonal, and irregular components.

The regARIMA model also includes exogenous information or regressors, like holiday effects, additive outliers, and level shifts. These elements help in forecasting and analyzing the series. For example, regARIMA modeling can answer if a series is affected by trading day effects or how outliers impact results. It's also used to integrate external regression variables such as moving holidays and trading day effects into the analysis.


## ARIMA Basics

The regARIMA model combines two elements: **reg**ression and **ARIMA**. The ARIMA segment itself is composed of a differencing order (the "I", for "integrated") and the ARMA part. This chapter aims to simplify these concepts without getting too technical, providing enough understanding for effective seasonal adjustment.

ARIMA stands for Autoregressive Integrated Moving Average. "Autoregressive" (AR) means the model uses past values of the series to predict the current value. For instance, an AR(1) model uses one lagged value:

$$ Y_t = \phi Y_{t-1} + a_t $$

Here, $Y_t$ is the time series, $\phi$ a coefficient, and $\{a_t\}$ an uncorrelated sequence of errors.[^ar_p]

[^ar_p]: An AR(p) model extends this to $p$ lagged values:

    $$ Y_t = \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \cdots + \phi_p Y_{t-p} + a_t $$

    where now we have $p$ coefficients $\phi_1, \phi_2, \ldots, \phi_p$ to be estimated.

The "Moving Average" (MA) part uses past errors of the series for prediction. An MA(1) model looks like:

$$ Y_t = a_t + \theta a_{t-1} $$

and uses the current and one lagged error term.[^ma_q]

[^ma_q]: An MA(q) model includes $q$ lagged error terms:

    $$ Y_t = a_t + \theta_1 a_{t-1} + \theta_2 a_{t-2} + \cdots + \theta_q a_{t-q} $$.

An ARMA(p, q) model combines these AR and MA components, using $p$ lagged values of the series and $q$ lagged error terms. In practice, X13's automatic modeling usually finds appropriate $p$ and $q$ values. However, it worth paying attention to correctly set the differencing and regression variables for seasonal adjustment.


## Differencing

ARMA models are most effective with stationary time series, where both the mean and correlation structure do not vary over time.
For non-stationary time series, transforming them into stationary ones is essential, and differencing is a widely used method for this purpose. It is known that differencing a series $k$ times can remove a polynomial trend of degree $k$. Therefore, first differencing is effective for a series with a linear trend, while second differencing works for a series with a quadratic trend.

Seasonal patterns might also require seasonal differencing to achieve stationarity. The orders of differencing for the non-seasonal and seasonal parts are denoted as $d$ and $D$, respectively. Combining these with the stochastic model specification gives the notation SARIMA(p, d, q)(P, D, Q), where $p$, $d$, $q$ are non-seasonal parameters, and $P$, $D$, $Q$ are seasonal.[^s_in_arima]:

[^s_in_arima]: The "S" in SARIMA stands for seasonal. Since most of the ARIMA models within X-13 are seasonal, we will restrain from using the term and usueally refer to an ARIMA model of the structure (p, d, q)(P, D, Q).

$$\text{SARIMA}\underbrace{(p, d, q)}_{\text{non-seasonal }}\underbrace{(P, D, Q)}_{\text{seasonal}}.$$

Let's apply this to `AirPassengers`. A log-transformed version of the series looks as follows:

```{r}
plot(log(AirPassengers))
```

This series exhibits a clear increasing trend and seasonal pattern. Let's call the log-transformed series $X_t$.
We can now difference the series to make $Y_t = \Delta X_t = X_t - X_{t-1}$.
Which looks like:

```{r}
plot(diff(log(AirPassengers)))
```

The trend is removed, but some seasonal patterns remain. Seasonal differencing is then applied to the already first differenced series $Y_t$:

$$ Z_t = Y_t - Y_{t-12} $$

A plot of $Z_t$:

```{r}
plot(diff(diff(log(AirPassengers)), 12))
```

Now, both the linear trend and seasonal patterns are removed, leaving a stationary process suitable for modeling with an (0, 0, 1)(0, 0, 1) ARIMA model. When the differencing order for both seasonal and non-seasonal components is included, the model becomes (0, 1, 1)(0, 1, 1), often called the "airline model" after Box and Jenkins' work.[^airline]

[^airline]: The "airline model," or the ARIMA(0, 1, 1)(0, 1, 1) model, was popularized by @box1970time through their influential work in the field of time series analysis. This model is often associated with their seminal book "Time Series Analysis: Forecasting and Control." First published in 1970, this book has been a foundational text in the field of time series analysis. The airline model, named for its application in modeling airline passenger data, exemplifies the application of Seasonal ARIMA modeling in practical scenarios.


<!-- DISCUSS: not sure how useful for now... -->
<!--


## Optional: Fitting ARIMA models

Here we present a very oversimplied way to start to understand what values of $p, P, q$ and $Q$ you can investigate for your time series of interest.
Recall that earlier it was mentioned that using automatic model identification is sufficient for most to get an adequate seasonal adjustment.
Hence, this is simply for the interested reader to begin to gain additional intuition into the stochastic structures involved in their series and the types of structures the automatic modeling procedures look at.
One of the main tools in a time series analyist tool box is the autocorrelation function (ACF).
This is a function that returns the correlation between observations $h$ time units apart throughout the entire sample.
So for $h=2$ this means looking at the correlation between the pairs $(X_1, X_3), (X_2, X_4), (X_3, X_5), \ldots$.
Then a way to build a SARIMA model is to match the sample ACF and the theoretical ACF of a given model.
The main point distinguishing an AR($p$) and MA($q$) is how their theoretical ACF behaves.
An AR($p$) will have ACF the has exponential decay as $h$ increases.
For example, an AR(1) ACF is $$\rho(h) = \phi^h$$ An MA($q$) models ACF will be non-zero for the first $q$ lags and then cutoff to zero thereafter.
The ACF of an MA(1) is $$\rho(h) = \begin{cases}
~~1 & h = 0 \\
\frac{\theta}{1 + \theta^2} & h = 1 \\
~~0 & \text{otherwise}
\end{cases}
$$ In practice of course the difference between decay and cut-off can be nebulous to detect but the interested reader is encouraged to explore the `arima.sim()` function the look at the sample ACF with the `acf()` function.
As you increase the sample size it will converge to the theoretical ACF value and you can start to see the structures just discussed.

```{r}
x_AR <- arima.sim(model = list(ar = .75), n = 300)
x_MA <- arima.sim(model = list(ma = .75), n = 300)
tsbox::ts_plot(cbind(x_AR, x_MA))
op <- par(mfrow = c(1, 2), mar = c(5, 2, 4, 2))
acf(x_AR, xlab = "h", main = ""); title("ACF of AR(1) model")
acf(x_MA, xlab = "h", main = ""); title("ACF of MA(1) model")
par <- op
```

 -->


## Regression

We have discussed SARIMA modeling (both the SARMA and differencing), now we see how exogenous regression variables come into play.

The regARIMA model takes the form $$ f\left(\frac{Y_t}{D_t} \right) = \boldsymbol{\beta}^\prime {\mathbf X}_t + Z_t .$$ Here $Y_t$ is the observed time series.
The function $f$ represents a transformation, most commonly used is the log transform ie $f(x) = \log(x)$.
$D_t$ is any intervention that has taken place prior to any transformation or modeling.
This intervention is usually subjective and customized for individual series on an as-needed basis.
For example, if a soybean farmer strike occurred and the soybean export series suffered for its duration.
This type of event might adversely affect the seasonal adjustment filters and automatic model identification routines and can be mediated as an initial step.
If no transformation or intervention is needed the model form is: $$ Y_t = \underbrace{\boldsymbol{\beta}^\prime {\mathbf X}_t}_{\text{Regression}} + \underbrace{Z_t}_{\text{ARIMA}} .$$

The regression variables appear in the columns of the design matrix ${\mathbf X}_t$ and $Z_t$ is an ARIMA process.
This last assumption on $Z_t$ is what distinguished a regARIMA model from more classic linear models and multiple linear regression where error terms are assumed uncorrelated.

In order to achieve a suitable seasonal adjustment it is important to get the regARIMA model correct.
For most dataset the built in automatic modeling features of the X13 program will be suitable to detect a reasonable model.
This can be used as a starting point for more rigorous regARIMA model development or used as the final regARIMA modeling choice for your seasonal adjustment needs.
We evoke automatic model identification through the XXX spec.
The default behavior of the R seasonal package is XXX which includes automatic model identification.

::: callout-tip
## Automatic and manual model choice

As an aside, the general rule is to not use automatic modeling in production.
This mean, if you are going to include seasonal adjustment as part of a large scale data processing that occurs regularly (say monthly), then it is not advisable to have automatic model identification run every month.
Instead, an alternative process, is to run automodel once and then fix the model choice in the XXX spec file.
This does not need to be done manually since the `static()` function from the seasonal package can do this for you.
:::

| Outlier Type                | Automatic Detection Available? |
|-----------------------------|--------------------------------|
| Additive outliers (AO)      | Yes (default)                  |
| Level shifts (LS)           | Yes (default)                  |
| Temporary level shifts (TL) | Yes                            |
| Temporary changes (TC)      | No                             |
| Ramps (RP, QI, QD)          | No                             |
| Seasonal outliers (SO)      | No                             |

## Case Study: AirPassengers

Consider the default seasonal adjustment:

```{r}
library(seasonal)
m <- seasonal::seas(AirPassengers, x11 = "")
print(m$spc$automdl)
print(m$spc$arima)
```

Notice the value `NULL` indicates no ARIMA model is specified and the returned arguments for the automdl spec indicate it is active during the X13 run.

```{r}
seasonal::udg(m, "automdl")
```

Indicates that automatic modeling identified the (0 1 1)(0 1 1) model as the best choice.
If we want to hardcode this model for subsequent runs, and turn off automatic model identification, this can be done via

```{r}
m_call <- seasonal::static(m)
m2 <- eval(m_call)
```

There are many options you can modify when searching for outliers in your series.
Some of the most practical options to start your exploration are the *type*, *critical value* and *span* that you would like to search.

Here is an example of using span to limit the outlier search to the last few years of a series:

```{r}
m_span <- seas(AirPassengers,
  outlier.types = c("ao", "ls", "tc"),
  outlier.critical = 4.0,
  outlier.span = "1958.jan, ")
summary(m_span)
```

```{r}
m_nospan <- seas(AirPassengers,
  outlier.types = c("ao", "ls", "tc"),
  outlier.critical = 4.0)
summary(m_nospan)
```

The default critical value is set based on the length of the outlier span.
Notice the MA-Nonseasonal-01 value when comparing `m_span` with `m_nospan`.
We see the choice of span, and ultimately the choise to include an outlier in your model can have a dramatic effect on the estimated regARIMA parameters.

<!-- ## Case study 2 -->

<!-- Decide if you should include AO in May 2014. -->

<!-- Construct a simple user defined regressor to handle specific issue. -->
