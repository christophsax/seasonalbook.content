[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Seasonal Adjustment in R",
    "section": "",
    "text": "Welcome\nThis is the website for the work-in-progress edition of Seasonal Adjustment in R, an online Book by James Livsey and Christoph Sax."
  },
  {
    "objectID": "index.html#about-the-book",
    "href": "index.html#about-the-book",
    "title": "Seasonal Adjustment in R",
    "section": "About the book",
    "text": "About the book\nThis book will teach you how to do seasonal adjustment in R, using X13-ARIMA-SEATS.\nSpecifically, the audience will be both R users who want to learn about seasonal adjustment as well as seasonal adjustment practitioners, who are interested in using R. The book will be tailored to the practical applications of seasonal adjustment within R. It presents background material and references for the theoretically minded reader. The main focus, however, is on concrete problems and examples.\nWe will showcase methods through detailed examples with associated code. This presentation allows the academic level to be quite broad; understood by undergraduates all the way through advanced Ph.D. students."
  },
  {
    "objectID": "index.html#key-features-of-the-book",
    "href": "index.html#key-features-of-the-book",
    "title": "Seasonal Adjustment in R",
    "section": "Key features of the book",
    "text": "Key features of the book\n\nEach chapter include a concrete practical problem and shows how X-13 can be used to address it\nTeach-by-example format\nContinuous connection of X-13ARIMA-SEATS input with R input and vice-versa\nFundamental theoretical material is referenced throughout (mainly as an option)\nFor each example given the book will give answers, code and provide data"
  },
  {
    "objectID": "10-introduction.html#seasonal-adjustment",
    "href": "10-introduction.html#seasonal-adjustment",
    "title": "1  Introduction",
    "section": "Seasonal Adjustment",
    "text": "Seasonal Adjustment\nMany time series exhibit a regular seasonal pattern over the year. US unemployment, for example, is usually higher from January to March and again in June and July. Similarly, retail sales tend to peak during the Christmas season. This seasonal behavior is regular and predictable. The goal of seasonal adjustment is to estimate and remove the seasonal component from a time series.\nWhy do we want to do this? Seasonal data is usually hard to interpret. For example, if we want to learn from the US unemployment rate if the economy is moving out of a recession during certain months, we want the labor market data to be free from seasonal effects."
  },
  {
    "objectID": "10-introduction.html#x-13arima-seats",
    "href": "10-introduction.html#x-13arima-seats",
    "title": "1  Introduction",
    "section": "X-13ARIMA-SEATS",
    "text": "X-13ARIMA-SEATS\nFundamentally, seasonal adjustment decomposes a time series into a trend, a seasonal, and an irregular component. Seasonal adjustment is then the act of removing the seasonal estimate from the observed series. There are many ways to perform this decomposition. This book focuses on a particular one, X-13ARIMA-SEATS (X-13, for short), the seasonal adjustment software developed by the United States Census Bureau. X-13 offers an elaborate toolkit to perform seasonal adjustment. The software allows users to control all aspects of the modeling process or alternatively, to use automated methods to make all modeling choices. In the text we will try to present material with this in mind. Throughout we offer suggestions about when built-in automatic method are sufficient (and sometimes even preferred) and when an analyst can get the most ``bang for the buck’’ to control modeling options themselves."
  },
  {
    "objectID": "10-introduction.html#r",
    "href": "10-introduction.html#r",
    "title": "1  Introduction",
    "section": "R",
    "text": "R\nThis book will teach you how to use X-13 in R through the seasonal package, which offers access to all features of X-13 with a usually much simpler syntax. It should be noted that the seasonal package is not a re-coding of the X-13 software. Instead it is a translation from R to the X-13 software. This translation is done under the hood and practitioners need not concern themselves with this inner working of the package. However, we make this point such that users understand that conceptually anything that can be done in the native X-13ARIMA-SEATS software, either from the command line or HTML version, can be done in the seasonal R package. Also this means if additional clarification or information about seasonal adjustment is desired, the X-13 manual or research papers can be consulted. Any example or methods found via the X-13 documentation can be easily translated to the R seasonal package. In fact, all examples from the X-13 manual can be seen run in the R seasonal package at http://www.seasonal.website/examples.html. The required X-13 binaries are provided by the x13binary package and automatically included in seasonal. The next chapter provides a minimal example to get you started in less than five minutes."
  },
  {
    "objectID": "10-introduction.html#target-audience",
    "href": "10-introduction.html#target-audience",
    "title": "1  Introduction",
    "section": "Target audience",
    "text": "Target audience\nWe write this book for two primary audiences: The first focus is on current practitioners of seasonal adjustment who are interested in learning how to implement in R. This audience includes researchers from statistical agencies who want to use features of R to evaluate the properties of their seasonal adjustments.\nThe second focus is on current R users who want to learn seasonal adjustment. We are able to leverage the reader’s knowledge of R to make learning seasonal adjustment easier. We will feature exciting applications outside official statistics, such as the seasonal adjustment of business data.\nThe book tries to be as practical as possible. It usually starts with a practical problem and shows how to solve it in a cookbook style. Formal derivations are usually avoided. Each chapter ends with a case study that discusses a real-life example of the topic."
  },
  {
    "objectID": "10-introduction.html#history-of-x-13",
    "href": "10-introduction.html#history-of-x-13",
    "title": "1  Introduction",
    "section": "History of X-13",
    "text": "History of X-13\nIn official statistics, seasonal adjustment has a long tradition. The US Census Bureau developed the original X-11 software in the 1960s, Statistics Canada (Dagum 1980) continued the development afterward. The following software packages by the US Census Bureau were called X-12-ARIMA (Findley et al. 1998) and X-13ARIMA-SEATS (or X-13, for short) (Monsell 2007). X-11 is still used as a name for filter-based seasonal adjustment methods within X-13. Meanwhile, TRAMO-SEATS, developed by the Bank of Spain (Caporello, Maravall, and Sánchez 2001), offers an alternative model-based approach to seasonal adjustment.\n\nDagum, Estela Bee. 1980. The x-11-ARIMA Seasonal Adjustment Method. Statistics Canada, Seasonal Adjustment; Time Series Staff.\n\nFindley, David F, Brian C Monsell, William R Bell, Mark C Otto, and Bor-Chung Chen. 1998. “New Capabilities and Methods of the x-12-ARIMA Seasonal-Adjustment Program.” Journal of Business & Economic Statistics 16 (2): 127–52.\n\nMonsell, B. 2007. “The x-13A-s Seasonal Adjustment Program.” In Proceedings of the 2007 Federal Committee on Statistical Methodology Research Conference. http://www.fcsm.gov/07papers/Monsell.II-B.pdf.\n\nCaporello, Gianluca, Agustin Maravall, and Fernando J Sánchez. 2001. “Program TSW Reference Manual.” 0112. Banco de España Madrid. https://ideas.repec.org/p/bde/wpaper/0112.html.\n\nNational Bank of Belgium, Deutsche Bundesbank, Eurostat. 2017. JDemetra+: Econometric Software for Seasonal Adjustment and Other Time Series Methods. Eurostat. https://ec.europa.eu/eurostat/cros/content/download.\nIn its most recent version, X-13 offers these two seasonal adjustment methods in a single command-line tool written in Fortran. The National Bank of Belgium has created an alternative Java-based implementation called JDemetra+ (National Bank of Belgium, Deutsche Bundesbank, Eurostat 2017), also widely deployed by statistical agencies."
  },
  {
    "objectID": "10-introduction.html#the-seasonalbook-package",
    "href": "10-introduction.html#the-seasonalbook-package",
    "title": "1  Introduction",
    "section": "\n1.1 The seasonalbook package",
    "text": "1.1 The seasonalbook package\nAn R package that supplements “Seasonal Adjustment in R”, and contains all data and examples.\nTo install:\nremotes::install_github(\"christophsax/seasonalbook\")\nExample series:\n\nlibrary(seasonalbook)\nplot(grocery)"
  },
  {
    "objectID": "10-introduction.html#acknowledgements",
    "href": "10-introduction.html#acknowledgements",
    "title": "1  Introduction",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe are indebted to the United States Census Bureau for X-13ARIMA-SEATS and support for research around the software. Help and support by Brian Monsell are especially acknowledged.\nseasonal was originally developed for use at the Swiss State Secretariat of Economic Affairs. It has been dramatically improved thanks to suggestions and support from Matthias Bannert, Freya Beamish, Vidur Dhanda, Alain Galli, Ronald Indergand, Preetha Kalambaden, Stefan Leist, James Livsey, Pinaki Mukherjee, Bruno Parnisari and many others. The related work on the x13binary package facilitated (automated) deployment thanks to the R package system, CRAN, and GitHub for the x13prebuilt repository."
  },
  {
    "objectID": "10-introduction.html#references",
    "href": "10-introduction.html#references",
    "title": "1  Introduction",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "11-getting-started.html#installation",
    "href": "11-getting-started.html#installation",
    "title": "\n2  Getting started\n",
    "section": "\n2.1 Installation",
    "text": "2.1 Installation\nIf you use R, installing X-13ARIMA-SEATS from CRAN is as easy as installing any other R package (Sax and Eddelbuettel 2018):\n\nSax, Christoph, and Dirk Eddelbuettel. 2018. “Seasonal Adjustment by X-13ARIMA-SEATS in R.” Journal of Statistical Software 87 (11): 1–17. https://doi.org/10.18637/jss.v087.i11.\ninstall.packages(\"seasonal\")"
  },
  {
    "objectID": "11-getting-started.html#sec-a-minimal-example",
    "href": "11-getting-started.html#sec-a-minimal-example",
    "title": "\n2  Getting started\n",
    "section": "\n2.2 A minimal example",
    "text": "2.2 A minimal example\nOnce the package is installed, you can load it in the usual way:\n\nlibrary(seasonal)\n\nThe seas() function provides the core functionality of the package. By default, seas calls the automatic procedures of X-13 to perform a seasonal adjustment that works well in most circumstances:\n\nseas(AirPassengers)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;           Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  \n#&gt;          -0.00295            0.01777            0.10016            0.11562  \n#&gt;    MA-Seasonal-12  \n#&gt;           0.49736\n\nThe first argument of seas is a time series of class ts. ts objects are frequently used in base R and are useful to store monthly, quarterly, or annual data. We restrict our attention to monthly and quarterly series. This is done for two reasons; first is these are the main frequencies handled by X-13, second, this sampling frequency make conceptual understanding of statistical methods, such as linear filters, easier to grasp. The AirPassengers example series is included in base R and shows monthly totals of international airline passengers from 1949 to 1960. seas() returns a seas object that contains the necessary information on the adjustment performed on this time series; we can assign it to a variable:\n\nm &lt;- seas(AirPassengers)\n\nThere are several functions and methods for \"seas\" objects. The final function returns the adjusted series. The plot method shows a plot with the unadjusted and the adjusted series.\n\nplot(m)\n\n\n\n\nAs you can see, the adjusted series is much less volatile than the original one because the seasonal component was removed from the original series. But the adjusted series is not entirely smooth. This is because it still contains the irregular component.\nThis constitutes a crucial point about seasonal adjustment: It only removes regular, predictable movements, not irregular ones. In the adjusted series, we can see a decrease in airline passengers in 1953 and between 1957 and 1958. These decreases were difficult to discover in the original series.\nThe summary method displays an overview of the model, very similar to the one produced by other R classes (eg lm or numeric):\n\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe summary gives an overview of the adjustment model and provides diagnostics. This book will help you do understand it in more detail. The following section discusses some of the elements and relates them to the chapters in this book."
  },
  {
    "objectID": "11-getting-started.html#where-to-go-from-here",
    "href": "11-getting-started.html#where-to-go-from-here",
    "title": "\n2  Getting started\n",
    "section": "\n2.3 Where to go from here",
    "text": "2.3 Where to go from here\nseas(AirPassengers) produces a good seasonal adjustment of the airline passengers time series. If you are very new to seasonal adjustment, the automated routines of X-13 and seasonal produce an adjustment that works well in most circumstances.\nThe command seas(AirPassengers) has invoked a large number of specs of X-13. spec is X-13 slang for a module within the software. X-13 is built on top of twenty specs that perform various subtasks of seasonal adjustment. Some specs are required most of the time (e.g., regression), while others are optional (e.g., seats) or purely technical (e.g., spans shortens the time series in use). Chapter 3 discusses the available specs in more detail.\nThis book teaches you how to use and fine-tune the individual specs and deal with concrete data problems.\n\n2.3.1 Fundamentals\nSpecifically, the command seas(unemp) has invoked the following fundamental specs – they are involved in most adjustments and are covered in the first part of the book:\n\nTransform\n\nA decision on initial transformation was made. The automated procedures concluded that a log transformation was made and a multiplicative seasonal adjustment model, rather than an additive model, was estimated. Chapter 4 discusses the choices. Since transform is a relatively simple spec, it is a good starting point to familiarize yourself with the spec idea.\n\nRegression\n\nAn automated model search concluded that AirPassengers is best modeled by an (0 1 1)(0 1 1) ARIMA model. Chapter 5 explains what that means and how such a model structure is determined and estimated.\n\nSEATS / X11\n\nSeasonal decomposition is performed by SEATS. SEATS is one of the two options for decomposing a series and is discussed in more detail in Chapter 7. The alternative, X11, is discussed in Chapter 6.\n\n\n2.3.2 Data issues\nThe command seas(AirPassengers) has also dealt with various data issues, which are covered in the second part of the book:\n\nHoliday\n\nSignificant Easter effects have been found in AirPassengers and were removed from the adjusted series. Moving holidays like Easter or Chinese New Year are vital in seasonal adjustment since they may significantly impact the behavior of many time series. For AirPassengers, the number of passengers is higher in months with Easter. Moving holiday effects will be discussed in Chapter 8.\n\nWeekday\n\nNot every month has the same number of weekdays. Since many activities (such as air traveling) differ between weekends and weekdays, this constitutes another predictable component. In AirPassengers, there are fewer passengers on a weekday than during a weekend, and the automated procedures decided to remove the effect. These effects are discussed in Chapter 9.\n\nOutliers\n\nCertain data points may be well out of the ordinary. These outliers are a problem for the modeling and adjustment process. An automated procedure scanned the series for outliers and found an additive outlier on May 1951. This outlier is shown in the plot above, too. Outliers are discussed in Chapter 10.\n\nSeasonal Breaks\n\nThe seasonal pattern in AirPassengers looks relatively stable. Some time series, however, show abrupt changes in the seasonal pattern. Chapter 11 discusses them and shows how to deal with seasonal breaks.\n\n\n2.3.3 Additional issues\nThe third part of the book deals with additional issues:\n\nPresence of seasonality\n\nWhile the presence of seasonality in AirPassengers is prominent, this is not always the case. If a series has no seasonal pattern, there is no need for a seasonal adjustment. If it is adjusted anyway, the process adds noise to the series and should be avoided. Chapter 12 shows how seasonality can be detected and how to decide whether an adjustment should be made or not.\n\nAnnual constraining\n\nUsually, a seasonal adjustment may affect the annual values of a time series. In part, this is by design. The number of weekdays may differ between years, so the adjusted annual values may be different too. In part, this may be an artifact of the adjustment process. X-13 offers tools to enforce the annual values of the adjusted series to be the same as the original one. Chapter 13 shows how to constrain annual value and whether it is a good idea.\n\nIndirect vs. direct adjustment\n\nOften, a seasonal adjustment may be performed on individual series or on an aggregate of multiple series. X-13 offers tools that let you compare these two possibilities. Chapter 14 discusses the options and helps you to decide which one is better.\n\n\n2.3.4 Quality assessment\nAdjusting a series with the automated procedure is straightforward. But is the resulting series a reasonable adjustment? The fourth part helps you to decide between competing seasonal adjustment models.\n\nQuality measures\n\nIn the lower part, the summary of the adjustment model shows various quality measures: The AICc and BIC information criterion and the QS, the Box-Ljung, and the Shapiro statistic. None of them shows any significance (indicated by one or several stars), which is a good sign. Various quality measures and their interpretation is shown in Chapter 15.\n\nRevisions\n\nWhen comparing seasonal adjustment models, the stability of the model and the series is often an important consideration. One does not want to get a different series with a new data point. X-13 offers tools to analyze revisions. Chapter 16 discusses them and helps you to decide which model to pick."
  },
  {
    "objectID": "11-getting-started.html#references",
    "href": "11-getting-started.html#references",
    "title": "\n2  Getting started\n",
    "section": "\n2.4 References",
    "text": "2.4 References"
  },
  {
    "objectID": "20-part-basics.html",
    "href": "20-part-basics.html",
    "title": "Basics",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter is complete enough as an education tool and can be used in a course. It needs additional polishing.\n\n\n\n\nThis section gets readers familiar with X-13ARIMA-SEATS. It begins by explaining the history and pedagogy of the software (Chapter 3). This leads directly into discussing the principal elements of X-13ARIMA-SEATS."
  },
  {
    "objectID": "21-overview.html#main-specs",
    "href": "21-overview.html#main-specs",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.1 Main specs",
    "text": "3.1 Main specs\nSome specs, like the transform and the regression spec, are used in most seasonal adjustment processes. Others fulfill a particular function and are used only occasionally. For example, the history spec allows an analysis of the revision history and is only called for diagnostical purposes. Other specs are mutually exclusive. You can choose x11 or seats to decompose a time series, but not both. Table 3.1 lists the main specs of X-13 and describes what they do.\n\n\nTable 3.1: Important specs that are used in most seasonal adjustment models\n\n\n\n\n\n\nSpec name\nWhat it does\nChapter\n\n\n\nestimate\nEstimates the regARIMA model specified by the regression and arima specs.\nChapter 5\n\n\narima\nSpecifies the ARIMA part of the regARIMA model.\nChapter 5\n\n\nregression\nSpecification for including regression variables in a regARIMA model.\n\nChapter 5, Chapter 8, Chapter 9\n\n\n\nautomdl\nSpecifies the ARIMA part of the regARIMA model using an automatic procedure.\nChapter 5\n\n\noutlier\nSpecification to perform automatic detection of additive (point) outliers.\nChapter 10\n\n\nseats\nInvoke the production of model-based signal extraction using SEATS. Default in the R seasonal package.\nChapter 7\n\n\nx11\nAn optional spec for invoking seasonal adjustment by the X-11 methodology.\nChapter 6\n\n\nforecast\nSpecification to forecast and/or backcast the time series given in the series spec using the estimated model.\nChapter 5"
  },
  {
    "objectID": "21-overview.html#interactions-between-specs",
    "href": "21-overview.html#interactions-between-specs",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.2 Interactions between specs",
    "text": "3.2 Interactions between specs\nX-13 specs interact with each other. For example, once a series is transformed, it is usually passed to the regression and arima specs, which estimate a regARIMA model. To come up with a good model, it uses the automdl spec to determine a good ARIMA model automatically. To correct outlier values, it collaborates with the outlier spec. Once the series is modeled, it is decomposed either by the seats or the x11 spec. Figure 6.1 shows the interaction between the main specs in a typical seasonal adjustment run.\n\n\n\n\n\nflowchart LR\n    A(  transform  )--&gt;regARIMA\n    subgraph regARIMA\n    direction LR\n    B(estimate)&lt;--&gt;D(regression)\n    B&lt;--&gt;C(automdl)\n    B&lt;--&gt;E(arima)\n    end\n    regARIMA --&gt; F(seats)\n    regARIMA --&gt; G(x11)\n\n\nFigure 3.1: Interactions between X-13 specs."
  },
  {
    "objectID": "21-overview.html#specs-arguments",
    "href": "21-overview.html#specs-arguments",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.3 Specs Arguments",
    "text": "3.3 Specs Arguments\nWithin specs, there are arguments. Spec arguments guide the behavior of the spec. For example, the function argument in the transform spec can be set to \"auto\", \"none\", \"log\", \"sqrt\", \"inverse\" or \"logistic“. The default is set to \"auto\", which causes an automated model evaluation between \"log\" and \"none\". There are many other arguments, and the X-13 Manual (US Census Bureau 2017) is the canonical reference. This book will list and explain the frequently used arguments while skipping some of the more exotic ones.\n\nUS Census Bureau. 2017. X-13ARIMA-SEATS Reference Manual. Version 1.1. Washington, DC, USA: Time Series Research Staff, Center for Statistical Research; Methodology, US Census Bureau. http://www.census.gov/ts/x13as/docX13ASHTML.pdf."
  },
  {
    "objectID": "21-overview.html#addressing-specs-from-r",
    "href": "21-overview.html#addressing-specs-from-r",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.4 Addressing specs from R",
    "text": "3.4 Addressing specs from R\nIn the R package seasonal, spec argument combinations can be directly fed to the seas() function. For example, to turn off the log transformation in the AirPassengers example from Section 2.2, we can specify the following:\n\nm_no_log &lt;- seas(AirPassengers, transform.function = \"none\")\nsummary(m_no_log)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, transform.function = \"none\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Constant          30.62077    4.60956   6.643 3.08e-11 ***\n#&gt; Leap Year         11.32104    3.43088   3.300 0.000968 ***\n#&gt; Weekday           -0.90361    0.17787  -5.080 3.77e-07 ***\n#&gt; Easter[1]          6.89372    1.80972   3.809 0.000139 ***\n#&gt; AR-Nonseasonal-01  0.81929    0.04903  16.709  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 0 0)(0 1 0)  Obs.: 144  Transform: none\n#&gt; AICc: 993.4, BIC:  1010  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.):  29.2   Shapiro (normality): 0.984\n\nAs you can see from the lower part of the summary, transform is now set equal to none. Note that the change in the transform argument has also affected the other specs. The ARIMA model is different now, and a leap-year adjustment is performed. We will discuss the working of the transform spec in more detail in the next chapter."
  },
  {
    "objectID": "21-overview.html#less-frequently-used-specs",
    "href": "21-overview.html#less-frequently-used-specs",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.5 Less frequently used specs",
    "text": "3.5 Less frequently used specs\nWhile the main specs appear in most seasonal adjustment processes, other specs are less often used. Some of them have a diagnostic purpose. The spectrum spec, for example, draws and analyses the spectrum of a time series, similar to the R base function spectrum(). Other specs are more elaborate. For example, the history spec produces a sequence of runs from a sequence of truncated versions of the time series and allows the analysis of potential revisions. The slidingspans spec models various parts of the time series and has a similar purpose as history. All diagnostics specs are listed in Table 3.3.\n\n\nTable 3.2: Diagnostic specs\n\n\n\n\n\n\nSpec name\nWhat it does\nChapter\n\n\n\nhistory\nRequesting a sequence of runs from a sequence of truncated versions of the time series for the purpose of creating historical records.\nChapter 16\n\n\nslidingspans\nProviding sliding spans stability analysis.\nChapter 16\n\n\nidentify\nProduce tables and line printer plots of sample ACFs and PACFs.\n\n\n\nspectrum\nProvides a choice between two spectrum diagnostics to detect seasonality or trading day effects.\n\n\n\ncheck\nProduce statistics for diagnostic checking of residuals from the estimated model.\n\n\n\n\n\nThe force and the composite spec are special-purpose specs. The former enforces the yearly totals of the seasonally adjusted series to be equal to those of the original series. The latter allows a comparison of indirect and direct seasonal adjustments. Table 3.3 gives an overview of the special-purpose specs.\n\n\nTable 3.3: Special purpose specs\n\n\n\n\n\n\nSpec name\nWhat it does\n\n\n\n\nforce\nAllow users to force yearly totals of the seasonally adjusted series to equal those of the original series for convenience.\nChapter 13\n\n\ncomposite\nObtaining both indirect and direct adjustments of a composite series.\nChapter 14\n\n\n\n\nFinally, a few specs are not covered in this book. Some of them are vintage specs that were important in earlier versions of X-13 but were superseded by other specs. It is generally recommended to use regression instead of x11regression and automdl instead of pickmdl. Other specs have a purely technical purpose. For example, the series spec provides X-13 with the data, starting date, and frequency. In R, this is handled by seasonal and will not be covered.\n\n\nTable 3.4: Vintage and technical specs that won’t be covered in this book)\n\n\n\n\n\nSpec name\nWhat it does\n\n\n\nx11regression\nAlternative to regression. Can only be used with X11.\n\n\npickmdl\nAlternative to automdl. Can only be used with X11.\n\n\nseries\nProvides X-13 with the data, the starting date and the frequency. In R, this is handled by seasonal and will not be covered.\n\n\nmetadata\nSpecification that allows users to insert metadata into the diagnostic summary file. In R, this is handled by seasonal and will not be covered."
  },
  {
    "objectID": "21-overview.html#main-user-choices",
    "href": "21-overview.html#main-user-choices",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.6 Main user choices",
    "text": "3.6 Main user choices\nWhile we will cover each spec in more detail, this section provides a few examples of frequent user choices. As we saw in the previous chapter, by default, seasonal uses defaults that work well in many circumstances. The following is a non-exhaustive list of deviations from the defaults. The default options of seas() are listed as explicit arguments and are discussed in the arguments section of the help page of\n\n3.6.1 Using X11\nWhile seas() calls SEATS by default, X11 is often easier to use. To perform a seasonal adjustment on AirPassengers with X11, we need to activate the x11 spec.\n\nm_x11 &lt;- seas(AirPassengers, x11 = \"\")\n\nAn empty string \"\" tells seas() to use the spec without an argument. Alternatively, you can also use an empty list, list(). If more than one mutually exclusive spec is included in seas(), specs are overwritten according to the priority rules shown in Table 3.5\n\n\nTable 3.5: If more than one mutually exclusive spec is included, specs are overwritten according to priority rules.\n\n\n\n\n\nProcedure\nPriority rules\n\n\n\nModel selection\n\narima\npickmdl\nautomdl\n\n\n\nAdjustment procedure\n\nx11\nseats\n\n\n\n\n\nThis is why the default SEATS procedure in the introductory example was overwritten by the specification of x11 = \"\".\n\n3.6.2 Turning off auto modeling\nBy default, the automdl spec finds a good ARIMA model. By specifying the model argument of the arima spec, the automated modeling is deactivated. Instead of the automatically chosen (0 1 1)0 1 1) ARIMA model, the following estimates an (1 1 0)1 1 0) model.\n\nm_arima &lt;- seas(AirPassengers, arima.model = c(1, 1, 0, 1, 1, 0))\nsummary(m_arima)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, arima.model = c(1, 1, 0, 1, 1, 0))\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029124  0.0004794  -6.076 1.23e-09 ***\n#&gt; Easter[1]          0.0167907  0.0067080   2.503   0.0123 *  \n#&gt; AO1951.May         0.0950587  0.0194363   4.891 1.00e-06 ***\n#&gt; AR-Nonseasonal-01 -0.1078564  0.0871940  -1.237   0.2161    \n#&gt; AR-Seasonal-12    -0.4588948  0.0790634  -5.804 6.47e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 1 0)(1 1 0)  Obs.: 144  Transform: log\n#&gt; AICc: 951.6, BIC: 968.1  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 35.88 . Shapiro (normality): 0.9937\n\n\n3.6.3 Turning off AIC testing and Outlier detection\nBy default, seas() evaluates the presence of weekday and Easter effects and checks for outliers in the data. Both can be turned off:\n\nm_no_auto &lt;- seas(AirPassengers, regression.aictest = NULL, outlier = NULL)\nsummary(m_no_auto)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL)\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; MA-Nonseasonal-01  0.40181    0.07887   5.095  3.5e-07 ***\n#&gt; MA-Seasonal-12     0.55695    0.07626   7.304  2.8e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 987.4, BIC: 995.8  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.04   Shapiro (normality): 0.9886  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nIn practice, many spec argument combinations can be extracted via the static() functions, which will be demonstrated in the next chapter. Alternatively, the seasonalview package offers a graphical user interface that allows you to click various spec argument combinations.\nm &lt;- seas(AirPassengers)\nview(m)\n\n\nManipulating spec argument combinations in the seasonalview graphical user interface"
  },
  {
    "objectID": "21-overview.html#references",
    "href": "21-overview.html#references",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.7 References",
    "text": "3.7 References"
  },
  {
    "objectID": "22-transform.html#prior-modifications-and-transformations",
    "href": "22-transform.html#prior-modifications-and-transformations",
    "title": "4  Transform",
    "section": "\n4.1 Prior modifications and transformations",
    "text": "4.1 Prior modifications and transformations\nThe first is a prior modification. A prior modification scales each observation for known fixed effects. These effects can be well-known and established, such as the length of a period or leap-year effects, or they can be more subjective such as a modification for a workers’ strike. We will see how this comes into the regARIMA model in Chapter 5. We can think of prior-modification factors as events or corrections made to your data that are fixed throughout the adjustment process. These prior modification factors can also be permanent (default) or temporary. Permanent modifications are excluded from the final seasonal adjustment. Temporary modifications are removed while calculating seasonal factors but added back to the seasonally adjusted series.\nThe second type is a nonlinear transformation applied to the observations. This is typically a choice between logarithmic transform and no transformation but for modeling can be any power of the Box-Cox transformation.\n\nm_none &lt;- seas(AirPassengers, transform.function = \"none\")\nm_log  &lt;- seas(AirPassengers, transform.function = \"log\")"
  },
  {
    "objectID": "22-transform.html#sec-additive-and-multiplicative-adjustment",
    "href": "22-transform.html#sec-additive-and-multiplicative-adjustment",
    "title": "4  Transform",
    "section": "\n4.2 Additive and multiplicative adjustment",
    "text": "4.2 Additive and multiplicative adjustment\nAs you remember from Chapter 1, Seasonal adjustment decomposes a time series into a trend, a seasonal, and an irregular component. Algebraically, the fundamental identity of seasonal adjustment looks like this:\n\\[Y_t = T_t + S_t + I_t. \\tag{4.1}\\]\nWe seek the decompose our observed series \\(Y_t\\) into a trend \\(T_t\\), a seasonal \\(S_t\\), and an irregular \\(I_t\\) component. The formulation above is additive, i.e., the trend, the seasonal, and the irregular component sum up to the observed series. The goal of seasonal adjustment is to subtract the seasonal component:\n\\[A_t = Y_t - S_t.\\]\nFor example, an observed value of 100 with a seasonal factor of 3.2 would result in a seasonally adjusted value of 100 - 3.2 = 96.8.\nAlternatively, the decomposition can be multiplicative:\n\\[Y_t = T_t \\cdot S_t \\cdot I_t \\tag{4.2}\\]\nI.e., the observed series is the product of the trend and the seasonal and irregular components. Since these are factors, the goal of seasonal adjustment is to remove seasonality by dividing by the seasonal factor.\n\\[A_t = \\frac{Y_t}{S_t}.\\]\nFor example, an observed value of 100 with a seasonal factor of 1.08 would result in a seasonally adjusted value of 100 / 1.08 = 92.59259. Hence for multiplicative models, values of \\(S_t &gt; 1\\) decrease the observed value, and \\(S_t &lt; 1\\) increase it. Keep this in mind when viewing seasonal factors such as in the function monthplot(m).\nFor a multiplicative adjustment, it is sufficient to take logarithms of the initial series and re-transform the results after the decomposition. The transform spec takes care of this."
  },
  {
    "objectID": "22-transform.html#model-choice",
    "href": "22-transform.html#model-choice",
    "title": "4  Transform",
    "section": "\n4.3 Model choice",
    "text": "4.3 Model choice\nX-13 has a built-in statistical test to decide between log and no transformation. The choice is made by comparing the AICc1 value of an ARIMA (0 1 1)(0 1 1) model fit, or a user-specified ARIMA model, to the log-transformed series and the original series.1 With small sample sizes, a standard AIC test may select models with too many parameters. AICc tackles this problem by correcting for sample size.\nFor most practical purposes, this is an effective choice and can be left to the program to decide. If your series has negative values, it can not be log-transformed, and automatic selection is performed. Other restrictions on the allowed transformations exist, but these situations are rare. We can look at the results of the transformation tests by looking at specific statistics. The udg() function provides access to a large number of diagnostical statistics.The qs() function and the AIC(), BIC() and logLik() methods are wrappers that use udg() to access some specific diagnostical statistics.\n\nm &lt;- seas(AirPassengers)\nudg(m, c(\"aictest.trans.aicc.nolog\", \"aictest.trans.aicc.log\"))\n#&gt; aictest.trans.aicc.nolog   aictest.trans.aicc.log \n#&gt;                1021.1919                 987.3845\n\nWe see the AICc for log transformation is lower and hence selected. We saw this in ?sec-getting-started, were the summary of the seasonal object, summary(m), has told us that Transform: log. The same infor transformation can also be found in many other places such as the HTML output with out(m) or the udg with argument name aictrans such as udg(m, \"aictrans\").\n\n\n\n\n\n\nX-13 HTML Output\n\n\n\nX-13ARIMA-SEATAS has a built-in HTML output that offers an extensive summary of a seasonal adjustment process. In R, this can be accessed using the out() function. E.g.,\n\nout(m)\n\n\n\nThe choice between log and none changes the type of seasonal decomposition that will occur and, hence, your interpretation of the seasonal factors. With no transformation, X-13 will perform an additive seasonal adjustment specified in Equation 4.1. If log transformation is selected, X-13 will perform a multiplicative adjustment as specified in Equation 4.2."
  },
  {
    "objectID": "22-transform.html#transform-options",
    "href": "22-transform.html#transform-options",
    "title": "4  Transform",
    "section": "\n4.4 Transform options",
    "text": "4.4 Transform options\nThe transform spec controls these options. Some primary options within this spec are\n\n\n\n\n\n\n\n\nSpec option\nUse\nExample values\ndefault\n\n\n\ntransform.function\nTransform function\n\nnone, log, auto\n\nnone\n\n\ntransform.aicdiff\nadjust tolerance of AIC test for log transform\n\n0.0, 3.0, -4.5\n\n-2.0\n\n\nxtrans\nPrior adjustment factor\nseas(m, xtrans = y)\nNULL"
  },
  {
    "objectID": "22-transform.html#case-study-airpassengers",
    "href": "22-transform.html#case-study-airpassengers",
    "title": "4  Transform",
    "section": "\n4.5 Case Study: AirPassengers\n",
    "text": "4.5 Case Study: AirPassengers\n\nAn increasing variance, also known as heteroskadasticity is one sign of requiring a logarithmic transform. We have already seen that this is present in AirPassengers. Let’s verify that the automatic transformation identifies this.\n\ntransformfunction(m)\n#&gt; [1] \"log\"\n\nThis is also a good place to get our first look at the seasonal factors. The monthplot() method offers a convenient way to look at these:\n\nmonthplot(m)\n\n\n\n\nLike the R base monthplot() function that can be applied on any time series (also on quarterly time series!), this groups time series data by months. If you look at the January (J), entry, the blue bars show the evolution of the detrended data from 1949 to 1960. The red bar shows the average seasonal factor over these years. The smooth red lines show the seasonal factors as estimated by the model.\nAs you can see from the plot, there are more passengers during the summer months and fewer in the winter. The seasonal factors change over time. The summer peak becomes more pronounced in later years, while the local peak in February and March disappears over time.\nIf you want to extract the seasonal factor directly into R, you can use the series() function:\nseries(m, \"seats.seasonal\")"
  },
  {
    "objectID": "22-transform.html#case-study-more-difficult-decision",
    "href": "22-transform.html#case-study-more-difficult-decision",
    "title": "4  Transform",
    "section": "\n4.6 Case Study: More difficult decision",
    "text": "4.6 Case Study: More difficult decision\nConsider the situation where you are trying to decide on transform choices for monthly retail grocery store data. The series grocery is part of the seasonalbook package.\n\nlibrary(seasonalbook)\nplot(grocery)\n\n\n\n\nVisual inspection of the series shows no immediate reason to think we need to perform a logarithmic transform. There is possible seasonal heteroskadasity which could be mitigated by taking logs. Perform an X-11 adjustment with all the defaults of seasonal\n\nm &lt;- seas(grocery, x11 = \"\")\nudg(m, c(\"aictest.trans.aicc.nolog\", \"aictest.trans.aicc.log\"))\n#&gt; aictest.trans.aicc.nolog   aictest.trans.aicc.log \n#&gt;                 4202.960                 4201.042\n\nThis is interesting since the AICc for no transformation is lower than the AICc for log transform.\n\ntransformfunction(m)\n#&gt; [1] \"log\"\n\nThe default value for transform.aicdiff is -2, meaning the program slightly prefers log transform, and the difference between the AICc values must exceed 2. In this situation, the difference between the AICc values is -1.917597. Suppose you were to change this option to transform.aicdiff = 0, then the program selects no transform.\n\nm2 &lt;- seas(grocery, x11 = \"\", transform.aicdiff = 2)\ntransformfunction(m2)\n#&gt; [1] \"none\""
  },
  {
    "objectID": "23-regARIMA.html#sarima-model",
    "href": "23-regARIMA.html#sarima-model",
    "title": "5  regARIMA Model",
    "section": "\n5.1 SARIMA model",
    "text": "5.1 SARIMA model\nAs the name implies, there are two components that one needs to understand when fitting a regARIMA model; namely regression and ARIMA. Furthermore, the ARIMA part is made up by a differencing order and the stochastic ARMA portion. In this chapter, we try to break these three components down to the most fundamental ingredients without an overly technical exposition. Essentially, providing readers with enough information about each topic to understand the rest of this book and go off and perform satisfactory seasonal adjustment. The interested reader is encouraged to find material devoted to each of these components separately to more fully understand them.\nARIMA is an acronym describing the three parts of the modeling paradigm. AR = autoregressive, I = integrated (differenced), and MA = moving average. The prefix auto or “self”, explains the AR portion perfectly. We model the current observation with lagged values from the past. This is illustrated with the classic autoregressive model of order 1:\n\\[ Y_t = \\phi Y_{t-1} + a_t \\]\nwhere \\(Y_t\\) is the observed time series, \\(\\phi\\) is a coefficient to be estimated and \\(\\{a_t\\}\\) is an uncorrelated sequence of errors similar to that of standard linear regression. This model is notated AR(1). If instead of a single lag we used \\(p\\) lags, the model would be and AR(\\(p\\)) and have structure:\n\\[ Y_t = \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + a_t \\]\nwhere now we have \\(p\\) coefficients \\(\\phi_1, \\phi_2, \\ldots, \\phi_p\\) to be estimated.\nThe moving average part of ARIMA model is similar in notation and reflects the number of lagged values of the error sequence should be included. For example, an MA(1) model with coefficient parameter \\(\\theta\\) is:\n\\[ Y_t = a_t + \\theta a_{t-1} \\].\nNote that instead of doing self-regression we include past values of the unobserved errors in the model at time \\(t\\). If instead of a single lag we wanted \\(q\\) lags of the past error terms, we would have an MA(\\(q\\)) model:\n\\[ Y_t = a_t + \\theta_1 a_{t-1} + \\theta_2 a_{t-2} + \\cdots + \\theta_q a_{t-q} \\].\nWhen we combine these two ideas we can model \\(Y_t\\) with \\(p\\) lagged values of itself together with \\(q\\) lagged values of the unobserved errors. Together it makes an ARMA(\\(p\\), \\(q\\)) model, one of the fundamental ingredients to the regARIMA model. For a practitioner the automatic modeling done in X13 is often sufficient to find an appropriate value for \\(p\\) and \\(q\\) and hence a well fitting ARMA model. If it more important from a seasonal adjustment perspective to correctly specify the differencing and regression variables in your overall regARIMA model."
  },
  {
    "objectID": "23-regARIMA.html#differencing",
    "href": "23-regARIMA.html#differencing",
    "title": "5  regARIMA Model",
    "section": "\n5.2 Differencing",
    "text": "5.2 Differencing\nARMA models work best for stationary time series. This means the mean does not depend on time (such as increasing trend) or have a correlation structure that changes. Many techniques could be used to take a non-stationary time series and transform it to stationarity, one ubiquitous method is differencing. There is a famous results that states if you difference your series \\(k\\) times it will remove a polynomial trend of degree \\(k\\). Essentially, if you observe a time series with a linear trend then first differencing will remove the trend. If a time series has quadratic trend (polynomial of order 2) then differencing twice will remove that trend. A similar phenomenon can happen at seasonal lags and often a time series will also require seasonal differencing to reduce it to stationary. The order of differencing, also called the intgreation order, for the non-seaosnal and seasonal parts of our model are usually notated as \\(d\\) and \\(D\\) respectively. When we bring the integration order together with the stocastic model specification we have the notation \\[\\text{SARIMA}\\underbrace{(p, d, q)}_{\\text{non-seasonal }}\\underbrace{(P, D, Q)}_{\\text{seasonal}}.\\] This can be seen easily with an example. Consider the log transformed AirPassengers series.\n\nplot(log(AirPassengers))\n\n\n\n\nWe see a clear increasing trend and seasonal pattern. Let’s call the observed series \\(X_t\\). We can difference the series to make \\(Y_t = \\Delta X_t = X_t - X_{t-1}\\). A plot of \\(Y_t\\) looks like\n\nplot(diff(log(AirPassengers)))\n\n\n\n\nThe trend has been removed however some seasonal trend (strong seasonal patterns) still exist. Apply seasonal differencing to the already first differenced series \\(Y_t\\):\n\\[ Z_t = Y_t - Y_{t-12} \\]\nA plot of \\(Z_t\\):\n\nplot(diff(diff(log(AirPassengers)), 12))\n\n\n\n\nHere we can see that both the original linear trend and seasonal pattern are removed and what is left is a stationary process that can adequately be modeled with an SARMA(0, 1)(0, 1) model. When you bring in the integration (differencing) order of one for the seasonal and non-seasonal components, we are left with the model named after this exact time series! The so called ``airline model’’ is the SARIMA(0, 1, 1)(0, 1, 1) and the terminology came to popularity via Box and Jenkins, “Time Series Analysis, Forecasting and Control” textbook."
  },
  {
    "objectID": "23-regARIMA.html#fitting-sarima-optional",
    "href": "23-regARIMA.html#fitting-sarima-optional",
    "title": "5  regARIMA Model",
    "section": "\n5.3 Fitting SARIMA (optional)",
    "text": "5.3 Fitting SARIMA (optional)\nHere we present a very oversimplied way to start to understand what values of \\(p, P, q\\) and \\(Q\\) you can investigate for your time series of interest. Recall that earlier it was mentioned that using automatic model identification is sufficient for most to get an adequate seasonal adjustment. Hence, this is simply for the interested reader to begin to gain additional intuition into the stochastic structures involved in their series and the types of structures the automatic modeling procedures look at. One of the main tools in a time series analyist tool box is the autocorrelation function (ACF). This is a function that returns the correlation between observations \\(h\\) time units apart throughout the entire sample. So for \\(h=2\\) this means looking at the correlation between the pairs \\((X_1, X_3), (X_2, X_4), (X_3, X_5), \\ldots\\). Then a way to build a SARIMA model is to match the sample ACF and the theoretical ACF of a given model. The main point distinguishing an AR(\\(p\\)) and MA(\\(q\\)) is how their theoretical ACF behaves. An AR(\\(p\\)) will have ACF the has exponential decay as \\(h\\) increases. For example, an AR(1) ACF is \\[\\rho(h) = \\phi^h\\] An MA(\\(q\\)) models ACF will be non-zero for the first \\(q\\) lags and then cutoff to zero thereafter. The ACF of an MA(1) is \\[\\rho(h) = \\begin{cases}\n~~1 & h = 0 \\\\\n\\frac{\\theta}{1 + \\theta^2} & h = 1 \\\\\n~~0 & \\text{otherwise}\n\\end{cases}\n\\] In practice of course the difference between decay and cut-off can be nebulous to detect but the interested reader is encouraged to explore the arima.sim() function the look at the sample ACF with the acf() function. As you increase the sample size it will converge to the theoretical ACF value and you can start to see the structures just discussed.\n\nx_AR &lt;- arima.sim(model = list(ar = .75), n = 300)\nx_MA &lt;- arima.sim(model = list(ma = .75), n = 300)\ntsbox::ts_plot(cbind(x_AR, x_MA))\nop &lt;- par(mfrow = c(1, 2), mar = c(5, 2, 4, 2))\nacf(x_AR, xlab = \"h\", main = \"\"); title(\"ACF of AR(1) model\")\nacf(x_MA, xlab = \"h\", main = \"\"); title(\"ACF of MA(1) model\")\npar &lt;- op"
  },
  {
    "objectID": "23-regARIMA.html#regression",
    "href": "23-regARIMA.html#regression",
    "title": "5  regARIMA Model",
    "section": "\n5.4 Regression",
    "text": "5.4 Regression\nWe have discussed SARIMA modeling (both the SARMA and differencing), now we see how exogenous regression variables come into play.\nThe regARIMA model takes the form \\[ f\\left(\\frac{Y_t}{D_t} \\right) = \\boldsymbol{\\beta}^\\prime {\\mathbf X}_t + Z_t .\\] Here \\(Y_t\\) is the observed time series. The function \\(f\\) represents a transformation, most commonly used is the log transform ie \\(f(x) = \\log(x)\\). \\(D_t\\) is any intervention that has taken place prior to any transformation or modeling. This intervention is usually subjective and customized for individual series on an as-needed basis. For example, if a soybean farmer strike occurred and the soybean export series suffered for its duration. This type of event might adversely affect the seasonal adjustment filters and automatic model identification routines and can be mediated as an initial step. If no transformation or intervention is needed the model form is: \\[ Y_t = \\underbrace{\\boldsymbol{\\beta}^\\prime {\\mathbf X}_t}_{\\text{Regression}} + \\underbrace{Z_t}_{\\text{ARIMA}} .\\]\nThe regression variables appear in the columns of the design matrix \\({\\mathbf X}_t\\) and \\(Z_t\\) is an ARIMA process. This last assumption on \\(Z_t\\) is what distinguished a regARIMA model from more classic linear models and multiple linear regression where error terms are assumed uncorrelated.\nIn order to achieve a suitable seasonal adjustment it is important to get the regARIMA model correct. For most dataset the built in automatic modeling features of the X13 program will be suitable to detect a reasonable model. This can be used as a starting point for more rigorous regARIMA model development or used as the final regARIMA modeling choice for your seasonal adjustment needs. We evoke automatic model identification through the XXX spec. The default behavior of the R seasonal package is XXX which includes automatic model identification.\n\n\n\n\n\n\nAutomatic and manual model choice\n\n\n\nAs an aside, the general rule is to not use automatic modeling in production. This mean, if you are going to include seasonal adjustment as part of a large scale data processing that occurs regularly (say monthly), then it is not advisable to have automatic model identification run every month. Instead, an alternative process, is to run automodel once and then fix the model choice in the XXX spec file. This does not need to be done manually since the static() function from the seasonal package can do this for you.\n\n\n\n\nOutlier Type\nAutomatic Detection Available?\n\n\n\nAdditive outliers (AO)\nYes (default)\n\n\nLevel shifts (LS)\nYes (default)\n\n\nTemporary level shifts (TL)\nYes\n\n\nTemporary changes (TC)\nNo\n\n\nRamps (RP, QI, QD)\nNo\n\n\nSeasonal outliers (SO)\nNo"
  },
  {
    "objectID": "23-regARIMA.html#case-study-airpassengers",
    "href": "23-regARIMA.html#case-study-airpassengers",
    "title": "5  regARIMA Model",
    "section": "\n5.5 Case Study: AirPassengers",
    "text": "5.5 Case Study: AirPassengers\nConsider the default seasonal adjustment:\n\nlibrary(seasonal)\nm &lt;- seasonal::seas(AirPassengers, x11 = \"\")\nprint(m$spc$automdl)\n#&gt; $print\n#&gt; [1] \"bestfivemdl\"\nprint(m$spc$arima)\n#&gt; NULL\n\nNotice the value NULL indicates no ARIMA model is specified and the returned arguments for the automdl spec indicate it is active during the X13 run.\n\nseasonal::udg(m, \"automdl\")\n#&gt;          automdl \n#&gt; \"(0 1 1)(0 1 1)\"\n\nIndicates that automatic modeling identified the (0 1 1)(0 1 1) model as the best choice. If we want to hardcode this model for subsequent runs, and turn off automatic model identification, this can be done via\n\nm_call &lt;- seasonal::static(m)\n#&gt; seas(\n#&gt;   x = AirPassengers,\n#&gt;   x11 = \"\",\n#&gt;   regression.variables = c(\"td1coef\", \"easter[1]\", \"ao1951.May\"),\n#&gt;   arima.model = \"(0 1 1)(0 1 1)\",\n#&gt;   regression.aictest = NULL,\n#&gt;   outlier = NULL,\n#&gt;   transform.function = \"log\"\n#&gt; )\nm2 &lt;- eval(m_call)\n\nThere are many options you can modify when searching for outliers in your series. Some of the most practical options to start your exploration are the type, critical value and span that you would like to search.\nHere is an example of using span to limit the outlier search to the last few years of a series:\n\nm_span &lt;- seas(AirPassengers,\n  outlier.types = c(\"ao\", \"ls\", \"tc\"),\n  outlier.critical = 4.0,\n  outlier.span = \"1958.jan, \")\nsummary(m_span)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier.types = c(\"ao\", \"ls\", \"tc\"), \n#&gt;     outlier.critical = 4, outlier.span = \"1958.jan, \")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.002644   0.000604  -4.377 1.20e-05 ***\n#&gt; Easter[1]          0.021321   0.008395   2.540  0.01110 *  \n#&gt; MA-Nonseasonal-01  0.235404   0.083756   2.811  0.00495 ** \n#&gt; MA-Seasonal-12     0.543743   0.074644   7.284 3.23e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 965.3, BIC: 979.2  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.26   Shapiro (normality): 0.9829 .\n\n\nm_nospan &lt;- seas(AirPassengers,\n  outlier.types = c(\"ao\", \"ls\", \"tc\"),\n  outlier.critical = 4.0)\nsummary(m_nospan)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier.types = c(\"ao\", \"ls\", \"tc\"), \n#&gt;     outlier.critical = 4)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe default critical value is set based on the length of the outlier span. Notice the MA-Nonseasonal-01 value when comparing m_span with m_nospan. We see the choice of span, and ultimately the choise to include an outlier in your model can have a dramatic effect on the estimated regARIMA parameters."
  },
  {
    "objectID": "24-x11.html#sec-seasonal-decomposition",
    "href": "24-x11.html#sec-seasonal-decomposition",
    "title": "6  X-11",
    "section": "\n6.1 Seasonal decomposition",
    "text": "6.1 Seasonal decomposition\nAs we have seen in the previous chapters, the core of seasonal adjustment is the decomposition of a time series into a trend, a seasonal and and irregular component. As we have seen in Section 4.2, we write the fundamental identity as:\n\\[\nX_t = T_t + S_t + I_t\n\\]\nwhere, \\(X_t\\) is the observed time series, \\(T_t\\) the trend, \\(S_t\\) the seasonal component and \\(I_t\\) the irregular component. Once the decomposition is done, the seasonally adjusted series for an additive1 decomposition can be computed as:\nFor a multiplicative decomposition, the fundamental identity is\n\\[\nX_t = T_t \\cdot S_t \\cdot I_t\n\\]\nand the adjusted series is:\n\\[\nA_t = \\frac{X_t}{S_t}\n\\]\n\n\\[\nA_t = X_t - S_t\n\\]\nHow to perform the seasonal decomposition? Ultimately, both X-11 and SEATS estimate the components \\(T_t\\), \\(S_t\\), \\(I_t\\) by passing moving average filters over the series. In order to get unbiased results at the margin, the underlying series is usually extended by forecasts from the regARIMA model discussed in the Chapter 5. This regARIMA model also serves as the foundation of the initial steps in the X11 algorithm to remove outliers and other regression effects before application of moving-averages.\nHow do we apply moving average filters over a series? The trend component can be estimated by applying a moving average over the observed series. For each point in time, an simple average that uses a certain number of observations both on the left and the right of the series. Because the window is symmetric, we need the series extended by forecasts and backcasts.\nOnce the trend component is computed, we can subtract it from the original series to compute a detrended series."
  },
  {
    "objectID": "24-x11.html#sec-simple-decomposition",
    "href": "24-x11.html#sec-simple-decomposition",
    "title": "6  X-11",
    "section": "\n6.2 A simple decomposition in R",
    "text": "6.2 A simple decomposition in R\nIn order to better understand the X-11 method, it will be helpful to first perform a basic seasonal adjustment procedure “by-hand”. A basic trend filter could be a simple 2x12 moving average. This filter has weights 1/24, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/12, 1/24. We use these weights to estimate the trend of the AirPassengers series.\n\nobserved &lt;- AirPassengers         \nfilter_trend = c(1/24, rep(1/12, 11), 1/24)     \ntrend = stats::filter(observed, filter = filter_trend, sides = 2)\ntsbox::ts_plot(observed, trend)\n\n\n\n\nAfter estimating the trend we now can estimate the seasonal component of the detrended series using a 3x3 seasonal filter that has weights (1,2,3,2,1)/9 applied to the same season.\n\ndetrended &lt;- observed - trend\nfilter_seas = c(1, rep(0, 11), 2, rep(0, 11), 3, rep(0, 11), 2, rep(0, 11), 1) / 9\nseasonal = stats::filter(detrended, filter = filter_seas, sides = 2)\ntsbox::ts_plot(detrended, seasonal)\n\n\n\n\nBy subtracting this seasonal estimate we have our crude seasonal adjustment.\n\nadjusted = observed - seasonal\ntsbox::ts_plot(observed, adjusted)\n\n\n\n\nThis basic seasonal adjustment is a useful tool to understand other features of X-13. The most obvious thing we see in this plot is the last of seasonal adjustment at the ends of the series. Hence, why we need to use regARIMA modeling to forecast extend. Additionally, we see some obvious flaws this this adjustment. It is difficult to estimate a trend in the presence of seasonality. Similarly, it is difficult to estimate the seasonal factors when the trend is poorly estimated/removed.\nThis motivates the X-11 method which is an iterative application of this simple procedure we have just performed. Each subsequent iteration allows the estimated components to be refined by selecting better filters and handling extreme values and regression effects. The first adaptation is to consider a transformation of our series from AirPassengers to log(AirPassengers). Our simple example performed an additive seasonal adjustment. This transformation will require a move to a multiplicative decomposition."
  },
  {
    "objectID": "24-x11.html#x-11-adjustment",
    "href": "24-x11.html#x-11-adjustment",
    "title": "6  X-11",
    "section": "\n6.3 X-11 Adjustment",
    "text": "6.3 X-11 Adjustment\nIn order to use symmetric moving average filters at the end of the time series (current value), a regARIMA model is used to forecast extend the series. This regARIMA model is where users can test for or specify outliers, trading day and moving holiday regressors in their adjustment. The forecast extended series is then used to filter.\nAdditionally, X-11 has a built in extreme value procedure included. This procedure identifies extremes and replaces. This results in a robust procedure that can automatically choose filters and identify extreme values without much user intervention. All that needs to be evoked beyond the default seas() call is to turn on the X11 spec option.\n\nm &lt;- seas(AirPassengers, x11 = \"\")\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, x11 = \"\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - Visually significant seasonal and trading day peaks have\n#&gt;   been found in one or more of the estimated spectra.\n\nBefore further discussion about the details of the X-11 process, let us see what happened during this modeling run. A variant of the simple decomposition performed in Section Section 6.2 is run 3 times along with a pre-processing step to fit a regARIMA model. This procedure can be seen in great detail in Ladiray and Quenneville (2012). The overview of each step:\n\nLadiray, Dominique, and Benoit Quenneville. 2012. Seasonal Adjustment with the x-11 Method. Vol. 158. Springer Science & Business Media.\n\nPart A\n\nPrior adjustments including regARIMA modeling of outliers, trading day and moving holiday effects.\n\nPart B\n\nFirst application of seasonal decomposition. Calculate initial extreme value weights.\n\nPart C\n\nSecond estimation of seasonal and trend. Final estimation of extreme value weights.\n\nPart D\n\nFinal estimation of seasonally adjusted series, seasonal factors, trend, irregular. Combined factors incorporate the trading day and moving holiday regression effects estimated in Part A\n\n\n\n\n\n\n\n\nOutliers and Extreme values\n\n\n\nWe will discuss extreme values and outliers in more detail in Chapter 10.\nThe terms outlier and extreme value seem interchangeable. In X-13, these refer to very different types of effects. An outlier is identified by the regARIMA model in Part A of the X-11 method. An extreme value is a value that is large enough to effect the results of a moving-average filter but is not identified by the regARIMA automatic modeling identification. Outliers are prior-adjusted out of the series while extreme values are replaced within the X-11 procedure.\nBoth types end up in the seasonally adjusted series. Extreme values are assigned to the irregular component and are hence included in the seasonally adjusted series. Outliers get included in Part D when X-11 calculates the final seasonal factors using the original series including outlier effects.\n\n\nDuring these steps the trend filter is automatically chosen based the noise-to-signal ratios, labeled I/C in the output file. The seasonal moving average is determined by the Global Moving Seasonality Ratio (GMSR). Being able to understand the\nWhen using the x11 spec you can change the length of the filter used for the trend and seasonal components with the trendma and seasonalma arguments respectively. Additionally, sigmalim will control the amount of extreme value adjustment that is done during the seasonal adjustment."
  },
  {
    "objectID": "24-x11.html#frequency-domain-of-time-series-optional",
    "href": "24-x11.html#frequency-domain-of-time-series-optional",
    "title": "6  X-11",
    "section": "\n6.4 Frequency domain of time series (optional)",
    "text": "6.4 Frequency domain of time series (optional)\nWe present the following as optional reading material. For those interesting in simply performing seasonal adjustment, an understanding of the frequency domain of a time series, is not mandatory. However, the spectral domain representation will help the interested reader further understand the impact a linear filter has on a time series. Since both X-11 and SEATS use linear filters this will deepen the users understanding of whichever seasonal adjustment procedure is chosen.\nSeasonal adjustment is highly motivated by the study, estimation, and ultimately removal of regular fluctuations in a time series. The words regular fluctuations immediately leads us to trigonometric functions sine and cosine. It turns out, there exist two equivalent representations of a time series. The first, and usually easier for beginners to understand, is the time domain representation. This is expressing how \\(X_t\\) evolves as time \\(t\\) evolves. For example, an MA(1) time domain representation:\n\\[X_t = w_t + \\theta w_{t-1}\\]\nThe second, is a frequency domain representation of a series. Here, \\(X_t\\) is represented as the sum of trigonometric functions. More specifically, the spectral density of \\(X_t\\) is the fourier transform of the acf of the series. \\[f_X(\\nu) = \\sum_{h = - \\infty}^{\\infty} \\gamma(h) e^{-2\\pi i \\nu h}\\] For example, the spectral density of an MA(1) is: \\[f_X(\\nu) = \\sigma^2 \\left( 1 + \\theta^2 + 2\\theta\\cos(2\\pi\\nu) \\right)\\]\nThe important concept here is to understand that these representations are equivalent; meaning they contain the same information about a time series, such as encoding the acf function.\n\n\n\n\n\n\nWhere does the term “White Noise” come from?\n\n\n\nThe spectral density of an uncorrelated sequence with variance \\(\\sigma^2\\) is simply \\(f(\\nu) = \\sigma^2\\). Notice this is not a function of any frequencies but just a constant for any \\(\\nu\\). Hence, it is a stochastic process that equally weight all frequencies in the spectrum. This is precisely where the names white noise comes from as white light has the same property of reflecting all color bands equally, combining to produce white light.\n\n\nNow that we know we can express a time series either in the time domain or as a sum of sin and cosine curves, we get to the important part for seasonal adjustment - how does a linear filter effect the input series? Assume we want to pass a moving-average linear filter over our data \\(X_t\\) with weights \\(\\ldots, w_{-2}, w_{-1}, w_{0}, w_{1}, w_{2}, \\ldots\\). Assume the output of the linear filter will be \\(Y_t\\) such that \\[Y_t = \\sum_{j = -\\infty}^{\\infty} w_j X_{t+j} =\n\\ldots + w_{-2}X_{t-2} + w_{-1}X_{t-1} +  w_{0}X_{t} + w_{1}X_{t+1} + w_{2}X_{t+2} + \\ldots\\] This type of linear filter can be expressed as a linear operator in terms of the backshift operator \\(B\\) , where \\(BX_t = X_{t-1}\\) and \\(B^{-1}X_t = X_{t+1}\\). \\[W(B) = \\ldots + w_{-2}B^2 + w_{-1}B +  w_{0} + w_{1}B^{-1} + w_{2}B^{-2} + \\ldots\\] and hence \\(Y_t = W(B)X_t\\). We can now express the spectral density of \\(Y_t\\) in terms of the input spectral density \\(X_t\\). \\[f_Y(\\nu) = \\underbrace{\\lvert W(e^{2\\pi i \\nu}) \\rvert^2}_{\\text{Square Gain Function}} f_X(\\nu)\\]\nThere is some mathematical machinery needed when understanding exactly what the square-gain function, \\(\\lvert W(e^{2\\pi i \\nu}) \\rvert^2\\), is. However, for the sake of this text we just know that it tells us exactly the frequencies of \\(X_t\\) that amplified in the output \\(Y_t\\) as well as the frequencies of \\(X_t\\) that will be annihilated (when the square-gain function equals 0).\nLet’s look at an example spectrum for the airline model. Instead of deriving the result, the following code simulates observations from an airline model with \\(\\theta = .5\\) and \\(\\Theta = .9\\). The spectrum is then estimated using a parametric estimator using the spec.ar function. Details of this estimation can be found in (Brockwell and Davis).\n\nlibrary(forecast)\n#&gt; Registered S3 method overwritten by 'quantmod':\n#&gt;   method            from\n#&gt;   as.zoo.data.frame zoo\nset.seed(123)\nmodel &lt;- Arima(y = ts(rnorm(1000),freq=12), \n               order=c(0,1,1), \n               seasonal=c(0,1,1),\n               fixed=c(theta=-0.5, Theta=-0.9))\nx &lt;- simulate(model, nsim=10000)\nfx = spec.ar(x, order = 36, plot = TRUE)\n\n# Pass a trend filter over data\nx_trend = stats::filter(x, filter = filter_trend, sides = 2)\nfx_trend = spec.ar(x_trend, na.action = na.pass)\n\n# Remove trend to leave seasonal + irregular\nx_seasonal = x - x_trend\nfx_seasonal = spec.ar(x_seasonal, na.action = na.pass)"
  },
  {
    "objectID": "24-x11.html#x-11-moving-average-filters",
    "href": "24-x11.html#x-11-moving-average-filters",
    "title": "6  X-11",
    "section": "\n6.5 X-11 Moving average filters",
    "text": "6.5 X-11 Moving average filters\nWe introduce the moving average filters and subsequently plot the filter weights along with the values of the squared gain function. The X-11 spec also allows users to control the length of the trend and seasonal moving average filters used during the adjustment. Generally speaking, longer filters imply a more stable seasonal component and shorter filters a more changing seasonal pattern. Of course, a longer filter will use more data for the calculation of components at each time point. This is an important observation and understanding it might help a user decide on a short or long filter. Since longer filters use more data there tend to be smaller revisions when a new data point is added. However, there will be revisions to data values further back.\nA shorter filter is just the opposite, they tend to produce larger revisions but they do not extend as far back into the series. If a filter is not choosen by the user then automatic filter selection is used. To understand the length of a filter let’s look at the (finite) number of choice available in during an x11 adjustment. Table 6.1 shows the different filters available for the seasonal component and the trend component.\n\n\nTable 6.1: Filters available in X11\n\n\n\n\n\nValue\nDescription\n\n\n\ns3x1\n3×1 moving average\n\n\ns3x3\n3×3 moving average\n\n\ns3x5\n3×5 moving average\n\n\ns3x9\n3×9 moving average\n\n\ns3x15\n3×15 moving average\n\n\nstable\nStable seasonal filter. A single seasonal factor for each calendar month or quarter is generated by calculating the simple average of all the values for each month or quarter (taken after detrending and outlier adjustment).\n\n\nx11default\nA 3×3 moving average is used to calculate the initial seasonal factors in each iteration, and a 3×5 moving average to calculate the final seasonal factors."
  },
  {
    "objectID": "24-x11.html#extreme-value",
    "href": "24-x11.html#extreme-value",
    "title": "6  X-11",
    "section": "\n6.6 Extreme value",
    "text": "6.6 Extreme value\nThe X11 method is sensitive to outliers. Beyond the specified regressors (AOs, level shifts, temporary changes, etc), an X11 adjustment will replace extreme values after the initial crude trend estimation occurs in the first iteration of the X11 method. The replacement procedure looks as follows:\n\n\n\n\nflowchart LR\n    A(  Estimate standard deviation &lt;br&gt; of irregular, s  )--&gt;B(Compare SI-ration to &lt;br&gt; multiples of s)\n    B--&gt;C(SI &lt; 1.5 * s)\n    B--&gt;D(1.5 * s &lt; SI &lt; 2.5 * s)\n    B--&gt;E(SI &gt; 2.5 * s)\n    C --&gt; F(SI unchanged)\n    D --&gt; G(SI linearly weighted)\n    E --&gt; H(SI fully weighted)\n\n\nFigure 6.1: Default behavior of Extreme value replacement procedure.\n\n\n\nUsers can change the multiples of \\(\\sigma\\) that are converted to extreme values. This is done with the sigmalim option within the x11 spec. This option should be a vector of length 2 that specifies when weighting should begin and when full weight of zero should be applied. Between the endpoints of the specified vector a linear weight will be applied. SI ratios are replaced with an average of the two nearest SI ratios from the same month/quarter. One caveat being that only fully weighted SI ratios are used for SI ratio replacement. Hence, if too small of a \\(\\sigma\\) limit is used the SI ratios used to replace an extreme value should be many years away.\n\nm = seas(AirPassengers, x11 = \"\")\nunmodified_SIratio &lt;- series(m, \"d8\")\nmodified_SIratio   &lt;- series(m, \"d9\")\nseasonal_factors &lt;- series(m, \"d10\")\ntsbox::ts_dygraphs(cbind(unmodified_SIratio, modified_SIratio, seasonal_factors))\n\n\n\n\n\n\nm = seas(AirPassengers, x11 = \"\", x11.sigmalim = c(1, 2))\nunmodified_SIratio &lt;- series(m, \"d8\")\nmodified_SIratio   &lt;- series(m, \"d9\")\nseasonal_factors &lt;- series(m, \"d10\")\ntsbox::ts_dygraphs(cbind(unmodified_SIratio, modified_SIratio, seasonal_factors))\n\n\n\n\n\nIt should be noted that extreme value choices can greatly affect the seasonal adjustment.\n\n\n\n\n\n\nSI ratio / SI difference\n\n\n\nIn a multiplicative adjustment, the detrended series is called the SI ratio. It is an estimate of the seasonal component. The SI ratio is used to identify extreme values during the initial and intermediate steps of the X-11 method."
  },
  {
    "objectID": "24-x11.html#additive-and-multiplicative-again",
    "href": "24-x11.html#additive-and-multiplicative-again",
    "title": "6  X-11",
    "section": "\n6.7 Additive and multiplicative (again)",
    "text": "6.7 Additive and multiplicative (again)\nThe X-13ARIMA-SEATS development was highly motivated to study economic time series. As such, the default seasonal adjustment mode is multiplicative due to most seasonal economic time series displaying seasonal fluctuations that increase and decrease along with the level of the time series.\nIf your series does not have this feature then additive adjustment might be more appropriate. This can be changed in the mode argument of the x11 spec. For example, seas(x, x11.mode = 'add') will perform an additive x11 run. There exist two other models for decomposition, pseudo-additive and log additive. These are less common than additive and multiplicative models and are not the focus of this text. If your series has some extremely small values in certain months (quarters) then pseudo-additive models could be worth further investigation. It has been observed that when multiplicative seasonal adjustment produces more extreme values in conjunction with small seasonal factors then pseudo-additive adjustment should be explored."
  },
  {
    "objectID": "24-x11.html#case-study",
    "href": "24-x11.html#case-study",
    "title": "6  X-11",
    "section": "\n6.8 Case study",
    "text": "6.8 Case study\n\n\ntsbox::ts_plot(\n  s3x1 = predict(seas(AirPassengers, x11.seasonalma = \"s3x1\")),\n  s3x15 = predict(seas(AirPassengers, x11.seasonalma = \"s3x15\"))\n)"
  },
  {
    "objectID": "24-x11.html#points-to-include-in-chapter",
    "href": "24-x11.html#points-to-include-in-chapter",
    "title": "6  X-11",
    "section": "\n6.9 Points to include in Chapter",
    "text": "6.9 Points to include in Chapter\n\nLevel shifts are included with the trend component while AOs and extreme values are included in the irregular.\nChanging filters can affect which values are extreme\nChanging sigma limits changes the extreme values and can affect what filter seems most appropriate\n\nExperiment with changing filters and sigma limits for your series to see the results"
  },
  {
    "objectID": "25-seats.html#model-based-decomposition",
    "href": "25-seats.html#model-based-decomposition",
    "title": "7  SEATS",
    "section": "\n7.1 Model based decomposition",
    "text": "7.1 Model based decomposition\nSignal Extraction in ARIMA Time Series, or SEATS, is a method for estimating unobserved components in a time series. It is developed from the work of Cleveland and Tiao (1976), Hillmer and Tiao (1982), Maravall (1986). If applied properly, SEATS seasonal factors are usually more stable than X-11, and the seasonally adjusted series show less revisions than X11 (see Section 7.10 for a more extensive discussion).\n\nCleveland, William P, and George C Tiao. 1976. “Decomposition of Seasonal Time Series: A Model for the Census x-11 Program.” Journal of the American Statistical Association 71 (355): 581–87.\n\nHillmer, S. C., and G. C. Tiao. 1982. “An ARIMA-Model-Based Approach to Seasonal Adjustment.” Journal of the American Statistical Association 77 (377): 63–70. http://www.jstor.org/stable/2287770.\n\nMaravall, Agustin. 1986. “Revisions in ARIMA Signal Extraction.” Journal of the American Statistical Association 81 (395): 736–40. http://www.jstor.org/stable/2289005.\nLike X-11, SEATS applies a series of filters to an observed time series, as described in Section 6.1. Like X-11, SEATS uses a forecast extended series, in order to obtain unbiased results at the margin.\nUnlike X-11, however, SEATS filters are derived from the ARIMA model of the time series. While X-11 filters are predefined and fixed, the SEATS filters are different for each ARIMA model.\nWhile X-11 offers a finite set of filters (in fact, there are seven seasonal filters available), SEATS offers an infinite set of filters. Overall, they cover a broader set of possible filter lengths, which makes SEATS a more flexible option than X-11. The available set filter lengths is the most crucial difference between X-11 and SEATS. At the same time, the additional flexibility may lead at times to filters that are undesirable. As will be shown later on, SEATS sometimes choose a filter that is too narrow, and produces an overly volatile seasonal component.\n\n\n\n\n\n\nComparing X-11 and SEATS filters\n\n\n\nX-11 filters\n\nfinite set of empirically developed moving average filters\nfixed filtering seen as easier to use (less statistical machinery)\nSEATS filters\n\nspecifies stochastic models for unobserved components\nderives seasonal adjustment filters from these models\ninfinite number of possible filter choices\nrequires more statistical machinery\n\n\n\n\n\n\n\n\n\nTODO\n\n\n\nPlots of X-11 filters vs SEATS filters\n\n\nGiven a certain ARIMA model (such as the “Airline” (0 1 1)(0 1 1) model which is appropriate for the description of the AirPassengers time series), SEATS decomposes the model into separate models for the trend, the seasonal and the irregular component. This is done by the Canonical Decomposition and will be discussed in Section 7.6.\nThe decomposition of the ARIMA model is almost independent of the data. For each ARIMA specification, there is a unique canonical decomposition. For a normal “Airline” (0 1 1)(0 1 1) model (with both moving average coefficients not being to close to 1), the trend component can be described with a (0 2 2)(0 0 0) model, while the seasonal component can be described approximately by a (0 0 11)(0 0 0) model. The parameters of these models can be derived from the parameter estimations of the initial airline model that describes the original series. The irregular component is usually white noise, described by the trivial (0 0 0)(0 0 0) model.\nThe decomposed ARIMA models imply a certain filter, which is derived by the Wiener-Kolmogorov procedure (Section 7.7)."
  },
  {
    "objectID": "25-seats.html#comparing-seats-with-x-11-filters",
    "href": "25-seats.html#comparing-seats-with-x-11-filters",
    "title": "7  SEATS",
    "section": "\n7.2 Comparing SEATS with X-11 filters",
    "text": "7.2 Comparing SEATS with X-11 filters\nIf SEATS and X-11 use similar filters, the final adjustment will be similar. Using the default arguments of seas() on AirPassengers, the adjustment is very similar:\n\nseats &lt;- seas(AirPassengers)\nx11 &lt;- seas(AirPassengers, x11 = list())\ntsbox::ts_plot(final(seats), final(x11))\n\n\n\n\nOthers have looked at comparing SEATS and X-11 filters. In Planas and Depoutot (2002) they show with X11 seasonal filter that is closest to an implied (0 1 1)(0 1 1) “Airline” SEATS model based on the \\(\\Theta_{12}\\). As a reminder, \\(\\Theta_{12}\\) refers to the moving average parameter of the seasonal difference in the ARIMA model.\n\nPlanas, Christophe, and Raoul Depoutot. 2002. “Controlling Revisions in Arima-Model-Based Seasonal Adjustment.” Journal of Time Series Analysis 23 (2): 193–213.\n\n\nFilter\nClosest Seasonal MA\nSeasonal MA Interval\n\n\n\n3x3\n0.364 - 0.400\n0.0 - 0.5\n\n\n3x5\n0.543 - 0.563\n0.51 - 0.74\n\n\n3x9\n0.723 - 0.732\n0.75 - 0.87\n\n\n3x15\n0.824 - 0.828\n0.88 - 1.00\n\n\n\nLet’s consider small vs large values of seasonal \\(\\Theta_{12}\\). Values of \\(\\Theta\\) close to zero yield a seasonal adjustment filter that has seasonal factors that change rapidly over time. This provides considerable smoothing and large revisions. These revisions will only last for a small number of years due to the shorter filters.\nValues of \\(\\Theta\\) close to one yield a seasonal adjustment filter that has seasonal factors that change slowly over time. This provides less smoothing but relatively small revisions. Any revisions that do occur will last for a longer period of time due to the longer filters.\nOverall, we may think of SEATS filters as a broader, more flexible set of filters than X-11 filers. While we have just seven filters in X-11, we have an infite numer of filters in SEATS. They cover a larger range of filters spans, ranging from filters that are much narrower than X-11 to filters that are much wider.\nSEATS greatest stength is also its greatest weakness. As we will see in the example below, SEATS sometimes chooses a filter that is very narrow. From a SEATS perspective, this makes sense: Given an ARIMA model with a very weak seasonality, the filter lengths should be chooses narrowly. From a practical perspective, the resulting seasonal component is undesirable. It is too volatile, essentially catching much of the irregular component and making the resulting seasonally adjusted series too smooth.\nAdditionally, the filters that are"
  },
  {
    "objectID": "25-seats.html#transitory-component",
    "href": "25-seats.html#transitory-component",
    "title": "7  SEATS",
    "section": "\n7.3 Transitory component",
    "text": "7.3 Transitory component\nSometimes SEATS includes a transitory component in its decomposition:\n\\[ X_t = T_t + S_t + R_t + I_t \\]\nThe transitory component captures short, erratic behavior that is not white noise, sometimes associated with awkward frequencies.\n\nThe variation from the transitory component should not contaminate the trend or seasonal, and removing it allows SEATS to obtain smoother, more stable trends and seasonal components.\nIn the final decomposition, the transitory and irregular components are usually combined.\nSEATS does not always estimate a transitory component"
  },
  {
    "objectID": "25-seats.html#quick-refresher-on-arima-models-and-notation",
    "href": "25-seats.html#quick-refresher-on-arima-models-and-notation",
    "title": "7  SEATS",
    "section": "\n7.4 Quick refresher on ARIMA models and notation",
    "text": "7.4 Quick refresher on ARIMA models and notation\nThe remaining of the SEATS section will heavily rely on the auto-regressive and moving-average operators \\(\\phi(B)\\) and \\(\\theta(B)\\) where \\(B X_t = X_{t-1}\\).\nIf \\(X_t\\) follows and ARIMA(\\(p\\), \\(d\\), \\(q\\)) model: \\[\n\\phi(B) X_t = \\theta(B) a_t\n\\]\n\\[\n(1 - \\phi_1 B - \\cdots - \\phi_p B^p)(1-B)^d X_t = (1 + \\theta_1 B + \\cdots \\theta_q B^q) a_t\n\\]\nFor example, in an ARIMA(2,0,1) we are modeling \\(X_t\\) as:\n\\[\nX_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + a_t + \\theta_1 a_{t-1}\n\\]\nand all model information is contained in \\(\\phi(B)\\) and \\(\\theta(B)\\). Moreover, for any specified \\(\\phi(B)\\) and \\(\\theta(B)\\) that satisfy certain causality criteria there exists a unique Wold decomposition \\[\n\\phi(B) X_t = \\theta(B) a_t  \n\\]\n\\[\nX_t = \\frac{\\theta(B)}{\\phi(B)} a_t = \\Psi(B) a_t = \\sum_{k=0}^{\\infty} \\psi_k a_{t-k}\n\\]"
  },
  {
    "objectID": "25-seats.html#seats-assumptions",
    "href": "25-seats.html#seats-assumptions",
    "title": "7  SEATS",
    "section": "\n7.5 SEATS Assumptions",
    "text": "7.5 SEATS Assumptions\n\nThe linearized series can be represented by an ARIMA model which captures the stochastic structure of the series. As a reminder, the linearized series is the series with regression effects removed.\nAfter differencing each with the ARIMA’s differencing polynomial, the components are orthogonal (uncorrelated)\n\nSEATS decomposes the auto-regressive polynomial by its roots associating them with different latent components. For example, roots near seasonal frequencies are associated with the seasonal component and roots near zero are associated with the trend component. \\[\n\\phi(B) = \\phi_T(B) \\cdot \\phi_S(B) \\cdot \\phi_R(B).\n\\]\nHence we have, \\[\nX_t =\n\\frac{\\theta(B)}{\\phi(B)} a_{t} =\n\\frac{\\theta_T(B)}{\\phi_T(B)} a_{T,t} +\n\\frac{\\theta_S(B)}{\\phi_S(B)} a_{S,t}  +\n\\frac{\\theta_R(B)}{\\phi_R(B)} a_{R,t}  + u_t\n\\]\nIf the spectra of all components in non-negative the decomposition is admissible, SEATS finds admissible models for components \\[ \\phi_T(B) T_t = \\theta_T(B) a_{T, t} \\] \\[ \\phi_S(B) S_t = \\theta_S(B) a_{S, t} \\] \\[\\phi_R(B) R_t = \\theta_R(B) a_{R, t} \\]"
  },
  {
    "objectID": "25-seats.html#sec-canonical-decomposition",
    "href": "25-seats.html#sec-canonical-decomposition",
    "title": "7  SEATS",
    "section": "\n7.6 Canonical Decomposition",
    "text": "7.6 Canonical Decomposition\nHowever, there infinite number of models that yield the same aggregate. The choices differ in how white noise is allocated among the components. This is where the Canonical Decomposition comes into play. SEATS uses the method of Pierce, Box-Hillmer, Tiao and Burman:\n\nPut all the white noise into the irregular components\nMaximize the variance of the irregular\nMinimizes the variance of the stationary transforms of the other components\n\nThis is called the Canonical Decomposition. We already stated that both X-11 and SEATS estimate the unobserved components by passing a moving-average filter over the observed data. So how do we use these implied component models to get a linear filter? It should be clear that the filter weights will depend on that arima model is picked \\(X_t = \\Psi(B) a_t\\), and what the implied seasonal model, \\(\\phi_S(B) S_t = \\theta_S(B) a_{S,t} \\Rightarrow S_t = \\Psi(B) a_t\\), is."
  },
  {
    "objectID": "25-seats.html#sec-wiener-kolmogorov-algorithm",
    "href": "25-seats.html#sec-wiener-kolmogorov-algorithm",
    "title": "7  SEATS",
    "section": "\n7.7 Wiener-Kolmogorov Algorithm",
    "text": "7.7 Wiener-Kolmogorov Algorithm\nThe Wiener-Kolmogorov (WK) algorithm outlines the methodology to get the so-called WK filter. This is the filter that is equal to the conditional expectation of the seasonal component conditional on the observed series.\n\\[\\widehat{S}_t = \\underbrace{\\left[ \\frac{\\Sigma_S}{\\Sigma} \\frac{\\Psi_S(B)\\Psi_S(F)}{\\Psi(B)\\Psi(F)} \\right]}_{\\mbox{WK filter weights}} X_t\\] where \\(F=B^{-1}\\) if the forward shift operator such that \\(F X_t = X_{t+1}\\).\nMore than other coefficients, the seasonal MA (\\(\\theta_{12}\\)) influences whether estimated seasonal factors change either slowly over time (\\(\\theta_{12}\\) close to 1) or rapidly over time (\\(\\theta_{12}\\) close to zero)."
  },
  {
    "objectID": "25-seats.html#example-seats-adjustment",
    "href": "25-seats.html#example-seats-adjustment",
    "title": "7  SEATS",
    "section": "\n7.8 Example SEATS adjustment",
    "text": "7.8 Example SEATS adjustment\nLet’s have a look at nominal taxes from Swiss production account, previously discussed here. (added some minutes ago, to be discussed in class).\nThe series looks as follows:\n\ntax_n &lt;- ts(c(5512.43723529998, 5302.66127551312, 5637.04650218708, 5407.75865307982, 5254.75041765537, 5883.31044127543, 5465.12983546186, 5296.83011638733, 5577.28917595672, 5634.79857930988, 5832.41514259211, 5640.32968921129, 6066.78258591999, 6222.68082980585, 6504.17063502564, 6074.99091524851, 6580.71692950301, 6274.60948561261, 7157.60005559455, 6944.58546551983, 7448.63554376696, 6976.09702323069, 7818.38121589548, 7289.71620307687, 7768.40193169586, 6942.77891782026, 7578.22907029965, 7077.70301249423, 7410.68364011917, 6927.73248230177, 7087.72613485434, 6926.90090299472, 7336.73867165469, 7108.4949497024, 7145.42480380572, 7154.30815153718, 7498.01519467561, 7559.01824893372, 7156.60513953808, 7639.02255770258, 7569.94029094276, 7515.34158790891, 7732.93688269533, 7551.953334793, 8197.88127458863, 7939.93851007643, 8141.79136494712, 7568.40068251781, 8499.84629558006, 8345.25921525785, 8386.38082590207, 7886.29186614002, 8821.87792569236, 8595.73223990369, 8637.63939154854, 7991.04698685541, 8464.50040108557, 8003.27264004253, 8399.90637539542, 8384.22143621648, 8784.63271925264, 8595.77482962329, 8591.67855177336, 8602.6019974407, 8966.1740189959, 8993.28779502417, 8839.41351045546, 8468.69899389445, 9221.6367572731, 8801.73025651442, 8426.53923852333, 8661.00570414916, 8930.21895672981, 9116.66536122397, 8794.81591614758, 8559.38402031864, 9056.19152051174, 8842.45736626125, 9043.08264307781, 8549.5389771392, 8980.20969432594, 8893.75993928538, 9010.28560160679, 8664.05904218189, 8765.47235867103, 9170.15544669832, 8970.77030836517, 8310.62969865549, 9180.42069018707, 8566.35919301958, 9497.27766001259, 9012.51934200076, 8454.34333463005, 9357.61750287723, 9190.28660347765, 9060.07897285508, 9253.43694298711, 8809.60616470625, 8825.87955511076, 9047.15212801588, 9255.87581159138, 8423.29760776073), start = c(1995, 1), frequency = 4)\n\n# static(seas(tax_n))\n\nm &lt;- seas(\n  x = tax_n,\n  regression.variables = c(\"easter[15]\"),\n  arima.model = \"(0 1 1)(1 0 0)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"none\"\n)\n\nplot(m)\n\n\n\n\nWhile the summary looks fine,\n\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = tax_n, transform.function = \"none\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"easter[15]\"), arima.model = \"(0 1 1)(1 0 0)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Easter[15]        -213.82083   63.50954  -3.367 0.000761 ***\n#&gt; AR-Seasonal-04       0.47697    0.09087   5.249 1.53e-07 ***\n#&gt; MA-Nonseasonal-01    0.63304    0.07859   8.055 7.98e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(1 0 0)  Obs.: 102  Transform: none\n#&gt; AICc:  1442, BIC:  1452  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 17.27   Shapiro (normality): 0.9833\n\nthe seasonal factors seem erratic:\n\nmonthplot(m)\n\n\n\n\nTo me (Christoph), this seems against the very basic idea of seasonal adjustment: We want to collect predictable fluctuations in the seasonal component, not random noise. The other side of the coin is a very smooth seasonal adjustment.\nThese kind of SI ratios appear in around 10 to 20% of SEATS adjustment and may be the reason why SEATS often seems smoother than X11.\nHow to detect these cases? How to deal with these adjustments?"
  },
  {
    "objectID": "25-seats.html#considerations-when-using-seats-in-x-13",
    "href": "25-seats.html#considerations-when-using-seats-in-x-13",
    "title": "7  SEATS",
    "section": "\n7.9 Considerations when using SEATS in X-13",
    "text": "7.9 Considerations when using SEATS in X-13\nSome model limitations when using SEATS are as follows.\n\nSEATS does not accept missing lag models. Hence, it is acceptable to specify a (0 1 3)(0 1 1) model but unacceptable to specify (0 1 [1 3])(0 1 1).\nThe AR and MA orders (p and q) cannot be greater than 3.\n\nInadmissible decomposition: Sometimes, the estimated values of coefficients make it impossible to estimate components from the estimated ARIMA models. SEATS will usually change the model and re-estimate it in order to get an admissible decomposition. When it is difficult to find an admissible decomposition the airline model is often used as a replacement. This usually gives acceptable results for a broad range of series.\nModel span can have large implications in a SEATS adjustment. This is due to the changing dynamics of long time series and how SEATS derives its filters."
  },
  {
    "objectID": "25-seats.html#sec-comparing",
    "href": "25-seats.html#sec-comparing",
    "title": "7  SEATS",
    "section": "\n7.10 Comparing X-11 and SEATS",
    "text": "7.10 Comparing X-11 and SEATS\nThe Bureau of Labor Statistics formed a group to do a comparison study between X-11 and model-based seasonal adjustments (CITE BLS 2007). The examined a cross section of 87 BLS series with X-11, SEATS, and STAMP using spectral, revisions history, model adequacy and sliding spans diagnostics. They found that SEATS seasonal factors are usually more stable than X-11 and X-11 trend component is usually more stable than SEATS. Also, among series that were seasonal, residual seasonality almost never appears using either method.\nThe only exception being a small number of SEATS runs where model inadequacy for the full span of data was present. This manifested as SEATS having difficulty identifying a usable model for decomposition and falling back on the airline model. They found even in these situations the SEATS seasonal adjustment is usually reasonable.\nOverall, X-11 and SEATS seasonal adjustments are very similar for many series. SEATS adjustments are often smoother than X-11 seasonal adjustments. For some series, the variance can be different based on the month or season. For example, U.S. Housing Starts is more variable in the winter months than in the summer due to the differences in warm and cold winters. ARIMA model-based seasonal adjustment does not handle this situation very well and assumes a constant variance and the SEATS adjustment wont compensate for this.\n\n7.10.1 SEATS filters from seas output\nThe trend filter and seasonal adjustment filter can be extracted from the output of a seasonal run. This is done via the save argument in the seats spec. In the following example the symmetric trend filter is saved and then exported. Note the finite='yes' argument must be specified to save filter weights.\n\nm &lt;- seas(AirPassengers, \n          seats.finite = 'yes',\n          seats.save   = 'ftf', # symmetric finite trend filter\n          out          = TRUE)\nftf_file &lt;- file.path(m$wdir, 'iofile.ftf')\n# reads in filter weights from ftf_file\nw &lt;- read.delim(textConnection(readLines(ftf_file)[-2]),\n                header = TRUE, stringsAsFactors = FALSE)\nplot(-72:71, w[,2], type = \"l\", \n     xlab = \"\", \n     ylab = \"weights\", \n     main = \"SEATS trend filter\")\n\n\n\n\nThe default SEATS output tables do not allow users to save the seasonal filter, only the seasonal adjustment and trend filters. Some additional work can be done to calculate the seasonal filters via the canonical decomposition implied models and the Wiener-Kolmogorov algorithm. The code provided here is a bit complicated and will be improved/modularized in subsequent version of this textbook. It involves outputting the mdc table and the using the grep functions to extract salient features for each model component. The naming conventions for the mdc table follow the Wald decomposition notation where moving average components appear in the numerator and differencing and/or autoregressive components appear in the denominator. The following assumes there are no AR components and anything appearing in the denominator is attributed to the differencing operator.\n\nm &lt;- seas(AirPassengers, \n          outlier = NULL, \n          regression.aictest = NULL,\n          arima.model = '(0 1 1)(0 1 1)',\n          seats.save = 'mdc', \n          out = TRUE)\n\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL, \n#&gt;     out = TRUE, arima.model = \"(0 1 1)(0 1 1)\", seats.save = \"mdc\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; MA-Nonseasonal-01  0.40182    0.07887   5.095 3.49e-07 ***\n#&gt; MA-Seasonal-12     0.55694    0.07626   7.303 2.80e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 987.4, BIC: 995.8  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.04   Shapiro (normality): 0.9886  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant seasonal peak has been\n#&gt;   found in the estimated spectrum of the regARIMA residuals.\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\ndecomp.m &lt;- read.delim(file.path(m$wdir, 'iofile.mdc'), sep = ':',\n                       stringsAsFactors = FALSE, header = FALSE)\nprint(decomp.m)\n#&gt;           V1           V2\n#&gt; 1     ntcnum  3.000000000\n#&gt; 2  tcnum.000  1.000000000\n#&gt; 3  tcnum.001  0.047518134\n#&gt; 4  tcnum.002 -0.952481866\n#&gt; 5     ntcden  3.000000000\n#&gt; 6  tcden.000  1.000000000\n#&gt; 7  tcden.001 -2.000000000\n#&gt; 8  tcden.002  1.000000000\n#&gt; 9      tcvar  0.054007671\n#&gt; 10     nsnum 12.000000000\n#&gt; 11  snum.000  1.000000000\n#&gt; 12  snum.001  1.412938279\n#&gt; 13  snum.002  1.485031335\n#&gt; 14  snum.003  1.412580521\n#&gt; 15  snum.004  1.216865960\n#&gt; 16  snum.005  0.970661608\n#&gt; 17  snum.006  0.704452210\n#&gt; 18  snum.007  0.440934873\n#&gt; 19  snum.008  0.218194121\n#&gt; 20  snum.009  0.009565283\n#&gt; 21  snum.010 -0.126641925\n#&gt; 22  snum.011 -0.415452995\n#&gt; 23     nsden 12.000000000\n#&gt; 24  sden.000  1.000000000\n#&gt; 25  sden.001  1.000000000\n#&gt; 26  sden.002  1.000000000\n#&gt; 27  sden.003  1.000000000\n#&gt; 28  sden.004  1.000000000\n#&gt; 29  sden.005  1.000000000\n#&gt; 30  sden.006  1.000000000\n#&gt; 31  sden.007  1.000000000\n#&gt; 32  sden.008  1.000000000\n#&gt; 33  sden.009  1.000000000\n#&gt; 34  sden.010  1.000000000\n#&gt; 35  sden.011  1.000000000\n#&gt; 36      svar  0.054246235\n#&gt; 37    nsanum  3.000000000\n#&gt; 38 sanum.000  1.000000000\n#&gt; 39 sanum.001 -1.365780650\n#&gt; 40 sanum.002  0.393702700\n#&gt; 41    nsaden  3.000000000\n#&gt; 42 saden.000  1.000000000\n#&gt; 43 saden.001 -2.000000000\n#&gt; 44 saden.002  1.000000000\n#&gt; 45     savar  0.625661730\n#&gt; 46    irrvar  0.297766039\n\n# trend-cycle model\nmacoefs &lt;- decomp.m[grep('^tcnum', decomp.m$V1),'V2'][-1]\ntrend.var &lt;- decomp.m[decomp.m$V1 == 'tcvar','V2']\ntrendDiff &lt;- decomp.m[grep('^tcden', decomp.m$V1),'V2']\n\n# seasonal model\nseasonal.macoefs &lt;- decomp.m[grep('^snum', decomp.m$V1),'V2'][-1]\nseasonal.var &lt;- decomp.m[decomp.m$V1 == 'svar','V2']\nseasonalDiff &lt;- decomp.m[grep('^sden', decomp.m$V1),'V2']\n\n# irregular variance\nirr.var &lt;- decomp.m[decomp.m$V1 == 'irrvar','V2']\n\n# transitory model (usually not needed)\ntrans.macoefs &lt;- decomp.m[grep('^trnum', decomp.m$V1),'V2'][-1]\ntrans.var &lt;- decomp.m[decomp.m$V1 == 'trvar','V2']\ntransDiff &lt;- decomp.m[grep('^trden', decomp.m$V1),'V2']\n\n# seasonally adjusted model\nsadj.macoefs &lt;- decomp.m[grep('^sanum', decomp.m$V1),'V2'][-1]\nsadj.var &lt;- decomp.m[decomp.m$V1 == 'savar','V2']\nsadjDiff &lt;- decomp.m[grep('^saden', decomp.m$V1),'V2']\n\nTo further understand these components the implied trend model is the following:\n\nmacoefs\n#&gt; [1]  0.04751813 -0.95248187\n\nwhich tells us the trend is an MA(2) with coefficients \\(\\theta_1 = 0.04751813\\) and \\(\\theta_2 = -0.95248187\\). The variance of the innovations, \\(\\sigma\\) is\n\ntrend.var\n#&gt; [1] 0.05400767\n\nand the differencing is\n\ntrendDiff\n#&gt; [1]  1 -2  1\n\nwhich is second differencing, i.e. \\(\\delta(B) = 1 - 2B + B^2 = (1-B)^2\\).\nWe can use these component models to apply the WK algorithm and get the seasonal filter weights. The details of this complex operation are omitted here but a plot of the seasonal filter weights is given in Figure ???.\n\n\n\n\n\n\n7.10.2 Reasons for using SEATS or X11\n\n\n\n\n\n\nTODO\n\n\n\nAdd Table with pros and cons\n\n\nFirst off, there does not exist a simple flow chat that tells each individual users whether they should use SEATS or X-11. For most well-behaved series both methods will produce suitable seasonal adjustments that will work for the majority of use cases. The ultimate decision between the two comes down to a few questions.\n\nWhat will you be doing with these seasonal adjustments?\nHow often is your data revised?\nDoes your agency have a policy to freeze data/seasonal adjustment revisions after a fixed period of time?\nHow much time can be devoted to development of initial spec files?\nHow much time can be devoted to maintenance of spec files?\nWhat is your maintenance schedule? (yearly, monthly, etc)\nWhat are the consequences of a poor adjustment?\nWhat are the consequences of large revisions?\nWill your agency be publishing original series, just SA, trends, seasonal factors?\nIs there an emphasis on deep methodological understanding of the procedures?\nIs there an emphasis on training users of released data to have a methodological understanding of the SA process?\n\n\nWhen applied properly (good ARIMA model, filters are not too narrow), it produces a seasonal component that is more stable. This leads to less revisions in the resulting series.\nWhen applied improperly (bad ARIMA model, narrow filters), it produces an unpredictable seasonal component and an overly smooth seasonally adjusted series.\nX-11 is more ‘robust’: If applied without additional checks. If this is desirable it may be a better option.\nIf you check SEATS models carefully, it may produce a more stable adjustment.\n\nTo sum up, whether you should use SEATS or X11 also depends on how much work you are willing to invest in a series."
  },
  {
    "objectID": "30-part-data-problems.html",
    "href": "30-part-data-problems.html",
    "title": "Data Problems",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter is currently a dumping ground for ideas, and we don’t recommend reading it.\n\n\n\n\nIn part III we look at more in-depth at practical issues with seasonal adjustment. The focus is on concrete solutions to each situation presented. Each subsection will prominently feature a case study dedicated to each problem."
  },
  {
    "objectID": "31-holidays.html#why-should-we-adjust-for-holiday-effects",
    "href": "31-holidays.html#why-should-we-adjust-for-holiday-effects",
    "title": "8  Irregular holidays",
    "section": "\n8.1 Why should we adjust for holiday effects",
    "text": "8.1 Why should we adjust for holiday effects\nEaster is based on the lunar cycles of the Jewish calendar. As such, the Easter dates change from year to year. Depending on the year, Easter is either in March or April. In quarterly data, Easter fall either in the first or in the second quarter.\nFor the interpretation of many time series, this constitutes problem. Retails sales, for example, are usually reduced during the Easter holiday. If March values are compared between years, their interpretation depends on the exact day of Easter. If Easter falls into March, we would expect lower retail sales in this month. Conversely, if it falls into April we would expect April numbers to be lower.\n\n\nTable 8.1: Possible values for regression.variables\n\n\n\n\n\n\nVariable\nDescription\n\n\n\nconst\nTrend constant regression variable to allow for a nonzero overall mean for the differenced data.\n\n\nseasonal\nFixed seasonal effects parameterized via s−1 seasonal contrast variables. The resulting variables allow for month-to-month (or quarter-to-quarter, etc.) differences in level, but have no net effect on overall level. Cannot be used with sincos or in models with seasonal differencing except as a partial change of regime variable.\n\n\nsincos[ ]\nFixed seasonal effects (for s = seasonal period) parameterized via trigonometric regression variables of the form sin(ωjt) and cos(ωjt) at seasonal frequencies ωj = (2πj/s) for 1 ≤ j ≤ s/2 (dropping sin(ωjt) ≡ 0 for j = s/2 for s even). Each frequency to be included must be specified, i.e., for monthly series sincos[1, 2, 3, 4, 5, 6] includes all seasonal frequencies while sincos[1, 2, 3] includes only the first three. Cannot be used with seasonal or in models with seasonal differencing.\n\n\ntd\nEstimate monthly (or quarterly) flow trading-day effects by including the tdnolpyear variables in the model, and handle leap-year effects either by re-scaling (for transformed series) or by including the lpyear regression variable (for untransformed series). Can only be used for monthly or quarterly series, and cannot be used with tdnolpyear, td1coef, td1nolpyear, lpyear, lom, loq, tdstock, or tdstock1coef. If td is specified, do not specify transform.adjust = \"lpyear\" or transform.adjust = \"lom\".\n\n\ntdnolpyear\nInclude the six day-of-week contrast variables (monthly and quarterly flow series only): (no. of Mondays) − (no. of Sundays), …, (no. of Saturdays) − (no. of Sundays). Cannot be used with td, td1coef, td1nolpyear, tdstock, or tdstock1coef.\n\n\ntd1coef\nEstimate monthly (or quarterly) flow trading-day effects by including the td1nolpyear variable (see below) in the model, and handle leap-year effects either by re-scaling (for transformed series) or by including the lpyear regression variable (for untransformed series). Can only be used for monthly or quarterly series, and cannot be used with td, tdnolpyear, td1nolpyear, lpyear, lom, loq, tdstock, or tdstock1coef.\n\n\ntd1nolpyear\nInclude the weekday-weekend contrast variable (monthly and quarterly flow series only): (no. of weekdays) −52 (no. of Saturdays and Sundays).\n\n\nlpyear\nInclude a contrast variable for leap-year (monthly and quarterly flow series only): 0.75 for leap-year Februaries (first quarters), -0.25 for non-leap year Februaries (first quarters), and 0.0 otherwise.\n\n\nlom\nInclude length-of-month as a regression variable. If lom is requested for a quarterly series, X-13ARIMA-SEATS uses loq instead. Requesting lom when s is neither 12 nor 4 produces an error.\n\n\nloq\nInclude length-of-quarter as a regression variable. If loq is requested for a monthly series, X-13ARIMA-SEATS uses lom instead.\n\n\ntdstock[w]\nEstimate day-of-week effects for inventories or other stocks reported for the w-th day of each month. The value w must be supplied and can range from 1 to 31. For any month of length less than the specified w, the tdstock variables are measured as of the end of the month. Use tdstock[31] for end-of-month stock series.\n\n\ntdstock1coef[w]\nEstimate a constrained stock trading day effect for inventories or other stocks reported for the w-th day of each month. The value w must be supplied and can range from 1 to 31. For any month of length less than the specified w, the tdstock1coef variables are measured as of the end of the month. Use tdstock1coef[31] for end-of-month stock series.\n\n\neaster[w]\nEaster holiday regression variable for monthly or quarterly flow data that assumes the level of daily activity changes on the w-th day before Easter and remains at the new level through the day before Easter. This value w must be supplied and can range from 1 to 25. A user can also specify an easter[0] regression variable, which assumes the daily level of activity level changes only on Easter Sunday. To estimate complex effects, several of these variables, differing in their choices of w, can be specified.\n\n\nlabor[w]\nLabor Day holiday regression variable (monthly flow data only) that assumes the level of daily activity changes on the w-th day before Labor Day and remains at the new level until the day before Labor Day. The value w must be supplied and can range from 1 to 25.\n\n\nthank[w]\nThanksgiving holiday regression variable (monthly flow data only) that assumes the level of daily activity changes on the w-th day before or after Thanksgiving and remains at the new level until December 24. The value w must be supplied and can range from −8 to 17. Values of w &lt; 0 indicate a number of days after Thanksgiving; values of w &gt; 0 indicate a number of days before Thanksgiving.\n\n\nsceaster[w]\nStatistics Canada Easter holiday regression variable (monthly or quarterly flow data only) assumes that the level of daily activity changes on the (w − 1)-th day before Easter and remains at the new level through Easter day. The value w must be supplied and can range from 1 to 24. To estimate complex effects, several of these variables, differing in their choices of w, can be specified.\n\n\neasterstock[w]\nEnd of month stock Easter holiday regression variable for monthly or quarterly stock data. This regressor is generated from the easter[w] regressors. The value w must be supplied and can range from 1 to 25. To estimate complex effects, several of these variables, differing in their choices of w, can be specified.\n\n\naodate\nAdditive (point) outlier variable, AO, for the given date or observation number. For series with associated dates, AOs are specified as aodate. For monthly series this is aoyear.month (e.g., ao1985.jul or ao1985.7), while for quarterly series this is aoyear.quarter (e.g., ao1985.1 for an AO in the first quarter of 1985), and for annual series this is aoyear (e.g., ao1922). For series without associated dates, AOs are specified as aoobservation number, e.g., ao50 for an AO at observation 50. More than one AO may be specified. All specified outlier dates must occur within the series.\n\n\naosdate-date\nSpecifies a sequence of additive (point) outlier variables, AO, for the given range of dates or observation numbers. Sequence AO outlers begin and end on a given date, e.g., aos2008.apr-2008.oct. More than one AOS may be specified, although the spans should not overlap. All specified outlier dates must occur within the series.\n\n\nlsdate\nRegression variable for a constant level shift (in the transformed series) beginning on the given date, e.g., \"ls1990.oct\" for a level shift beginning in October 1990. More than one level shift may be specified. Dates are specified as for AOs and the same restrictions apply with one addition: level shifts cannot be specified to occur on the start date of the series (or of the span specified by the span argument of the series spec).\n\n\nlssdate-date\nSpecifies a sequence of level shift outlier variable, LS, for the given range of dates or observation numbers. Sequence LS outlers begin and end on a given date, e.g., \"lss2008.jun-2008.nov\". More than one LSS may be specified, though the spans should not overlap. All specified outlier dates must occur within the series.\n\n\ntcdate\nRegression variable for a temporary level change (in the transformed series) beginning on the given date, e.g., \"tc1990.oct\" for a temporary change beginning in October 1990. More than one temporary change may be specified. Dates are specified as for AOs, and the same restrictions apply.\n\n\nsodate\nRegression variable for a seasonal outlier (in the transformed series) beginning on the given date, e.g., \"so1988.mar\" for a seasonal outlier beginning in March 1988. More than one seasonal outlier change may be specified. Dates are specified as for AOs, and the same restrictions apply with one addition: seasonal level shifts cannot be specified to occur on the start date of the series (or of the span specified by the span argument of the series spec).\n\n\nrpdate-date\nRamp effect that begins and ends on the given dates, e.g., \"rp1988.apr-1990.oct\". The rate of change during the ramp for this regression variable is constant. More than one ramp effect may be specified. All dates of the ramps must occur within the series. Ramps can overlap other ramps, TLs, AOs, and level shifts.\n\n\nqddate-date\nQuadratic ramp effect that begins and ends on the given dates, e.g., \"qd1998.may-2000.aug\". The rate of change during the ramp for this regression variable is decreasing in magnitude. More than one quadratic ramp effect may be specified. All dates of the ramps must occur within the series. Quadratic ramps can overlap other ramps, TLs, AOs, and level shifts.\n\n\nqidate-date\nQuadratic ramp effect that begins and ends on the given dates, e.g., \"qi2010.apr-2011.oct\". The rate of change during the ramp for this regression variable is increasing in magnitude. More than one quadratic ramp effect may be specified. All dates of the ramps must occur within the series. Quadratic ramps can overlap other ramps, TLs, AOs, and level shifts.\n\n\ntldate-date\nTemporary level change effect which begins and ends on the given dates, e.g., \"tl1983.jul-1984.nov\". More than one temporary level shift effect may be specified. All dates of the temporary level shift regressor must occur within the series."
  },
  {
    "objectID": "31-holidays.html#automated-adjustment",
    "href": "31-holidays.html#automated-adjustment",
    "title": "8  Irregular holidays",
    "section": "\n8.2 Automated Adjustment",
    "text": "8.2 Automated Adjustment\nBy default, seas() calls the automated routines to detect Easter effects in a series. For example, the default call detects an Easter effect with a length of one in the air passengers time series:\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nX-13 tests various lengths of an Easter effect and picks the one model with the lowest AICc. Easter[1] indicates that a length of one day has been chosen. I.e., the Easter holiday period is thought to start on Easter day and last for only one day. Alternatively, Easter[8] starts at Easter day and lasts for the eight subsequent days. If we want to enforce an eight day Easter holiday, we can specify the call as follows:\n\nm_easter_8 &lt;- seas(AirPassengers, regression.variables = \"easter[8]\")\nsummary(m_easter_8)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.variables = \"easter[8]\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0028967  0.0005289  -5.477 4.33e-08 ***\n#&gt; Easter[8]          0.0158629  0.0074253   2.136   0.0327 *  \n#&gt; AO1951.May         0.1008171  0.0206437   4.884 1.04e-06 ***\n#&gt; MA-Nonseasonal-01  0.1215690  0.0858086   1.417   0.1566    \n#&gt; MA-Seasonal-12     0.5036477  0.0770917   6.533 6.44e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 948.8, BIC: 965.4  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.):  26.4   Shapiro (normality): 0.9895\n\nSurprisingly, the 8 day Easter model has a lower AICc than the one day model. This opens the question why the one day model has been chosen in the beginning.\nIncluding holiday effects can have a dramatic effect on a final seasonal adjustment. Consider the monthly retail sales from Hobby, toy, and game stores. The data can be found at the US Census Time Series repository.\n\n\n\n\n\n\nHow to read data from CENSUS into R\n\n\n\n\nget_census_time_series &lt;- function(url) {\n  tf &lt;- tempfile(fileext = \".txt\")\n  download.file(census_url, tf)\n  ans &lt;- readr::read_csv(tf, skip = 6, col_types = cols(\n    Period = col_character(),\n    Value = col_double()\n  ))\n\n  ans |&gt;\n    mutate(\n      month.abb = gsub(\"\\\\-.+$\", \"\", Period),\n      year = gsub(\"^.+\\\\-\", \"\", Period)\n    ) |&gt;\n    left_join(tibble(month.abb, month = seq(month.abb)), by = join_by(month.abb)) |&gt;\n    mutate(time = as.Date(paste(year, month, 1, sep = \"-\"))) |&gt;\n    select(time, value = Value) |&gt;\n    filter(!is.na(value)) |&gt;\n    tsbox::ts_ts()\n}\n\ncensus_url &lt;- \"https://www.census.gov/econ_export/?format=csv&adjusted=true&notAdjusted=false&errorData=false&mode=report&default=&errormode=Dep&charttype=&chartmode=&chartadjn=&submit=GET+DATA&program=MARTS&startYear=1992&endYear=2023&categories%5B0%5D=44X72&dataType=SM&geoLevel=US\"\n\nget_census_time_series(census_url)\n\n\n\n\nts_plot(hobby_toy_game, title = \"Hobby, Toy and Game store monthly sales\")\n\n\n\n\nWe can perform a seasonal adjustment on this series with and without the Easter[8] regressor.\n\nm0 &lt;- seas(hobby_toy_game, x11 = \"\", regression = NULL, outlier = NULL)\nm1 &lt;- seas(hobby_toy_game, x11 = \"\", regression.variables = \"Easter[8]\", outlier = NULL)\nts_dygraphs(\n  ts_c(\n    hobby_toy_game, SA_noEaster = final(m0), SA_withEaster = final(m1)\n  )\n)\n\n\n\n\n\nNotice the large differences during certain Easter periods. For example, the final seasonally adjusted series including an Easter regressor in April 2011 was 1360.52. The final seasonally adjusted values without an Easter regressor was 1449.3, a difference of 89 million dollars which is over 7.5% difference from of the original series value."
  },
  {
    "objectID": "31-holidays.html#case-study-chinese-new-year",
    "href": "31-holidays.html#case-study-chinese-new-year",
    "title": "8  Irregular holidays",
    "section": "\n8.3 Case Study: Chinese New Year",
    "text": "8.3 Case Study: Chinese New Year\nThe Lunar New Year is the most important holiday in China and many other Asian countries. Traditionally, the holiday starts on Lunar New Year’s Eve, and lasts to the Lantern Festival on the 15th day of the first month of the lunisolar calendar. The Chinese New Year is celebrated either in January or in February of the Gregorian calendar.\nBecause of its importance, Chinese New Year seriously distorts monthly time series, which are usually reported according to the Gregorian calendar. Unlike Easter, Chinese New Year does not affect quarterly time series, as it always falls in the first quarter.\nX-13-ARIMA-SEATS has a built-in adjustment procedure for Easter holiday, but not for Chinese New Year. However, all packages allow for the inclusion of user-defined variables, and the Chinese New Year can be modeled as such.\nWith the R package seasonal, generating and including such a series is easy. We will use it in the following to seasonally adjust and remove Chinese New Year effects from the nominal dollar value of imports to China. seasonal is an interface to X-13ARIMA-SEATS; for more information and installation details, see here.\n\n8.3.1 Imports of Goods to China\nChinese imports are included as an example series in seasonal, both with and without the official seasonal adjustment.\n\nlibrary(tsbox)\nstopifnot(packageVersion(\"seasonalbook\") &gt;= \"0.0.2\")\nts_plot(imp_cn)\n\n\n\n\nThe series has a very different seasonal pattern before 2000, we focus on the later period. (Adjusting the whole series in one step is possible, but for good results one should manually model the seasonal break.)\n\nimp_cn_2000 &lt;- ts_span(imp_cn, start = 2000)\n\nts_dygraphs() works similar to ts_plot(), but allows for zooming:\n\nts_dygraphs(imp_cn_2000)\n\n\n\n\n\n\n\n\n\n\n\nHow to read data from FRED into R\n\n\n\n{fredr} provides access to the Federal Reserve of Economic Data (FRED), provided by the Federal Reserve Bank of St. Louis. To use fredr and the FRED API in general, you must first obtain a FRED API key. Have a look at the Documentation for details.\nThe core function in this package is fredr(), which fetches observations for a FRED series.\nWe can use purrr::map_dfr() to download multiple series at once:\n\nlibrary(fredr)\nimp_cn_raw &lt;- purrr::map_dfr(c(\"XTIMVA01CNM667S\", \"XTIMVA01CNM667N\"), fredr)\n\nA bit of tidying:\n\nimp_cn_tidy &lt;-\n  imp_cn_raw %&gt;%\n  select(time = date, id = series_id, value) %&gt;%\n  mutate(id = recode(\n    id,\n    XTIMVA01CNM667S = \"sa\",\n    XTIMVA01CNM667N = \"nsa\"\n  ))\n\nUse the tsbox package to convert the data frame into ts objects.\n\nlibrary(tsbox)\nimp_cn_sa &lt;- ts_ts(ts_pick(imp_cn_tidy, \"sa\"))\nimp_cn &lt;- ts_ts(ts_pick(imp_cn_tidy, \"nsa\"))\n\nBoth time series are included in the book package.\n\nlibrary(seasonalbook)\nimp_cn_sa\nimp_cn\n\n\n\nseasonal includes the genhol() function, a R version of the equally named software utility by the U.S. Census Bureau. Using the dates of the Chinese New Year as an input, it produces a time series with the deviations from the monthly means. Here we are assuming that the holiday starts on New Year’s Eve and lasts for one week.\n\nreg_cny &lt;- genhol(cny, start = -1, end = 6, center = \"calendar\")\ntsbox::ts_dygraphs(reg_cny)\n\n\n\n\n\n\n8.3.2 Including user-defined regressors\nThe time series reg_cny can be included in the main seasonal adjustment. The automated procedures of X-13ARIMA-SEATS can be applied to the imp series in the following way:\n\nm1 &lt;- seas(\n  imp_cn,\n  xreg = reg_cny,\n  regression.usertype = \"holiday\",\n  x11 = list()\n)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, xreg = reg_cny, regression.usertype = \"holiday\", \n#&gt;     x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg              -0.1763689  0.0126544 -13.937  &lt; 2e-16 ***\n#&gt; Weekday            0.0074166  0.0009114   8.138 4.02e-16 ***\n#&gt; AO1999.Dec        -0.2066833  0.0505465  -4.089 4.33e-05 ***\n#&gt; LS2008.Nov        -0.3898401  0.0528219  -7.380 1.58e-13 ***\n#&gt; MA-Nonseasonal-01  0.4537545  0.0469504   9.665  &lt; 2e-16 ***\n#&gt; MA-Seasonal-12     0.3143759  0.0485684   6.473 9.62e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.693e+04, BIC: 1.695e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.03   Shapiro (normality): 0.9704 ***\nplot(m1)\n\n\n\n\nWith xreg, arbitrary user-defined regressors can be included, regression.usertype = “holiday” ensures that the final series does not include the regression effect. We also have chosen X11 as the decomposition method.\nUnsurprisingly, the summary reveals a highly significant Chinese New Year effect. As the automatic model has been estimated on the logarithmic series, the coefficient of -0.17 indicates that New Year in 2023 will lower imports in January, by approximately 0.74 * 17 ~ 13% (compared to average January), and increase it by the same amount in February. The automatic procedure has also detected weekday effects and a level shift during the financial crisis.\n\n8.3.3 Multiple regressors\nWe can do even better by using more than one user-defined regressors, one for the pre-New-Year period and one for the post-New-Year period:\n\npre_cny &lt;- genhol(cny, start = -6, end = -1, frequency = 12, center = \"calendar\")\npost_cny &lt;- genhol(cny, start = 0, end = 6, frequency = 12, center = \"calendar\")\nm2 &lt;- seas(\n  imp_cn,\n  xreg = ts_c(pre_cny, post_cny),\n  regression.usertype = \"holiday\",\n  x11 = list()\n)\nsummary(m2)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, xreg = ts_c(pre_cny, post_cny), regression.usertype = \"holiday\", \n#&gt;     x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg1              0.008910   0.015179   0.587    0.557    \n#&gt; xreg2             -0.186830   0.018563 -10.065  &lt; 2e-16 ***\n#&gt; Weekday            0.007404   0.000906   8.172 3.04e-16 ***\n#&gt; AO1999.Dec        -0.206691   0.050272  -4.111 3.93e-05 ***\n#&gt; LS2008.Nov        -0.388900   0.052698  -7.380 1.58e-13 ***\n#&gt; MA-Nonseasonal-01  0.450334   0.046985   9.585  &lt; 2e-16 ***\n#&gt; MA-Seasonal-12     0.313567   0.048553   6.458 1.06e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.693e+04, BIC: 1.696e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.37   Shapiro (normality): 0.9687 ***\nplot(m2)\n\n\n\n\n\n8.3.4 Compare with official adjustments\nI haven’t done any research on how the officially seasonally adjusted rates are computed, but they seem very close to a default call to seas(). Our models (both m1, but especially m2), does a much better job of adjusting to Chinese New Year.\n\nts_dygraphs(\n  ts_c(\n    cny = ts_span(reg_cny * 1e11 + 1e11, start = 2000, end = 2024),\n    ts_pick(imp_cn_2000, \"sa\"),\n    final(seas(x = imp_cn, x11 = \"\")),\n    final(m2)\n  )\n)"
  },
  {
    "objectID": "32-trading-days.html#why-should-we-adjust-for-trading-day-effects",
    "href": "32-trading-days.html#why-should-we-adjust-for-trading-day-effects",
    "title": "9  Trading days",
    "section": "\n9.1 Why should we adjust for trading day effects",
    "text": "9.1 Why should we adjust for trading day effects\nMonths and quarters may differ in their overall length, or, more importantly may differ in the number of weekdays. Similar to the holiday adjustments, X-13 offers various tools to deal with differences in the number of days or weekdays.\n\n\n\n\n\n(a) January, 2022\n\n\n\n\n\n(b) January, 2023\n\n\n\nFigure 9.1: The number of weekdays differ between months\n\n\nTrading day effects, as weekday effects are called in X-13, constitute a predictable movement in a time series, and therefore should not be part of the seasonally adjusted series. Trading day effects are usually removed by the regression spec, although some adjustments can be also done by the transform spec. Contrary to the regression spec, the transform spec performs a 1:1 adjustment, while the regression spec estimates the size of the effect from the data.\nAs with most adjustments, X-13 offers a built in automated adjustment that works well in most circumstances. We start the chapter by looking at the automated procedures. Sometimes, you want to rely on a user defined specification of trading days, a topic covered ?sec-user-defined-regressors. Finally, in ?sec-replicate-x-13-trading-days-adjustment, we link the two sections by replicating the built-in regressors in R."
  },
  {
    "objectID": "32-trading-days.html#built-in-trading-day-adjustment",
    "href": "32-trading-days.html#built-in-trading-day-adjustment",
    "title": "9  Trading days",
    "section": "\n9.2 Built-in trading day adjustment",
    "text": "9.2 Built-in trading day adjustment\nIn a default run of seas(), X-13 uses a familiar AICc test to decide between a number of potential trading day adjustments. Form the various models, it uses the one with the lowest AICc as the best model. By default, the following models are evaluated:\n\ntd1coef: A single coefficient trading day adjustment\ntd: A six day coefficients trading day adjustment\n\nThe first model distinguishes between weekday and weekends, while the second model treats every day as it’s own. The first model is appropriate for many economic time series, where variables behave differently during the week than during the weekend. In some series, there may be large differences between weekdays, or even between Saturday and Sunday. Retail sales, for example, usually peak towards the end of the week and are weak on Sunday.\nUsing the built-in trading day adjustment in X-13 is straightforward:\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe procedure has opted for a one coefficient model. During weekdays, the number of air passengers was lower during the period of the example series, by about 0.3% (note we are looking at a logarithmic, multiplicative model).\nWe can manipulate the automated model. To enforce a six coefficient model, regression.variables can be specified as \"td\" (as opposed to \"td1coef\"):\n\nm_td &lt;- seas(AirPassengers, regression.variables = \"td\")\nsummary(m_td)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.variables = \"td\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon            -0.001527   0.003458  -0.442   0.6588    \n#&gt; Tue            -0.007677   0.003607  -2.129   0.0333 *  \n#&gt; Wed            -0.001125   0.003465  -0.325   0.7453    \n#&gt; Thu            -0.005350   0.003425  -1.562   0.1183    \n#&gt; Fri             0.004676   0.003447   1.357   0.1749    \n#&gt; Sat             0.003025   0.003568   0.848   0.3965    \n#&gt; Easter[1]       0.017999   0.007246   2.484   0.0130 *  \n#&gt; AO1951.May      0.109256   0.019651   5.560 2.70e-08 ***\n#&gt; MA-Seasonal-12  0.500775   0.077252   6.482 9.03e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 0)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 949.5, BIC: 976.4  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.05   Shapiro (normality): 0.9902\n\nNote that the resulting AICc is higher (949.5) than for the one coefficient model (947.3). That is why the automated procedure has opted for the simpler model."
  },
  {
    "objectID": "32-trading-days.html#case-study-hobby-toy-game",
    "href": "32-trading-days.html#case-study-hobby-toy-game",
    "title": "9  Trading days",
    "section": "\n9.3 Case Study: Hobby Toy Game",
    "text": "9.3 Case Study: Hobby Toy Game\n\nm &lt;- seas(hobby_toy_game)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = hobby_toy_game)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon               -0.009625   0.003358  -2.866 0.004157 ** \n#&gt; Tue                0.014245   0.003276   4.349 1.37e-05 ***\n#&gt; Wed               -0.009167   0.003289  -2.787 0.005326 ** \n#&gt; Thu               -0.001631   0.003258  -0.501 0.616624    \n#&gt; Fri                0.010977   0.003332   3.295 0.000984 ***\n#&gt; Sat                0.011069   0.003316   3.338 0.000843 ***\n#&gt; Easter[8]          0.061462   0.006426   9.564  &lt; 2e-16 ***\n#&gt; AO1996.May        -0.217402   0.025347  -8.577  &lt; 2e-16 ***\n#&gt; AO1996.Dec         0.145309   0.025339   5.735 9.77e-09 ***\n#&gt; MA-Nonseasonal-01  0.377066   0.056405   6.685 2.31e-11 ***\n#&gt; MA-Nonseasonal-02  0.360585   0.056510   6.381 1.76e-10 ***\n#&gt; MA-Seasonal-12     0.326875   0.055259   5.915 3.31e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 282  Transform: log\n#&gt; AICc:  2826, BIC:  2871  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.25   Shapiro (normality): 0.9887 *\n\nstatic(m)\n#&gt; seas(\n#&gt;   x = hobby_toy_game,\n#&gt;   regression.variables = c(\"td\", \"easter[8]\", \"ao1996.May\", \"ao1996.Dec\"),\n#&gt;   arima.model = \"(0 1 2)(0 1 1)\",\n#&gt;   regression.aictest = NULL,\n#&gt;   outlier = NULL,\n#&gt;   transform.function = \"log\"\n#&gt; )\n\nm0 &lt;- seas(\n  x = hobby_toy_game,\n  regression.variables = c(\"td\", \"easter[8]\", \"ao1996.May\", \"ao1996.Dec\"),\n  arima.model = \"(0 1 2)(0 1 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\nsummary(m0)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = hobby_toy_game, transform.function = \"log\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"td\", \"easter[8]\", \n#&gt;         \"ao1996.May\", \"ao1996.Dec\"), arima.model = \"(0 1 2)(0 1 1)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon               -0.009625   0.003358  -2.866 0.004157 ** \n#&gt; Tue                0.014245   0.003276   4.349 1.37e-05 ***\n#&gt; Wed               -0.009167   0.003290  -2.787 0.005327 ** \n#&gt; Thu               -0.001631   0.003258  -0.501 0.616637    \n#&gt; Fri                0.010977   0.003332   3.295 0.000985 ***\n#&gt; Sat                0.011069   0.003316   3.338 0.000843 ***\n#&gt; Easter[8]          0.061462   0.006426   9.564  &lt; 2e-16 ***\n#&gt; AO1996.May        -0.217403   0.025348  -8.577  &lt; 2e-16 ***\n#&gt; AO1996.Dec         0.145309   0.025339   5.735 9.78e-09 ***\n#&gt; MA-Nonseasonal-01  0.377086   0.056405   6.685 2.30e-11 ***\n#&gt; MA-Nonseasonal-02  0.360597   0.056509   6.381 1.76e-10 ***\n#&gt; MA-Seasonal-12     0.326884   0.055258   5.916 3.31e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 282  Transform: log\n#&gt; AICc:  2826, BIC:  2871  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.25   Shapiro (normality): 0.9887 *\n\n\n\nm1 &lt;- seas(\n  x = hobby_toy_game,\n  regression.variables = c(\"td1coef\", \"easter[8]\", \"ao1996.May\", \"ao1996.Dec\"),\n  arima.model = \"(0 1 2)(0 1 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = hobby_toy_game, transform.function = \"log\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"td1coef\", \"easter[8]\", \n#&gt;         \"ao1996.May\", \"ao1996.Dec\"), arima.model = \"(0 1 2)(0 1 1)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday            0.0005289  0.0005944   0.890    0.374    \n#&gt; Easter[8]          0.0542854  0.0074088   7.327 2.35e-13 ***\n#&gt; AO1996.May        -0.2300586  0.0290640  -7.916 2.46e-15 ***\n#&gt; AO1996.Dec         0.1231689  0.0289604   4.253 2.11e-05 ***\n#&gt; MA-Nonseasonal-01  0.4421089  0.0569371   7.765 8.17e-15 ***\n#&gt; MA-Nonseasonal-02  0.3495768  0.0569694   6.136 8.45e-10 ***\n#&gt; MA-Seasonal-12     0.3571851  0.0551869   6.472 9.65e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 282  Transform: log\n#&gt; AICc:  2875, BIC:  2904  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 40.88 * Shapiro (normality): 0.9943\n\nlibrary(tsbox)\nts_dygraphs(ts_c(\n  final(m0),\n  final(m1)\n))"
  },
  {
    "objectID": "32-trading-days.html#case-study-replicate-x-13-trading-days-adjustment",
    "href": "32-trading-days.html#case-study-replicate-x-13-trading-days-adjustment",
    "title": "9  Trading days",
    "section": "\n9.4 Case Study: Replicate X-13 trading days adjustment",
    "text": "9.4 Case Study: Replicate X-13 trading days adjustment\n‘Trading day adjustment’ removes the effect of the weekdays, and but does not include holidays, such as Christmas or Easter. These are handled separately (Easter) or dealt with by standard seasonal adjustment (Christmas).\nSometimes, users may want to specify user defined trading day regressors, in order to incorporate country specific trading day patterns. In ?sec-replicate-x-13-trading-days-adjustment, we replicate the built-in regressors. These regressors simply use the number of weekdays, and do not pay any reference to a country specific calendar. If you want to deviate from them, a good way is to start with the replicated values, and adjust from there.\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(tsbox)\nlibrary(seasonal)\n\n\n9.4.1 Constructing weekday regressors\n\ndates &lt;- seq(as.Date(\"1931-01-01\"), as.Date(\"2030-12-31\"), by = \"day\")\n\nfirst_of_month &lt;- function(x) {\n  as.Date(paste(\n    data.table::year(dates),\n    data.table::month(dates),\n    1,\n    sep = \"-\"\n  ))\n}\n\n\ntd1nolpyear\n\nInclude the weekday-weekend contrast variable (monthly and quarterly flow eries only): (no. of weekdays) −(5/2) (no. of Saturdays and Sundays).\n\ntdnolpyear\n\nInclude the six day-of-week contrast variables (monthly and quarterly flow series only): (no. of Mondays) − (no. of Sundays), . . . , (no. of Saturdays) − (no. of Sundays).\n\n\n\ntd_m_tbl &lt;-\n  tibble(dates, wd = as.POSIXlt(dates)$wday, name = weekdays(dates)) %&gt;%\n  group_by(time = first_of_month(dates)) %&gt;%\n  summarize(\n    td1 = sum(wd %in% 1:5) - 5 / 2 * sum(wd %in% c(6, 0)),\n    mon = sum(wd == 1) - sum(wd == 0),\n    tue = sum(wd == 2) - sum(wd == 0),\n    wed = sum(wd == 3) - sum(wd == 0),\n    thu = sum(wd == 4) - sum(wd == 0),\n    fri = sum(wd == 5) - sum(wd == 0),\n    sat = sum(wd == 6) - sum(wd == 0)\n  )\n\nhead(as.data.frame(td_m_tbl), 10)\n#&gt;          time  td1 mon tue wed thu fri sat\n#&gt; 1  1931-01-01 -0.5   0   0   0   1   1   1\n#&gt; 2  1931-02-01  0.0   0   0   0   0   0   0\n#&gt; 3  1931-03-01 -0.5   0   0  -1  -1  -1  -1\n#&gt; 4  1931-04-01  2.0   0   0   1   1   0   0\n#&gt; 5  1931-05-01 -4.0  -1  -1  -1  -1   0   0\n#&gt; 6  1931-06-01  2.0   1   1   0   0   0   0\n#&gt; 7  1931-07-01  3.0   0   0   1   1   1   0\n#&gt; 8  1931-08-01 -4.0   0  -1  -1  -1  -1   0\n#&gt; 9  1931-09-01  2.0   0   1   1   0   0   0\n#&gt; 10 1931-10-01 -0.5   0   0   0   1   1   1\n\n‘Trading day adjustment’ removes the effect of the weekdays, and but does not include holidays, such as Christmas or Easter. These are handled separately (Easter) or dealt with by standard seasonal adjustment (Christmas).\n\ntd1nolpyear &lt;-\n  td_m_tbl %&gt;%\n  select(time, value = td1) %&gt;%\n  ts_ts()\n\ntdnolpyear &lt;-\n  td_m_tbl %&gt;%\n  select(-td1) %&gt;%\n  ts_long() %&gt;%\n  ts_ts()\n\n\n9.4.2 Single coef\n\nm_td1coef &lt;- seas(\n  AirPassengers,\n  xreg = td1nolpyear,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.usertype = \"td\"\n)\nsummary(m_td1coef)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, xreg = td1nolpyear, regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.usertype = \"td\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg              -0.0025474  0.0006732  -3.784 0.000154 ***\n#&gt; MA-Nonseasonal-01  0.3292278  0.0813633   4.046 5.20e-05 ***\n#&gt; MA-Seasonal-12     0.5695911  0.0739360   7.704 1.32e-14 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 976.6, BIC: 987.7  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 24.86   Shapiro (normality): 0.9805 *\n\n\nm_td1coef_built_in &lt;- seas(\n  AirPassengers,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.variables = c(\"td1nolpyear\", outlier = NULL)\n)\nsummary(m_td1coef_built_in)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL, \n#&gt;     regression.variables = c(\"td1nolpyear\", outlier = NULL))\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0025474  0.0006732  -3.784 0.000154 ***\n#&gt; MA-Nonseasonal-01  0.3292278  0.0813633   4.046 5.20e-05 ***\n#&gt; MA-Seasonal-12     0.5695911  0.0739360   7.704 1.32e-14 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 976.6, BIC: 987.7  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 24.86   Shapiro (normality): 0.9805 *\n\n\n9.4.3 All coefs\n\nm_td &lt;- seas(\n  AirPassengers,\n  xreg = tdnolpyear,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.usertype = \"td\"\n)\nsummary(m_td)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, xreg = tdnolpyear, regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.usertype = \"td\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg1             -0.004982   0.004731  -1.053 0.292359    \n#&gt; xreg2             -0.004589   0.004762  -0.964 0.335172    \n#&gt; xreg3             -0.001612   0.004745  -0.340 0.734094    \n#&gt; xreg4             -0.003817   0.004680  -0.816 0.414652    \n#&gt; xreg5              0.003958   0.004706   0.841 0.400272    \n#&gt; xreg6              0.003164   0.004829   0.655 0.512342    \n#&gt; MA-Nonseasonal-01  0.298942   0.082193   3.637 0.000276 ***\n#&gt; MA-Seasonal-12     0.579965   0.073855   7.853 4.07e-15 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 983.9, BIC:  1008  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.43   Shapiro (normality): 0.9781 *\n\n\nm_td_built_in &lt;- seas(\n  AirPassengers,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.variables = c(\"tdnolpyear\", outlier = NULL)\n)\nsummary(m_td_built_in)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL, \n#&gt;     regression.variables = c(\"tdnolpyear\", outlier = NULL))\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon               -0.004982   0.004731  -1.053 0.292359    \n#&gt; Tue               -0.004589   0.004762  -0.964 0.335172    \n#&gt; Wed               -0.001612   0.004745  -0.340 0.734094    \n#&gt; Thu               -0.003817   0.004680  -0.816 0.414652    \n#&gt; Fri                0.003958   0.004706   0.841 0.400272    \n#&gt; Sat                0.003164   0.004829   0.655 0.512342    \n#&gt; MA-Nonseasonal-01  0.298942   0.082193   3.637 0.000276 ***\n#&gt; MA-Seasonal-12     0.579965   0.073855   7.853 4.07e-15 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 983.9, BIC:  1008  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.43   Shapiro (normality): 0.9781 *"
  },
  {
    "objectID": "33-outliers.html#introduction",
    "href": "33-outliers.html#introduction",
    "title": "10  Outliers",
    "section": "\n10.1 Introduction",
    "text": "10.1 Introduction\nExceptional data values, or outliers, constitute a problem both for the ARIMA model building as well as for the seasonal filtering. When analyzing time series data, outlier values are common. In some cases, these issues can be linked to actual events in the real world, such as:\n\nthe COVID-19 pandemic\nthe 2008/09 financial market crash\nNatural disasters\nUkraine crisis\n\nThese events can impact the accuracy of seasonal adjustment. As a result, X-13 tries to remove these inconsistencies before performing seasonal adjustment.\nFor example, when running seas() on AirPassengers with default settings, X-13 detects an additive outlier in may 1951. This additive outlier is removed in the regARIMA part but will be readded to the final, seasonally adjusted series.\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe plot() method highlights the outlier values and marks them accordingly:\n\nplot(m)\n\n\n\n\nThe default settings discovered a single, additive outlier. By default, X-13 uses a formula that interpolates critical values for numbers of observations between 3 and 99 (Table 7.22 in the Manual). For standard time series, this results in a critical value around 4.\nUsing the outlier.critical argument, we can fine tune the detection prosses. With outlier.critical = 3, we set a lower bar for the detection of outliers. outlier.critical is the z-value of a particular value that is needed to be classified as an outlier. A value of three means that the z-value must be 3 or larger.\n\nm_high &lt;- seas(AirPassengers, outlier.critical = 3)\nsummary(m_high)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier.critical = 3)\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday        -0.0027692  0.0004187  -6.613 3.76e-11 ***\n#&gt; Easter[1]       0.0140649  0.0058438   2.407 0.016092 *  \n#&gt; AO1950.Jan     -0.0629435  0.0174523  -3.607 0.000310 ***\n#&gt; AO1951.May      0.1081042  0.0165482   6.533 6.46e-11 ***\n#&gt; LS1953.Jun     -0.0755237  0.0228402  -3.307 0.000944 ***\n#&gt; AO1954.Feb     -0.0693534  0.0160240  -4.328 1.50e-05 ***\n#&gt; LS1960.Apr      0.0847557  0.0272119   3.115 0.001842 ** \n#&gt; MA-Seasonal-12  0.4967116  0.0749535   6.627 3.43e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 0)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 910.7, BIC: 935.1  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.07   Shapiro (normality): 0.9911  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nWith outlier.critical = 3, we see additive outliers in January 1950, May 1951 and February 1954. In addition, we also see level shifts in June 1953 and April 1960. Note that all z-values are larger than 3.\nX-13 offers several ways to model outliers. In this chapter, we will focus on two most important types of effects that can occur in time series data: level shifts and additive outliers. By understanding these effects and how to address them, analysts can improve the quality of their analyses and draw more accurate conclusions from the data.\n\nArguments to the `outlier` spec\n\n\n\n\n\n\nArgument\nDescription\nDefault\n\n\n\noutlier.critical\n\nSets the value to which the absolute values of the outlier t-statistics are compared to detect outliers.\nIf only one value is given for this argument, then this critical value is used for all types of outliers. If a list of up to three values is given, different values are used for additive outliers, level shift outliers and temporary change outliers.\n\nObtained by a modification of the asymptotic formula of Ljung (1993) that interpolates critical values for numbers of observations between 3 and 99.\n\n\noutlier.method\n\nDetermines how the program successively adds detected outliers to the model. The choices are \"addone\" or \"addall\".\n\"addone\" calculates t-statistics for each type of outlier specified at all time points.\n\"addall\" follows the same general steps as the addone method, except it adds to the model all outliers with absolute t-statistics exceeding the critical value.\n\n\"addone\".\n\n\noutlier.span\nSpecifies start and end dates of a span of the time series to be searched for outliers. The start and end dates of the span must both lie within the series.\nNone.\n\n\noutlier.types\nSpecifies the types of outliers to detect. The choices are: \"ao\" (additive outliers), \"ls\" (level shifts), \"tc\" (temporary change), \"all\": (detect all three of the above types simultaneously), and \"none\" (turn off outlier detection, but not t-statistics for temporary level shifts).\nThe default is c(\"ao\", \"ls\")."
  },
  {
    "objectID": "33-outliers.html#level-shift",
    "href": "33-outliers.html#level-shift",
    "title": "10  Outliers",
    "section": "\n10.2 Level Shift",
    "text": "10.2 Level Shift\nThe first outlier category we look at are level shifts. Level shifts refers to a sudden and sustained change in the underlying level of a time series. There can be various causes of level shifts in time series data, such as changes in concepts or definitions of the survey population, alterations in the method of data collection, shifts in economic behavior, changes in legislation, etc. Level shifts are a problem for seasonal adjustment because they will distort the estimation of the seasonal factors.\nBelow is an example of a manually specified level shift:\n\nm_level_shift &lt;- seas(\n  AirPassengers,\n  regression.variables = \"ls1953.Jun\",\n  outlier = NULL\n)\nsummary(m_level_shift)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier = NULL, regression.variables = \"ls1953.Jun\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; LS1953.Jun        -0.0782358  0.0270308  -2.894 0.003800 ** \n#&gt; Weekday           -0.0024659  0.0006125  -4.026 5.67e-05 ***\n#&gt; Easter[1]          0.0205837  0.0084022   2.450 0.014294 *  \n#&gt; MA-Nonseasonal-01  0.3020780  0.0823400   3.669 0.000244 ***\n#&gt; MA-Seasonal-12     0.5241174  0.0756816   6.925 4.35e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 959.8, BIC: 976.4  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.):  26.8   Shapiro (normality): 0.9807 *\n\nWe use the regression.variables argument to manually specify a level-shift. Since we want to deactivate the automated outlier detection from above, we specify outlier = NULL.\nLevel shifts are a problem for seasonal adjustment because they will distort the estimation of the seasonal factors. Within X-13, the initial trend is calculated by applying a moving average to the series. If there is an abrupt change in the level of the series, the estimates will be distorted. The estimates before the level shift will be underestimated, and those after will be overestimated. As the calculation of the irregular and seasonal components follow on from this initial trend-cycle estimation, they may be distorted as well."
  },
  {
    "objectID": "33-outliers.html#additive-outliers",
    "href": "33-outliers.html#additive-outliers",
    "title": "10  Outliers",
    "section": "\n10.3 Additive Outliers",
    "text": "10.3 Additive Outliers\nAn additive outlier is a data point that falls outside the general pattern of the trend and seasonal component in a time series. Outliers can be caused by random effects, such as an extreme irregular point, or by identifiable factors, such as a strike or bad weather.\nAdditive outliers pose a significant challenge to seasonal adjustment methods, which rely on moving averages. The crux of the problem lies in the inherent sensitivity of averages to the presence of extreme values or outliers. When unusual data points are included, the average can become unrepresentative of the underlying pattern in the series. Without proper adjustments or allowances for outliers, estimates for all the components in a time series can become distorted. As such, addressing additive outliers is critical to maintaining the integrity of seasonal adjustment techniques and ensuring accurate analyses.\nBelow is an example of a manually specified additive outlier:\n\nm_additive_outlier &lt;- seas(\n  AirPassengers,\n  regression.variables = \"ao1954.Feb\",\n  outlier = NULL\n)\nsummary(m_additive_outlier)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier = NULL, regression.variables = \"ao1954.Feb\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; AO1954.Feb        -0.0733392  0.0217684  -3.369 0.000754 ***\n#&gt; Weekday           -0.0026730  0.0005682  -4.705 2.54e-06 ***\n#&gt; Easter[1]          0.0222881  0.0079155   2.816 0.004866 ** \n#&gt; MA-Nonseasonal-01  0.2014840  0.0844582   2.386 0.017051 *  \n#&gt; MA-Seasonal-12     0.5483430  0.0750706   7.304 2.79e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 956.7, BIC: 973.3  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 32.09   Shapiro (normality): 0.9819 .\n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nAgain, we use the regression.variables argument to manually specify an additive outlier. Since we want to deactivate the automated outlier detection from above, we specify outlier = NULL."
  },
  {
    "objectID": "33-outliers.html#manually-identifying-outliers",
    "href": "33-outliers.html#manually-identifying-outliers",
    "title": "10  Outliers",
    "section": "\n10.4 Manually Identifying Outliers",
    "text": "10.4 Manually Identifying Outliers\nX-13 contains an automated outlier detection procedure that works well in most circumstances and can be used as a starting point. Plotting the series may add additional information on whether outliers should be adjusted or not. The identify() method opens a window that allows you to manually identify outliers. Select or deselect outliers by point and click. To quit and return the call, press ESC. Click several times to loop through different outlier types.\n\nm &lt;- seas(\n  AirPassengers\n)\nidentify(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n#&gt; seas(\n#&gt;   x = AirPassengers,\n#&gt;   regression.variables = c(\"td1coef\", \"easter[1]\", \"ao1951.May\"),\n#&gt;   arima.model = \"(0 1 1)(0 1 1)\",\n#&gt;   regression.aictest = NULL,\n#&gt;   outlier = NULL,\n#&gt;   transform.function = \"log\"\n#&gt; )\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;           Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  \n#&gt;          -0.00295            0.01777            0.10016            0.11562  \n#&gt;    MA-Seasonal-12  \n#&gt;           0.49736"
  },
  {
    "objectID": "34-seasonal-breaks.html#case-study-imports-of-goods-to-china",
    "href": "34-seasonal-breaks.html#case-study-imports-of-goods-to-china",
    "title": "11  Seasonal breaks",
    "section": "\n11.1 Case Study: Imports of Goods to China",
    "text": "11.1 Case Study: Imports of Goods to China\nWe previously used the imports of goods to China, as series that seem to have a pretty obvious seasonal break.\nChinese imports are included as an example series in seasonal, both with and without the official seasonal adjustment.\n\nlibrary(tsbox)\nstopifnot(packageVersion(\"seasonalbook\") &gt;= \"0.0.2\")\nlibrary(seasonalbook)\nlibrary(seasonal)\n\nts_plot(imp_cn)\n\n\n\n\nThe series has a very different seasonal pattern before 2000. In our previous example, we simply cut the data and focused on the later period.\n\nts_span(imp_cn, start = 2000)\n#&gt;               Jan          Feb          Mar          Apr          May\n#&gt; 2000  15258000000  13428000000  17806000000  18355000000  16966000000\n#&gt; 2001  15545000000  18226000000  20773000000  21859000000  18809000000\n#&gt; 2002  18970000000  15918000000  22486000000  25753000000  22435000000\n#&gt; 2003  31016000000  23780000000  32549000000  34601000000  31604000000\n#&gt; 2004  35710000000  42020000000  46480000000  49530000000  42980000000\n#&gt; 2005  44260000000  39900000000  55210000000  57660000000  49400000000\n#&gt; 2006  55497000000  51684000000  66857000000  66491000000  60110000000\n#&gt; 2007  70726000000  58358000000  76686000000  80760000000  71644000000\n#&gt; 2008  90230000000  79130000000  95800000000 102390000000 100770000000\n#&gt; 2009  51375000000  60058000000  71886000000  78987000000  75689000000\n#&gt; 2010  95517000000  87110000000 119465000000 118434000000 112213000000\n#&gt; 2011 144591000000 104270000000 152310000000 144370000000 144120000000\n#&gt; 2012 122813000000 146394000000 160395000000 144581000000 162863000000\n#&gt; 2013 159156000000 124450000000 183059000000 168619000000 162160000000\n#&gt; 2014 175138000000 136846000000 162257000000 169980000000 159537000000\n#&gt; 2015 140561000000 108485000000 141719000000 142701000000 131646000000\n#&gt; 2016 112591000000  93633000000 130313000000 126998000000 130996000000\n#&gt; 2017 131890000000 129500000000 156380000000 141490000000 149230000000\n#&gt; 2018 180142000000 137630000000 179100000000 171650000000 187950000000\n#&gt; 2019 179670000000 132371000000 166867000000 180532000000 172773000000\n#&gt; 2020 156910000000 142327000000 165213108000 154900580000 143886746000\n#&gt; 2021 198640212000 166975331000 227336197000 221063587000 218382769000\n#&gt; 2022 241914340000 186832863000 228704260000 222500588000 229490725000\n#&gt;               Jun          Jul          Aug          Sep          Oct\n#&gt; 2000  20300000000  19490000000  20785000000  20713000000  18943000000\n#&gt; 2001  21252000000  20957000000  22162000000  21851000000  18902000000\n#&gt; 2002  23094000000  26988000000  27206000000  29794000000  25197000000\n#&gt; 2003  32336000000  36514000000  34621000000  41652000000  35193000000\n#&gt; 2004  48890000000  48980000000  46820000000  50720000000  45440000000\n#&gt; 2005  56210000000  54900000000  57780000000  62570000000  56050000000\n#&gt; 2006  66808000000  65714000000  71970000000  76342000000  64298000000\n#&gt; 2007  76469000000  83347000000  86224000000  88263000000  80547000000\n#&gt; 2008 100470000000 111412000000 105999000000 106792000000  92748000000\n#&gt; 2009  87540000000  95150000000  88243000000 103199000000  86848000000\n#&gt; 2010 117153000000 116888000000 119475000000 128356000000 109107000000\n#&gt; 2011 139700000000 145020000000 155390000000 154990000000 140230000000\n#&gt; 2012 148199000000 151629000000 151467000000 158696000000 143448000000\n#&gt; 2013 146979000000 168160000000 162321000000 170556000000 154341000000\n#&gt; 2014 155223841100 165590000000 158629387300 182635508000 161461228100\n#&gt; 2015 144347000000 151292000000 136473000000 145317000000 130903000000\n#&gt; 2016 131447000000 132051000000 138601000000 142503000000 128420000000\n#&gt; 2017 153560000000 146690000000 157090000000 169570000000 150810000000\n#&gt; 2018 175113000000 187516000000 189440000000 195000000000 182375000000\n#&gt; 2019 162817000000 177758000000 179959655000 178474843000 169898075000\n#&gt; 2020 167152978000 175301874000 176333799000 202759047000 178739425000\n#&gt; 2021 229890607000 226073489000 235984248000 238979506000 215681597000\n#&gt; 2022 233322854000 231696993000 235527165000 238011751000 213217901000\n#&gt;               Nov          Dec\n#&gt; 2000  21641000000  21414000000\n#&gt; 2001  20846000000  22390000000\n#&gt; 2002  28735000000  28734000000\n#&gt; 2003  36893000000  42336000000\n#&gt; 2004  50970000000  52680000000\n#&gt; 2005  61660000000  64380000000\n#&gt; 2006  72926000000  73097000000\n#&gt; 2007  91203000000  91723000000\n#&gt; 2008  74657000000  72046000000\n#&gt; 2009  94691000000 112349000000\n#&gt; 2010 130970000000 141466000000\n#&gt; 2011 159770000000 158020000000\n#&gt; 2012 159776000000 167805000000\n#&gt; 2013 168390000000 182165000000\n#&gt; 2014 156966500000 177900668700\n#&gt; 2015 142616000000 163506000000\n#&gt; 2016 149317000000 168595000000\n#&gt; 2017 177170000000 177112000000\n#&gt; 2018 182670000000 164190000000\n#&gt; 2019 183411013000 191057245000\n#&gt; 2020 192673058000 203753955000\n#&gt; 2021 253813881000 246035373000\n#&gt; 2022 226252602000 228066200000\n\nBack then, we said that adjusting the whole series in one step is possible, but for good results one should manually model the seasonal break. Let’s do this now.\n\n11.1.1 Identifying a seasonal break\nIn part, the seasonal break is visible in the series. It is more straigthforward to spot in the monthplot of the series:\n\nmonthplot(seas(imp_cn))\n\n\n\n\nThis makes it obvious that there were very strong December effects before 2000. We don’t know anything about the series, but we can speculate thatprior to 2000, custom receipts were counted when they were handed in (at the end of the year), rather than at the date of import.\n\nsummary(seas(imp_cn, regression.variables = \"seasonal/2000.jan//\"))\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, regression.variables = \"seasonal/2000.jan//\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Jan I             -0.1662776  0.0294653  -5.643 1.67e-08 ***\n#&gt; Feb I             -0.0978000  0.0272530  -3.589 0.000332 ***\n#&gt; Mar I             -0.0348167  0.0268771  -1.295 0.195182    \n#&gt; Apr I             -0.0776090  0.0267186  -2.905 0.003676 ** \n#&gt; May I              0.0797005  0.0266373   2.992 0.002771 ** \n#&gt; Jun I             -0.0218536  0.0265109  -0.824 0.409755    \n#&gt; Jul I             -0.0318924  0.0265695  -1.200 0.230007    \n#&gt; Aug I             -0.0586952  0.0267450  -2.195 0.028191 *  \n#&gt; Sep I             -0.1054443  0.0268916  -3.921 8.81e-05 ***\n#&gt; Oct I              0.0505228  0.0269457   1.875 0.060795 .  \n#&gt; Nov I              0.0161593  0.0267806   0.603 0.546245    \n#&gt; Weekday            0.0064750  0.0008732   7.415 1.22e-13 ***\n#&gt; AO1992.Jan        -0.4999959  0.0619702  -8.068 7.13e-16 ***\n#&gt; AO1993.Jan        -0.6321962  0.0526077 -12.017  &lt; 2e-16 ***\n#&gt; LS1994.Jan        -0.2743605  0.0533460  -5.143 2.70e-07 ***\n#&gt; AO1995.Jan        -0.2195211  0.0516319  -4.252 2.12e-05 ***\n#&gt; AO1999.Dec        -0.4192300  0.0514073  -8.155 3.49e-16 ***\n#&gt; AO2001.Jan        -0.2615086  0.0497203  -5.260 1.44e-07 ***\n#&gt; AO2004.Feb         0.2099186  0.0488191   4.300 1.71e-05 ***\n#&gt; LS2008.Nov        -0.3437454  0.0507702  -6.771 1.28e-11 ***\n#&gt; AO2009.Jan        -0.2922712  0.0487401  -5.997 2.02e-09 ***\n#&gt; AO2012.Jan        -0.2063534  0.0484210  -4.262 2.03e-05 ***\n#&gt; LS2016.Jan        -0.2389579  0.0505957  -4.723 2.33e-06 ***\n#&gt; MA-Nonseasonal-01  0.5338610  0.0509112  10.486  &lt; 2e-16 ***\n#&gt; MA-Nonseasonal-02 -0.1686792  0.0509516  -3.311 0.000931 ***\n#&gt; MA-Seasonal-12     0.8567887  0.0307654  27.849  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.684e+04, BIC: 1.694e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 19.61   Shapiro (normality): 0.9922 *\n\nA formal test of a seasonal break can be performed by including regression.variables = \"seasonal/1999.jan//\" into the specification. By default, seasonal outliers are removed from the final series. Therefore, this can be used to model a seasonal break. Modeling a seasonal break is usually preferable to a separation of the time series in two parts."
  },
  {
    "objectID": "40-part-other-issues.html",
    "href": "40-part-other-issues.html",
    "title": "Other Issues",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter is currently a dumping ground for ideas, and we don’t recommend reading it.\n\n\n\n\nPart IV investigates more holistic issues that practitioners face. The main focus is to give classical methodology to answer their problems. Since these types of issues can be highly specialized, we concentrate on known solutions to the topics."
  },
  {
    "objectID": "41-presence-of-seasonality.html",
    "href": "41-presence-of-seasonality.html",
    "title": "12  Presence of seasonality",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter should be readable but needs polishing.\n\n\n\n\nShould a series be seasonally adjusted at all?\nX-13 removes seasonality from the series, even if a series is not seasonal from the beginning. If a series is not seasonal, the resulting series may be bad.\nFortunately, X-13 contains a few tests that help users decide if a series is seasonal.\nBefore applying X-13, deciding if the series is seasonal may be necessary. This section discusses how to decide whether a series should be adjusted.\n\n12.0.1 Basic Principle\nIn general, adjusting a non-seasonal series is less of a problem than not adjusting a seasonal series. So, unless you have good reasons to believe that a series is not-seasonal, adjust it. If in doubt, adjust!\n\n12.0.2 Available Tests\nTo help you to make a good decision, X-13 offers a few formal checks:\n\nThe QS test is the primary test to evaluate seasonality both the original or in the adjusted series. It will be discussed in more detail in Chapter 15.\nThe Identifiable Seasonality Test (IDS) gives a simple yes or no answer to whether a series is seasonal or not. It is available for X11 adjustments only.\nThe M7 statistic applies critical values to the Identifiable Seasonality Test (IDS) and returns a simple yes or no answer.\n\nWhich tests are preferable, and how should a user decide if the tests are not aligned?\n\n12.0.3 QS Test\nThe QS test has a few advantages compared to the IDS statistics and is generally preferable. It is available both with X11 and SEATS.\nYou can retrieve the results of the QS test by the qs() function. (We will say more about the QS statistic in Chapter 15).\n\nqs(seas(AirPassengers))\n#&gt;                     qs  p-val\n#&gt; qsori        167.64858 0.0000\n#&gt; qsorievadj   203.07731 0.0000\n#&gt; qsrsd          0.00000 1.0000\n#&gt; qssadj         0.00000 1.0000\n#&gt; qssadjevadj    0.00000 1.0000\n#&gt; qsirr          0.00000 1.0000\n#&gt; qsirrevadj     0.00000 1.0000\n#&gt; qssori       115.08988 0.0000\n#&gt; qssorievadj  135.11320 0.0000\n#&gt; qssrsd         0.36904 0.8315\n#&gt; qsssadj        0.00000 1.0000\n#&gt; qsssadjevadj   0.00000 1.0000\n#&gt; qssirr         0.00000 1.0000\n#&gt; qssirrevadj    0.00000 1.0000\n\nThe QS Statistic shows the degree of seasonality in various components of the seasonal adjustment. For our purposes, the first line is the most interesting. It shows that the QS value of the original series is 168, which comes with a p-value of essentially 0. This reads as there is a 0 probability that the null-hypothesis of seasonality in the original series can be rejected.\nIn other words, AirPassengers is a clearly seasonal series, which should not come as a surprise at this point.\n\n12.0.4 Identifiable Seasonality Test\nA second test for seasonality is the Identifiable Seasonality Test. It is only available in X11.\nAccording to UK Office for National Statistics (2007), a value lower than 1.150 (monthly series) or lower than 0.900 (quarterly series) indicates that seasonality is clearly present.\n\nUK Office for National Statistics. 2007. Guide to Seasonal Adjustment with x-12-ARIMA. http://www.ons.gov.uk/ons/guide-method/method-quality/general-methodology/time-series-analysis/guide-to-seasonal-adjustment.pdf.\nAt the same time, a value between 1.150 and 1.250 (monthly series) or between 0.900 and 1.050 (quarterly series) indicates that seasonality may be present.\nValues above 1.250 (monthly series) or 1.050 (quarterly series) point to non-seasonal series.\nAs we have stated above, the recommendation is to adjust the series unless you have clear evidence that a series is not seasonal.\nLet’s try AirPassengers:\n\nudg(seas(AirPassengers, x11 = list()), \"f3.m07\")\n#&gt; f3.m07 \n#&gt;  0.203\nudg(seas(AirPassengers, x11 = list()), \"f2.idseasonal\")\n#&gt; f2.idseasonal \n#&gt;         \"yes\"\n\nThe M7 value is way below the critical values. Accordingly, the Identifiable Seasonality Test indicates seasonality in the series.\n\n12.0.5 Case Study\nConsider the following less clear-cut series:\n\nlibrary(tsbox)\nlibrary(seasonal)\n\nx &lt;- ts(\n  c(\n    1070.67782091276, 1074.85048025033, 1057.22943663105, 1054.83329692382,\n    1035.00741277933, 1014.37654341674, 1016.01971482192, 1031.5736998743,\n    1055.97206482734, 1069.14603895638, 1054.70695712307, 1033.65404358999,\n    988.507205808669, 957.755772336067, 936.185046914472, 939.221279279722,\n    962.250799500941, 984.056833428967, 999.390633761089, 1033.68786613334,\n    1055.87289736274, 1097.92353618165, 1114.50822274577, 1148.65763657244,\n    1199.32404772514, 1208.39317300933, 1185.13960320363, 1154.58521771845,\n    1101.7137166423, 1053.89252948544, 996.495317493457, 926.283479008456,\n    850.048912454291, 809.84549670808, 772.216576162406, 784.114051995134,\n    806.261273184001, 820.618967152661, 815.649757299053, 812.501547645406,\n    809.899692888929, 823.778177350232, 811.211453993884, 814.868987237855,\n    829.047528533717, 831.891817984415, 843.653707473654, 895.684951210102,\n    926.544452180194, 949.41125175328, 950.333376822119, 994.228127170556,\n    999.697246815797, 1008.00877350773, 1006.7566419533, 990.419046839283,\n    962.941704204873, 947.541756501729, 929.161895739204, 910.588436791225,\n    1248.42457644542, 1266.67760866087, 1248.78020047598, 1290.47101093513,\n    1328.51898051507, 1356.02796471527, 1363.37837075383, 1398.27679451834,\n    1399.20602270507, 1391.19336700805, 1387.13912745033, 1346.03774501977,\n    1370.73051832038, 1346.29966480321, 1340.09701324613, 1331.07456050929,\n    1321.82409348173, 1343.5116656349, 1366.41043298961, 1363.10871463069,\n    1391.84216974474, 1417.38495449438, 1432.17468812037, 1394.40194160954,\n    1385.72476381292, 1388.23802327199, 1354.10595421438, 1345.15701390051,\n    960.801527083357, 941.027878841707, 887.618178201697, 842.12961787775,\n    795.717159404159, 757.35803147815, 724.93681522789, 716.66515476601,\n    708.682334791168, 689.925785264133, 687.748168972216, 688.809213406042,\n    664.421326451325, 661.822007527535, 687.161046216216, 684.548292412124,\n    713.757983905367, 729.917128362926, 750.569868821847, 745.544259228118,\n    758.516668782925, 758.841495662419, 757.815323362363\n  ),\n  frequency = 4,\n  start = 1995\n)\n\nts_plot(x)\n\n\n\n\nIf we apply standard SEATS seasonal adjustment, this does not seem to do anything:\n\nm &lt;- seas(x)\nplot(m)\n\n\n\n\nWhat do formal statistics say?\n\nqs(m)\n#&gt;                   qs   p-val\n#&gt; qsori        0.00000 1.00000\n#&gt; qsorievadj   0.08751 0.95719\n#&gt; qsrsd        0.00000 1.00000\n#&gt; qssadj       0.00000 1.00000\n#&gt; qssadjevadj  0.08751 0.95719\n#&gt; qsirr        1.81436 0.40366\n#&gt; qsirrevadj   1.81436 0.40366\n#&gt; qssori       0.00000 1.00000\n#&gt; qssorievadj  0.78501 0.67536\n#&gt; qssrsd       0.26233 0.87707\n#&gt; qsssadj      0.00000 1.00000\n#&gt; qsssadjevadj 0.78501 0.67536\n#&gt; qssirr       1.92576 0.38179\n#&gt; qssirrevadj  1.92576 0.38179\n\nLet’s have a look at the first line. A QS value of 0 has a p-value of 1, meaning the Nul-Hypothesis of seasonality in the orgininal value can be savely rejected. According to this measure, it is clear that this series has no seasonality.\nIf we want to consider the M7 values, we need to use X11:\n\nm_x11 &lt;- seas(x, x11 = list())\n\nThe QS statistic has to be the same for the unadjusted series but not for the adjusted one:\n\nqs(m_x11)\n#&gt;                   qs   p-val\n#&gt; qsori        0.00000 1.00000\n#&gt; qsorievadj   0.08751 0.95719\n#&gt; qsrsd        0.00000 1.00000\n#&gt; qssadj       0.00000 1.00000\n#&gt; qssadjevadj  0.00000 1.00000\n#&gt; qsirr        0.00000 1.00000\n#&gt; qsirrevadj   0.03306 0.98361\n#&gt; qssori       0.00000 1.00000\n#&gt; qssorievadj  0.78501 0.67536\n#&gt; qssrsd       0.26233 0.87707\n#&gt; qsssadj      0.00000 1.00000\n#&gt; qsssadjevadj 0.00000 1.00000\n#&gt; qssirr       0.00000 1.00000\n#&gt; qssirrevadj  0.08751 0.95719\n\nBecause we use X11, we can now have a look at the M7 value:\n\nudg(m_x11, \"f3.m07\")\n#&gt; f3.m07 \n#&gt;  1.222\n\nIf you look for simple answers, the \"f2.idseasonal\" gives you a simple yes or no answer. From the previous discussion, it should not be surprising that the answer is no.\n\nudg(m_x11, \"f2.idseasonal\")\n#&gt; f2.idseasonal \n#&gt;          \"no\""
  },
  {
    "objectID": "42-annual-constraining.html",
    "href": "42-annual-constraining.html",
    "title": "13  Annual constraining",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter is currently a dumping ground for ideas, and we don’t recommend reading it.\n\n\n\n\n\n\n13.0.1 The Problem\nSeasonal adjustment may affect the annual values of a series. The yearly total of an adjusted series usually differs from the total fo an unadjusted series. By applying the Denton Method, the adjustment procedure used by the SECO enforces the totals to be equal. In seasonal, this can be performed with the option force.type = \"denton\".\n\n13.0.2 Re-adjusting annual values\n\nm &lt;- seas(AirPassengers)\n\n\nlibrary(tsbox)\n\nts_plot(\n  ts_frequency(final(seas(AirPassengers)), aggregate = \"sum\"),\n  ts_frequency(AirPassengers, aggregate = \"sum\")\n)\n\n\n\n\n\n\nts_frequency(final(seas(AirPassengers, force.type = \"denton\")), aggregate = \"sum\")\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1] 1520 1676 2042 2364 2700 2867 3408 3939 4421 4572 5140 5714\n\nts_frequency(AirPassengers, aggregate = \"sum\")\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1] 1520 1676 2042 2364 2700 2867 3408 3939 4421 4572 5140 5714\n\n\n13.0.3 Should the annual values be restrained?"
  },
  {
    "objectID": "43-indirect-vs-direct.html#built-in-tools",
    "href": "43-indirect-vs-direct.html#built-in-tools",
    "title": "14  Indirect vs direct adjustment",
    "section": "\n14.1 Built-in tools",
    "text": "14.1 Built-in tools\nX-13 offers various diagnostics to Compare Direct and Indirect Adjustments\n\nSpectral graphs\nSliding spans\n\nSet the same sliding spans length for all components\n\n\nRevisions history\n\nSet the same history span for all components\n\n\nSmoothness measures (Statistics Canada introduced in X-11-ARIMA)\n\n(We don’t use these much)\n\n\n\nWhen the indirect approach is considered, seasonally adjusted aggregates should be checked to exclude the presence of residual seasonality using the F-test available in X-13.\nX-13 offers various diagnostic tools to evaluate the direct and indirect adjustment of aggregates. The program calculates seasonally adjusted aggregates using the direct and indirect approach and provides in output a set of statistics to compare the results (M diagnostics, measures of smoothness, frequency spectrum diagnostics, etc.). Furthermore, sliding spans and revision history diagnostics can be requested to assess which of the two approaches provides more stable and reliable seasonally adjusted results."
  },
  {
    "objectID": "50-part-quality-assessment.html",
    "href": "50-part-quality-assessment.html",
    "title": "Quality assessment",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter is currently a dumping ground for ideas, and we don’t recommend reading it.\n\n\n\n\nThis section focuses on diagnostic tools for seasonal adjustment. This will be written as a stand-alone section as well as a continuance of prior sections. The idea here is that many readers may be interested in checking the quality of their adjustments but not need help performing it.\nSeasonal Adjustment Diagnostics refers to the process of evaluating and assessing the quality of seasonal adjustments made to time series data using the X-13ARIMA-SEATS software. The objectives of these diagnostics are to determine the presence of seasonality in the series, assess the overall quality of the seasonal adjustment, and make decisions regarding adjustments and options. The diagnostics include spectral graphs, stability diagnostics, sliding spans, revisions history, and monitoring and quality diagnostics. The diagnostics involve analyzing the series in the time and frequency domains, examining spectral graphs, and identifying visually significant peaks. Other diagnostic tools include the F test for seasonal regressors and the QS (autocorrelation) test for residual seasonality. Sliding spans diagnostic compares adjustments from overlapping subspans of the series to assess stability. We can use all this information to help make choice about seasonal adjustment options, such as seasonal filter lengths or sigma limits. Let’s look back at our flow chart, with a done box added, to see where seasonal adjustment diagnostics fit in. Notice there are 3 routes the diagnostics could take us; back to seasonal adjustment, to completion, or all the way back to regARIMA modeling.\n\n\n\n\nflowchart TD\n  A[RegARIMA Modeling] --&gt; B(Model Comparison / Diagnostics)\n  B --&gt; A\n  A --&gt; C[Seasonal Adjustment]\n  C --&gt; D{Seasonal Adjustment Diagnostics}\n  D -.-&gt; C\n  D -.-&gt; A\n  D -.-&gt; E[Done]"
  },
  {
    "objectID": "51-quality-measures.html#residual-seasonality",
    "href": "51-quality-measures.html#residual-seasonality",
    "title": "15  Quality measures",
    "section": "\n15.1 Residual Seasonality",
    "text": "15.1 Residual Seasonality\nResidual seasonality plays a crucial role in determining the quality of a seasonal adjustment. Residual seasonality refers to the presence of remaining seasonal patterns or fluctuations in the seasonally adjusted series or its residuals. It indicates that the seasonal adjustment may not have fully removed all the seasonal effects from the data. If residual seasonality is present in the adjusted series, it can lead to biased or misleading analysis and forecasts. It implies that there are still systematic patterns or cycles left in the data, which can hinder accurate interpretation and decision-making. There are many ways to test for residual seasonality. Three prominent ones are (I THINK THIS IS A GOOD PLACE TO ADD A REFERENCE TABLE THAT LISTS THESE THREE METHODS ALONG WITH PROS, CONS, IMMEDIATE INTERPRETATIONS. I THINK MANY READERS WILL JUST WANT TO KNOW HOW TO IDENTIFY RESIDUAL SEASONALITY AND MATCH UP A TEST WITH THEIR SKILL-SET AND THEN SEE HOW TO APPLY IT)\n\nVisual inspection of the spectrum\nQS-statistic\nF-test for residual seasonality\n\n\n15.1.1 Spectrum\nWe start with visual inspection of the spectrum of a series. For those unfamiliar with spectral analysis of a time series, the following discussion is intended to be accessable to all trying to perform seasonal adjustment. Hence, we take some liberies with language an interpretation in an effort to make the discussion accessible. For example, we use the term spectrum to refer to the theoretical construct as well as the estimated periodogram. We note here that we will use a parametric AR representation to estimate the spectrum of a process. This is the easiest and most straight forward way to get smooth yet sensible empirical specral estimates for the everyday user. Peaks in the spectrum indicate significant influence to your series of a sin/cos curve of the corresponding frequency. For example, looking at the spectrum of the AirPassengers series we see large peaks at frequencies 1/12, 2/12, 3/12, …\n\nspec.ar(AirPassengers, order = 13)\n\n\n\n\nWe know that X-11 with automatic modeling and automatic filter identification performs a good seasonal adjustment. If we look at the spectrum of the seasonally adjusted series, the peaks have been removed.\n\nrequire(seasonal)\nm &lt;- seas(AirPassengers, x11 = \"\")\nspec.ar(final(m))\n\n\n\n\nLet’s intentionally perform a poor seasonal adjustment and see the effect on the spectrum of the seasonally adjusted series.\n\nrequire(seasonal)\nm &lt;- seas(AirPassengers, transform.function = \"none\", x11 = \"\", x11.seasonalma = 'stable')\nspec.ar(final(m))\n\n\n\n\nHere we see peaks remaining the the final seasonal adjustment. This is a clear indication of lack of quality and something needs to be done to improve the adjustment.\n\n15.1.2 QS statistc\nThe QS statistics check for positive autocorrelation at the seasonal lags. The null hypothesis is that the autocorrelation is zero, indicating no seasonal autocorrelation. Hence, a small p-value indicates residual seasonality.\nLet \\(\\hat{\\gamma}(h)\\) be the estimated autocorrelation function of a differenced time series. The QS statistic for a montly time series is \\[\nQS = n(n+2)\\left(\\frac{\\hat{\\gamma}(12)^2}{n - 12} + \\frac{\\hat{\\gamma}(24)^2}{n - 24}\\right)\n\\] For a quarterly series replace the 12s and 24s with 4s and 8s. The value QS is approximately chi-squared with 2 degrees of freedom. The seasonal package provides functionality to immediately look at the QS table from the UDG file. We will breakdown what all these tests and p-values are\n\nm &lt;- seas(AirPassengers)\nqs(m)\n#&gt;                     qs  p-val\n#&gt; qsori        167.64858 0.0000\n#&gt; qsorievadj   203.07731 0.0000\n#&gt; qsrsd          0.00000 1.0000\n#&gt; qssadj         0.00000 1.0000\n#&gt; qssadjevadj    0.00000 1.0000\n#&gt; qsirr          0.00000 1.0000\n#&gt; qsirrevadj     0.00000 1.0000\n#&gt; qssori       115.08988 0.0000\n#&gt; qssorievadj  135.11320 0.0000\n#&gt; qssrsd         0.36904 0.8315\n#&gt; qsssadj        0.00000 1.0000\n#&gt; qsssadjevadj   0.00000 1.0000\n#&gt; qssirr         0.00000 1.0000\n#&gt; qssirrevadj    0.00000 1.0000\n\nIn the output table we see 14 rows. The top 7 rows correspond to the QS statistic 1. Original series 1. Original series, adjusted for extreme values 1. Model residuals 1. Seasonally adjusted series 1. Seasonally adjusted series, adjusted for extreme values 1. Irregular series 1. Irregular series, adjusted for extreme values The next seven rows are simply the exact same statistics calculated on a (possibly) shorter span of the data. The default span used for the second 7 QS statistics is set to be the same as the spectrum uses, 96 observations or 8 years in a monthly series."
  },
  {
    "objectID": "51-quality-measures.html#stability-and-smoothness",
    "href": "51-quality-measures.html#stability-and-smoothness",
    "title": "15  Quality measures",
    "section": "\n15.2 Stability and smoothness",
    "text": "15.2 Stability and smoothness\nNext we explore two related concepts and their associated spec. First, the stability of a seasonal adjustment which refers to its consistency and reliability over time. It assesses whether the model fits remain consistent as new data becomes available. Stability is important as large revisions are a hindrance in a production cycle of seasonal adjustment. Again, this is a good example of a situation where a user interested in only a single seasonal adjustment (will never adjust this series again) may not care to read this section. The diagnostics provided in other chapters will more adequately aid them to produce a quality seasonal adjustment. However, for those that produce a seasonal adjustment, say monthly, stability is crucial for producing consistent and trustworthy data that can be used for analysis, decision-making, and forecasting.\n\n15.2.1 Sliding spans\nThe basic diagnostics provide descriptive information about how seasonal adjustments and their month-to-month changes vary when the data span used to calculate them is changed systematically. When comparing two neighboring spans, the extent of their differences depends on whether one starts and ends a year later than the other. The length of the data span is determined by the length of the seasonal filter used for the adjustment.\n\n\n\n\ngantt\n  title Illustration of Four 8-year spans\n  dateFormat YYYY-MM\n  section Full Data Span\n  Span 1 : des1, 1974-01, 8y\n  Span 2 : des2, 1975-01, 8y\n  Span 3 : des3, 1976-01, 8y\n  Span 4 : des4, 1977-01, 8y\n\n\n\n\n\nFor series where all seasonally adjusted values are positive, two important sliding spans statistics, A(%) and MM(%), are viewed as follows.\n\nm &lt;- seas(AirPassengers, \n          x11.seasonalma = \"S3X9\",\n          slidingspans.length = 40,\n          slidingspans.numspans = 3\n)\n# Seasonal Factors - Percentage of months flagged as unstable\nSF &lt;- udg(m, \"s2.a.per\")\nrow.names(SF) &lt;- c(\"Number of months flagged\", \"Total number of months\", \"Percent\")\ncolnames(SF) &lt;- \"seasonal factors\"\nprint(SF)\n#&gt;                          seasonal factors\n#&gt; Number of months flagged                0\n#&gt; Total number of months                 40\n#&gt; Percent                                 0\n# Month-to-Month Changes in SA Series - Percentage of months flagged as unstable\nudg(m, \"s2.d.per\")\n#&gt;      s2.d.per\n#&gt; [1,]    2.000\n#&gt; [2,]   39.000\n#&gt; [3,]    5.128\n\n\n15.2.2 Histories"
  },
  {
    "objectID": "52-revisions.html",
    "href": "52-revisions.html",
    "title": "16  Revisions",
    "section": "",
    "text": "You are reading an early draft of Seasonal Adjustment in R. This chapter is currently a dumping ground for ideas, and we don’t recommend reading it.\n\n\n\n\n\nHow to measure revisions?\nShould a model be re-estimated each period?\nHow to use the slidingspan and history spec"
  }
]