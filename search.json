[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Seasonal Adjustment in R",
    "section": "",
    "text": "Welcome\nThis is the website for the work-in-progress edition of Seasonal Adjustment in R, an online Book by James Livsey and Christoph Sax."
  },
  {
    "objectID": "index.html#about-the-book",
    "href": "index.html#about-the-book",
    "title": "Seasonal Adjustment in R",
    "section": "About the book",
    "text": "About the book\nThis book will teach you how to do seasonal adjustment in R, using X13-ARIMA-SEATS.\nSpecifically, the audience will be both R users who want to learn about seasonal adjustment as well as seasonal adjustment practitioners, who are interested in using R. The book will be tailored to the practical applications of seasonal adjustment within R. It presents background material and references for the theoretically minded reader. The main focus, however, is on concrete problems and examples.\nWe will showcase methods through detailed examples with associated code. This presentation allows the academic level to be quite broad; understood by undergraduates all the way through advanced Ph.D. students."
  },
  {
    "objectID": "index.html#key-features-of-the-book",
    "href": "index.html#key-features-of-the-book",
    "title": "Seasonal Adjustment in R",
    "section": "Key features of the book",
    "text": "Key features of the book\n\nEach chapter include a concrete practical problem and shows how X-13 can be used to address it\nTeach-by-example format\nContinuous connection of X-13ARIMA-SEATS input with R input and vice-versa\nFundamental theoretical material is referenced throughout (mainly as an option)\nFor each example given the book will give answers, code and provide data\n\nCertainly! Here’s a refined version of the section describing the specialized boxes used throughout your book:"
  },
  {
    "objectID": "index.html#specialized-content-boxes",
    "href": "index.html#specialized-content-boxes",
    "title": "Seasonal Adjustment in R",
    "section": "Specialized Content Boxes",
    "text": "Specialized Content Boxes\nWe employ a variety of specialized content boxes to enhance the reading experience. Each type of box serves a unique purpose, catering to different reader interests.\n Case Study\nThese boxes present practical applications of specific topics discussed in the book. They feature a wide array of time series examples, varying in geographical and topological contexts. Case studies are designed to be universally appealing, offering insights for all readers.\n Fundamentals\nTo gain deeper insights, it is sometimes interesting to derive of X-13 from basic fundamentals. Instead of solely depending on X-13 for analysis, we explore key concepts through R functions. This approach is particularly engaging for readers who are proficient in R.\n Frequency Domain\nTime series analysis in the frequency domain provides a powerful perspective for understanding time series behaviors. These boxes introduce and explain the applications and advantages of frequency domain methods in time series analysis. If you are unfamiliar with the frequency domain, you can safely skip these sections.\n Exercises\nEach chapter concludes with a series of exercises. These are designed to reinforce the material covered and test your knowledge. They are particularly valuable for readers using this book in an academic course or for self-study."
  },
  {
    "objectID": "10-introduction.html#seasonal-adjustment",
    "href": "10-introduction.html#seasonal-adjustment",
    "title": "1  Introduction",
    "section": "Seasonal Adjustment",
    "text": "Seasonal Adjustment\nMany time series exhibit a regular seasonal pattern over the year. US unemployment, for example, is usually higher from January to March and again in June and July. Similarly, retail sales tend to peak during the Christmas season. This seasonal behavior is regular and predictable. The goal of seasonal adjustment is to estimate and remove the seasonal component from a time series.\nWhy do we want to do this? Seasonal data is usually hard to interpret. For example, if we want to learn from the US unemployment rate if the economy is moving out of a recession during certain months, we want the labor market data to be free from seasonal effects."
  },
  {
    "objectID": "10-introduction.html#x-13arima-seats",
    "href": "10-introduction.html#x-13arima-seats",
    "title": "1  Introduction",
    "section": "X-13ARIMA-SEATS",
    "text": "X-13ARIMA-SEATS\nFundamentally, seasonal adjustment decomposes a time series into a trend, a seasonal, and an irregular component. Seasonal adjustment is then the act of removing the seasonal estimate from the observed series. There are many ways to perform this decomposition. This book focuses on a particular one, X-13ARIMA-SEATS (X-13, for short), the seasonal adjustment software developed by the United States Census Bureau. X-13 offers an elaborate toolkit to perform seasonal adjustment. The software allows users to control all aspects of the modeling process or alternatively, to use automated methods to make all modeling choices. In the text we will try to present material with this in mind. Throughout we offer suggestions about when built-in automatic method are sufficient (and sometimes even preferred) and when an analyst can get the most ``bang for the buck’’ to control modeling options themselves."
  },
  {
    "objectID": "10-introduction.html#r",
    "href": "10-introduction.html#r",
    "title": "1  Introduction",
    "section": "R",
    "text": "R\nThis book will teach you how to use X-13 in R through the seasonal package, which offers access to all features of X-13 with a usually much simpler syntax. It should be noted that the seasonal package is not a re-coding of the X-13 software. Instead it is a translation from R to the X-13 software. This translation is done under the hood and practitioners need not concern themselves with this inner working of the package. However, we make this point such that users understand that conceptually anything that can be done in the native X-13ARIMA-SEATS software, either from the command line or HTML version, can be done in the seasonal R package. Also this means if additional clarification or information about seasonal adjustment is desired, the X-13 manual or research papers can be consulted. Any example or methods found via the X-13 documentation can be easily translated to the R seasonal package. In fact, all examples from the X-13 manual can be seen run in the R seasonal package at http://www.seasonal.website/examples.html. The required X-13 binaries are provided by the x13binary package and automatically included in seasonal. The next chapter provides a minimal example to get you started in less than five minutes."
  },
  {
    "objectID": "10-introduction.html#target-audience",
    "href": "10-introduction.html#target-audience",
    "title": "1  Introduction",
    "section": "Target audience",
    "text": "Target audience\nWe write this book for two primary audiences: The first focus is on current practitioners of seasonal adjustment who are interested in learning how to implement in R. This audience includes researchers from statistical agencies who want to use features of R to evaluate the properties of their seasonal adjustments.\nThe second focus is on current R users who want to learn seasonal adjustment. We are able to leverage the reader’s knowledge of R to make learning seasonal adjustment easier. We will feature exciting applications outside official statistics, such as the seasonal adjustment of business data.\nThe book tries to be as practical as possible. It usually starts with a practical problem and shows how to solve it in a cookbook style. Formal derivations are usually avoided. Each chapter ends with a case study that discusses a real-life example of the topic."
  },
  {
    "objectID": "10-introduction.html#history-of-x-13",
    "href": "10-introduction.html#history-of-x-13",
    "title": "1  Introduction",
    "section": "History of X-13",
    "text": "History of X-13\nIn official statistics, seasonal adjustment has a long tradition. The US Census Bureau developed the original X-11 software in the 1960s, Statistics Canada (Dagum 1980) continued the development afterward. The following the X-11 software, the US Census Bureau released X-12-ARIMA (Findley et al. 1998) and X-13ARIMA-SEATS (or X-13, for short) (Monsell 2007). X-11 is still used as a name for filter-based seasonal adjustment methods within X-13. This distinction is a point of confusion for those unfamiliar with X-13ARIMA-SEATS and the nomenclature. Meanwhile, TRAMO-SEATS, developed by the Bank of Spain (Caporello, Maravall, and Sánchez 2001), offers an alternative model-based approach to seasonal adjustment.\n\nDagum, Estela Bee. 1980. The x-11-ARIMA Seasonal Adjustment Method. Statistics Canada, Seasonal Adjustment; Time Series Staff.\n\nFindley, David F, Brian C Monsell, William R Bell, Mark C Otto, and Bor-Chung Chen. 1998. “New Capabilities and Methods of the x-12-ARIMA Seasonal-Adjustment Program.” Journal of Business & Economic Statistics 16 (2): 127–52.\n\nMonsell, B. 2007. “The x-13A-s Seasonal Adjustment Program.” In Proceedings of the 2007 Federal Committee on Statistical Methodology Research Conference. http://www.fcsm.gov/07papers/Monsell.II-B.pdf.\n\nCaporello, Gianluca, Agustin Maravall, and Fernando J Sánchez. 2001. “Program TSW Reference Manual.” 0112. Banco de España Madrid. https://ideas.repec.org/p/bde/wpaper/0112.html.\n\nNational Bank of Belgium, Deutsche Bundesbank, Eurostat. 2017. JDemetra+: Econometric Software for Seasonal Adjustment and Other Time Series Methods. Eurostat. https://ec.europa.eu/eurostat/cros/content/download.\nIn its most recent version, X-13 offers these two seasonal adjustment methods in a single command-line tool written in Fortran. The National Bank of Belgium has created an alternative Java-based implementation called JDemetra+ (National Bank of Belgium, Deutsche Bundesbank, Eurostat 2017), also widely deployed by statistical agencies."
  },
  {
    "objectID": "10-introduction.html#the-seasonalbook-package",
    "href": "10-introduction.html#the-seasonalbook-package",
    "title": "1  Introduction",
    "section": "\n1.1 The seasonalbook package",
    "text": "1.1 The seasonalbook package\nAn R package that supplements “Seasonal Adjustment in R”, and contains all data and examples.\nTo install:\nremotes::install_github(\"christophsax/seasonalbook\")\nExample series:\n\nlibrary(seasonalbook)\nplot(grocery)"
  },
  {
    "objectID": "10-introduction.html#acknowledgements",
    "href": "10-introduction.html#acknowledgements",
    "title": "1  Introduction",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe are indebted to the United States Census Bureau for X-13ARIMA-SEATS and support for research around the software. Help and support by Brian Monsell are especially acknowledged.\nseasonal was originally developed for use at the Swiss State Secretariat of Economic Affairs. It has been dramatically improved thanks to suggestions and support from Matthias Bannert, Freya Beamish, Vidur Dhanda, Alain Galli, Ronald Indergand, Preetha Kalambaden, Stefan Leist, James Livsey, Pinaki Mukherjee, Bruno Parnisari and many others. The related work on the x13binary package facilitated (automated) deployment thanks to the R package system, CRAN, and GitHub for the x13prebuilt repository."
  },
  {
    "objectID": "11-getting-started.html#installation",
    "href": "11-getting-started.html#installation",
    "title": "2  Getting started",
    "section": "\n2.1 Installation",
    "text": "2.1 Installation\nIf you use R, installing X-13ARIMA-SEATS from CRAN is as easy as installing any other R package (Sax and Eddelbuettel 2018):\n\nSax, Christoph, and Dirk Eddelbuettel. 2018. “Seasonal Adjustment by X-13ARIMA-SEATS in R.” Journal of Statistical Software 87 (11): 1–17. https://doi.org/10.18637/jss.v087.i11.\ninstall.packages(\"seasonal\")"
  },
  {
    "objectID": "11-getting-started.html#sec-a-minimal-example",
    "href": "11-getting-started.html#sec-a-minimal-example",
    "title": "2  Getting started",
    "section": "\n2.2 A minimal example",
    "text": "2.2 A minimal example\nOnce the package is installed, you can load it in the usual way:\n\nlibrary(seasonal)\n\nThe seas() function provides the core functionality of the package. By default, seas calls the automatic procedures of X-13 to perform a seasonal adjustment that works well in most circumstances:\n\nseas(AirPassengers)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;           Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  \n#&gt;          -0.00295            0.01777            0.10016            0.11562  \n#&gt;    MA-Seasonal-12  \n#&gt;           0.49736\n\nThe first argument of seas is a time series of class ts. ts objects are frequently used in base R and are useful to store monthly, quarterly, or annual data. We restrict our attention to monthly and quarterly series. This is done for two reasons; first is these are the main frequencies handled by X-13, second, this sampling frequency make conceptual understanding of statistical methods, such as linear filters, easier to grasp. The AirPassengers example series is included in base R and shows monthly totals of international airline passengers from 1949 to 1960. seas() returns a seas object that contains the necessary information on the adjustment performed on this time series; we can assign it to a variable:\n\nm &lt;- seas(AirPassengers)\n\nThere are several functions and methods for \"seas\" objects. The final function returns the adjusted series. The plot method shows a plot with the unadjusted and the adjusted series.\n\nplot(m)\n\n\n\n\nAs you can see, the adjusted series is much less volatile than the original one because the seasonal component was removed from the original series. But the adjusted series is not entirely smooth. This is because it still contains the irregular component.\nThis constitutes a crucial point about seasonal adjustment: It only removes regular, predictable movements, not irregular ones. In the adjusted series, we can see a decrease in airline passengers in 1953 and between 1957 and 1958. These decreases were difficult to discover in the original series.\nThe summary method displays an overview of the model, very similar to the one produced by other R classes (eg lm or numeric):\n\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe summary gives an overview of the adjustment model and provides diagnostics. This book will help you do understand it in more detail. The following section discusses some of the elements and relates them to the chapters in this book."
  },
  {
    "objectID": "11-getting-started.html#where-to-go-from-here",
    "href": "11-getting-started.html#where-to-go-from-here",
    "title": "2  Getting started",
    "section": "\n2.3 Where to go from here",
    "text": "2.3 Where to go from here\nseas(AirPassengers) produces a good seasonal adjustment of the airline passengers time series. If you are very new to seasonal adjustment, the automated routines of X-13 and seasonal produce an adjustment that works well in most circumstances.\nThe command seas(AirPassengers) has invoked a large number of specs of X-13. spec is X-13 slang for a module within the software. X-13 is built on top of twenty specs that perform various subtasks of seasonal adjustment. Some specs are required most of the time (e.g., regression), while others are optional (e.g., seats) or purely technical (e.g., spans shortens the time series in use). Chapter 3 discusses the available specs in more detail.\nThis book teaches you how to use and fine-tune the individual specs and deal with concrete data problems.\n\n2.3.1 Fundamentals\nSpecifically, the command seas(unemp) has invoked the following fundamental specs – they are involved in most adjustments and are covered in the first part of the book:\n\nTransform\n\nA decision on initial transformation was made. The automated procedures concluded that a log transformation was made and a multiplicative seasonal adjustment model, rather than an additive model, was estimated. Chapter 4 discusses the choices. Since transform is a relatively simple spec, it is a good starting point to familiarize yourself with the spec idea.\n\nRegression\n\nAn automated model search concluded that AirPassengers is best modeled by an (0 1 1)(0 1 1) ARIMA model. Chapter 5 explains what that means and how such a model structure is determined and estimated.\n\nSEATS / X11\n\nSeasonal decomposition is performed by SEATS. SEATS is one of the two options for decomposing a series and is discussed in more detail in Chapter 7. The alternative, X11, is discussed in Chapter 6.\n\n\n2.3.2 Data issues\nThe command seas(AirPassengers) has also dealt with various data issues, which are covered in the second part of the book:\n\nHoliday\n\nSignificant Easter effects have been found in AirPassengers and were removed from the adjusted series. Moving holidays like Easter or Chinese New Year are vital in seasonal adjustment since they may significantly impact the behavior of many time series. For AirPassengers, the number of passengers is higher in months with Easter. Moving holiday effects will be discussed in Chapter 8.\n\nWeekday\n\nNot every month has the same number of weekdays. Since many activities (such as air traveling) differ between weekends and weekdays, this constitutes another predictable component. In AirPassengers, there are fewer passengers on a weekday than during a weekend, and the automated procedures decided to remove the effect. These effects are discussed in Chapter 9.\n\nOutliers\n\nCertain data points may be well out of the ordinary. These outliers are a problem for the modeling and adjustment process. An automated procedure scanned the series for outliers and found an additive outlier on May 1951. This outlier is shown in the plot above, too. Outliers are discussed in Chapter 10.\n\nSeasonal Breaks\n\nThe seasonal pattern in AirPassengers looks relatively stable. Some time series, however, show abrupt changes in the seasonal pattern. Chapter 11 discusses them and shows how to deal with seasonal breaks.\n\n\n2.3.3 Additional issues\nThe third part of the book deals with additional issues:\n\nPresence of seasonality\n\nWhile the presence of seasonality in AirPassengers is prominent, this is not always the case. If a series has no seasonal pattern, there is no need for a seasonal adjustment. If it is adjusted anyway, the process adds noise to the series and should be avoided. Chapter 12 shows how seasonality can be detected and how to decide whether an adjustment should be made or not.\n\nAnnual constraining\n\nUsually, a seasonal adjustment may affect the annual values of a time series. In part, this is by design. The number of weekdays may differ between years, so the adjusted annual values may be different too. In part, this may be an artifact of the adjustment process. X-13 offers tools to enforce the annual values of the adjusted series to be the same as the original one. Chapter 13 shows how to constrain annual value and whether it is a good idea.\n\nIndirect vs. direct adjustment\n\nOften, a seasonal adjustment may be performed on individual series or on an aggregate of multiple series. X-13 offers tools that let you compare these two possibilities. Chapter 14 discusses the options and helps you to decide which one is better.\n\n\n2.3.4 Quality assessment\nAdjusting a series with the automated procedure is straightforward. But is the resulting series a reasonable adjustment? The fourth part helps you to decide between competing seasonal adjustment models.\n\nQuality measures\n\nIn the lower part, the summary of the adjustment model shows various quality measures: The AICc and BIC information criterion and the QS, the Box-Ljung, and the Shapiro statistic. None of them shows any significance (indicated by one or several stars), which is a good sign. Various quality measures and their interpretation is shown in Chapter 15.\n\nRevisions\n\nWhen comparing seasonal adjustment models, the stability of the model and the series is often an important consideration. One does not want to get a different series with a new data point. X-13 offers tools to analyze revisions. Chapter 16 discusses them and helps you to decide which model to pick."
  },
  {
    "objectID": "11-getting-started.html#exercises",
    "href": "11-getting-started.html#exercises",
    "title": "2  Getting started",
    "section": "\n2.4 Exercises",
    "text": "2.4 Exercises\n Exercises\n\n\nRunning a basic seasonal adjustment:\n\nRun the following code to perform a seasonal adjustment on the unemp dataset and plot the results.\nWhy is the seasonally adjusted series not entirely smooth? What components are still present in the adjusted series?\n\n\n\nWorking with AirPassengers:\n\nPerform a seasonal adjustment on the AirPassengers data using the seas function and plot the results.\nDescribe the seasonal pattern observed in the original series and how it changes in the adjusted series.\n\n\n\nInterpreting the summary output:\n\nRun the summary function on the seasonal adjustment model m from the AirPassengers dataset.\nIdentify and explain the key diagnostics provided in the summary output.\nDiscuss how these diagnostics help in evaluating the quality of the seasonal adjustment.\n\n\n\nExploring seasonal adjustment with different data:\n\nLoad the seasonal package and use the seas function on a different time series dataset, such as nottem (average air temperatures in Nottingham).\nPerform a seasonal adjustment on the nottem dataset and plot the results.\nDiscuss any visible patterns and how the seasonal adjustment has altered the original series."
  },
  {
    "objectID": "20-part-basics.html",
    "href": "20-part-basics.html",
    "title": "Basics",
    "section": "",
    "text": "This section gets readers familiar with X-13ARIMA-SEATS. It begins by explaining the history and pedagogy of the software (Chapter 3). This leads directly into discussing the principal elements of X-13ARIMA-SEATS."
  },
  {
    "objectID": "21-overview.html#main-specs",
    "href": "21-overview.html#main-specs",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.1 Main specs",
    "text": "3.1 Main specs\nSome specs, like the transform and the regression spec, are used in most seasonal adjustment processes. Others fulfill a particular function and are used only occasionally. For example, the history spec allows an analysis of the revision history and is only called for diagnostical purposes. Other specs are mutually exclusive. You can choose x11 or seats to decompose a time series, but not both. Table 3.1 lists the main specs of X-13 and describes what they do.\n\n\nTable 3.1: Important specs that are used in most seasonal adjustment models\n\n\n\n\n\n\nSpec name\nWhat it does\nChapter\n\n\n\nestimate\nEstimates the regARIMA model specified by the regression and arima specs.\nChapter 5\n\n\narima\nSpecifies the ARIMA part of the regARIMA model.\nChapter 5\n\n\nregression\nSpecification for including regression variables in a regARIMA model.\n\nChapter 5, Chapter 8, Chapter 9\n\n\n\nautomdl\nSpecifies the ARIMA part of the regARIMA model using an automatic procedure.\nChapter 5\n\n\noutlier\nSpecification to perform automatic detection of additive (point) outliers.\nChapter 10\n\n\nseats\nInvoke the production of model-based signal extraction using SEATS. Default in the R seasonal package.\nChapter 7\n\n\nx11\nAn optional spec for invoking seasonal adjustment by the X-11 methodology.\nChapter 6\n\n\nforecast\nSpecification to forecast and/or backcast the time series given in the series spec using the estimated model.\nChapter 5"
  },
  {
    "objectID": "21-overview.html#interactions-between-specs",
    "href": "21-overview.html#interactions-between-specs",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.2 Interactions between specs",
    "text": "3.2 Interactions between specs\nX-13 specs interact with each other. For example, once a series is transformed, it is usually passed to the regression and arima specs, which estimate a regARIMA model. To come up with a good model, it uses the automdl spec to determine a good ARIMA model automatically. To correct outlier values, it collaborates with the outlier spec. Once the series is modeled, it is decomposed either by the seats or the x11 spec. Figure 6.1 shows the interaction between the main specs in a typical seasonal adjustment run.\n\n\n\n\n\nflowchart LR\n    A(  transform  )--&gt;regARIMA\n    subgraph regARIMA\n    direction LR\n    B(estimate)&lt;--&gt;D(regression)\n    B&lt;--&gt;C(automdl)\n    B&lt;--&gt;E(arima)\n    end\n    regARIMA --&gt; F(seats)\n    regARIMA --&gt; G(x11)\n\n\nFigure 3.1: Interactions between X-13 specs."
  },
  {
    "objectID": "21-overview.html#specs-arguments",
    "href": "21-overview.html#specs-arguments",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.3 Specs Arguments",
    "text": "3.3 Specs Arguments\nWithin specs, there are arguments. Spec arguments guide the behavior of the spec. For example, the function argument in the transform spec can be set to \"auto\", \"none\", \"log\", \"sqrt\", \"inverse\" or \"logistic“. The default is set to \"auto\", which causes an automated model evaluation between \"log\" and \"none\". There are many other arguments, and the X-13 Manual (US Census Bureau 2017) is the canonical reference. This book will list and explain the frequently used arguments while skipping some of the more exotic ones.\n\nUS Census Bureau. 2017. X-13ARIMA-SEATS Reference Manual. Version 1.1. Washington, DC, USA: Time Series Research Staff, Center for Statistical Research; Methodology, US Census Bureau. https://www2.census.gov/software/x-13arima-seats/x-13-data/documentation/docx13as.pdf."
  },
  {
    "objectID": "21-overview.html#addressing-specs-from-r",
    "href": "21-overview.html#addressing-specs-from-r",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.4 Addressing specs from R",
    "text": "3.4 Addressing specs from R\nIn the R package seasonal, spec argument combinations can be directly fed to the seas() function. For example, to turn off the log transformation in the AirPassengers example from Section 2.2, we can specify the following:\n\nm_no_log &lt;- seas(AirPassengers, transform.function = \"none\")\nsummary(m_no_log)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, transform.function = \"none\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Constant          30.62077    4.60956   6.643 3.08e-11 ***\n#&gt; Leap Year         11.32104    3.43088   3.300 0.000968 ***\n#&gt; Weekday           -0.90361    0.17787  -5.080 3.77e-07 ***\n#&gt; Easter[1]          6.89372    1.80972   3.809 0.000139 ***\n#&gt; AR-Nonseasonal-01  0.81929    0.04903  16.709  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 0 0)(0 1 0)  Obs.: 144  Transform: none\n#&gt; AICc: 993.4, BIC:  1010  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.):  29.2   Shapiro (normality): 0.984\n\nAs you can see from the lower part of the summary, transform is now set equal to none. Note that the change in the transform argument has also affected the other specs. The ARIMA model is different now, and a leap-year adjustment is performed. We will discuss the working of the transform spec in more detail in the next chapter."
  },
  {
    "objectID": "21-overview.html#less-frequently-used-specs",
    "href": "21-overview.html#less-frequently-used-specs",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.5 Less frequently used specs",
    "text": "3.5 Less frequently used specs\nWhile the main specs appear in most seasonal adjustment processes, other specs are less often used. Some of them have a diagnostic purpose. The spectrum spec, for example, draws and analyses the spectrum of a time series, similar to the R base function spectrum(). Other specs are more elaborate. For example, the history spec produces a sequence of runs from a sequence of truncated versions of the time series and allows the analysis of potential revisions. The slidingspans spec models various parts of the time series and has a similar purpose as history. All diagnostics specs are listed in Table 3.3.\n\n\nTable 3.2: Diagnostic specs\n\n\n\n\n\n\nSpec name\nWhat it does\nChapter\n\n\n\nhistory\nRequesting a sequence of runs from a sequence of truncated versions of the time series for the purpose of creating historical records.\nChapter 16\n\n\nslidingspans\nProviding sliding spans stability analysis.\nChapter 16\n\n\nidentify\nProduce tables and line printer plots of sample ACFs and PACFs.\n\n\n\nspectrum\nProvides a choice between two spectrum diagnostics to detect seasonality or trading day effects.\n\n\n\ncheck\nProduce statistics for diagnostic checking of residuals from the estimated model.\n\n\n\n\n\nThe force and the composite spec are special-purpose specs. The former enforces the yearly totals of the seasonally adjusted series to be equal to those of the original series. The latter allows a comparison of indirect and direct seasonal adjustments. Table 3.3 gives an overview of the special-purpose specs.\n\n\nTable 3.3: Special purpose specs\n\n\n\n\n\n\nSpec name\nWhat it does\n\n\n\n\nforce\nAllow users to force yearly totals of the seasonally adjusted series to equal those of the original series for convenience.\nChapter 13\n\n\ncomposite\nObtaining both indirect and direct adjustments of a composite series.\nChapter 14\n\n\n\n\nFinally, a few specs are not covered in this book. Some of them are vintage specs that were important in earlier versions of X-13 but were superseded by other specs. It is generally recommended to use regression instead of x11regression and automdl instead of pickmdl. Other specs have a purely technical purpose. For example, the series spec provides X-13 with the data, starting date, and frequency. In R, this is handled by seasonal and will not be covered.\n\n\nTable 3.4: Vintage and technical specs that won’t be covered in this book)\n\n\n\n\n\nSpec name\nWhat it does\n\n\n\nx11regression\nAlternative to regression. Can only be used with X11.\n\n\npickmdl\nAlternative to automdl. Can only be used with X11.\n\n\nseries\nProvides X-13 with the data, the starting date and the frequency. In R, this is handled by seasonal and will not be covered.\n\n\nmetadata\nSpecification that allows users to insert metadata into the diagnostic summary file. In R, this is handled by seasonal and will not be covered."
  },
  {
    "objectID": "21-overview.html#main-user-choices",
    "href": "21-overview.html#main-user-choices",
    "title": "3  The fundamentals of X-13",
    "section": "\n3.6 Main user choices",
    "text": "3.6 Main user choices\nWhile we will cover each spec in more detail, this section provides a few examples of frequent user choices. As we saw in the previous chapter, by default, seasonal uses defaults that work well in many circumstances. The following is a non-exhaustive list of deviations from the defaults. The default options of seas() are listed as explicit arguments and are discussed in the arguments section of the help page of\n\n3.6.1 Using X11\nWhile seas() calls SEATS by default, X11 is often easier to use. To perform a seasonal adjustment on AirPassengers with X11, we need to activate the x11 spec.\n\nm_x11 &lt;- seas(AirPassengers, x11 = list())\n\nAn empty list list() tells seas() to use the spec without an argument. Alternatively, you can also use an empty string, \"\". If more than one mutually exclusive spec is included in seas(), specs are overwritten according to the priority rules shown in Table 3.5\n\n\nTable 3.5: If more than one mutually exclusive spec is included, specs are overwritten according to priority rules.\n\n\n\n\n\nProcedure\nPriority rules\n\n\n\nModel selection\n\narima\npickmdl\nautomdl\n\n\n\nAdjustment procedure\n\nx11\nseats\n\n\n\n\n\nThis is why the default SEATS procedure in the introductory example was overwritten by the specification of x11 = \"\".\n\n3.6.2 Turning off automatic ARIMA modeling\nBy default, the automdl spec finds a good ARIMA model. By specifying the model argument of the arima spec, the automated modeling is deactivated. Instead of the automatically chosen (0 1 1)0 1 1) ARIMA model, the following estimates an (1 1 0)1 1 0) model.\n\nm_arima &lt;- seas(AirPassengers, arima.model = c(1, 1, 0, 1, 1, 0))\nsummary(m_arima)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, arima.model = c(1, 1, 0, 1, 1, 0))\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029124  0.0004794  -6.076 1.23e-09 ***\n#&gt; Easter[1]          0.0167907  0.0067080   2.503   0.0123 *  \n#&gt; AO1951.May         0.0950587  0.0194363   4.891 1.00e-06 ***\n#&gt; AR-Nonseasonal-01 -0.1078564  0.0871940  -1.237   0.2161    \n#&gt; AR-Seasonal-12    -0.4588948  0.0790634  -5.804 6.47e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 1 0)(1 1 0)  Obs.: 144  Transform: log\n#&gt; AICc: 951.6, BIC: 968.1  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 35.88 . Shapiro (normality): 0.9937\n\n\n3.6.3 Turning off AIC testing for outlier detection and regressors\nBy default, seas() evaluates the presence of weekday and Easter effects and checks for outliers in the data. Both can be turned off:\n\nm_no_auto &lt;- seas(AirPassengers, regression.aictest = NULL, outlier = NULL)\nsummary(m_no_auto)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL)\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; MA-Nonseasonal-01  0.40181    0.07887   5.095  3.5e-07 ***\n#&gt; MA-Seasonal-12     0.55695    0.07626   7.304  2.8e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 987.4, BIC: 995.8  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.04   Shapiro (normality): 0.9886  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nIn practice, many spec argument combinations can be extracted via the static() functions, which will be demonstrated in the next chapter. Alternatively, the seasonalview package offers a graphical user interface that allows you to click various spec argument combinations.\nm &lt;- seas(AirPassengers)\nview(m)\n\n\nManipulating spec argument combinations in the seasonalview graphical user interface"
  },
  {
    "objectID": "22-transform.html#sec-additive-and-multiplicative-adjustment",
    "href": "22-transform.html#sec-additive-and-multiplicative-adjustment",
    "title": "4  Transform",
    "section": "\n4.1 Additive and multiplicative adjustment",
    "text": "4.1 Additive and multiplicative adjustment\nAs you remember from Chapter 1, Seasonal adjustment decomposes a time series into a trend, a seasonal, and an irregular component. Algebraically, the fundamental identity of seasonal adjustment looks like this:\n\\[Y_t = T_t + S_t + I_t. \\tag{4.1}\\]\nWe seek the decompose our observed series \\(Y_t\\) into a trend \\(T_t\\), a seasonal \\(S_t\\), and an irregular \\(I_t\\) component. The formulation above is additive, i.e., the trend, the seasonal, and the irregular component sum up to the observed series. The goal of seasonal adjustment is to subtract the seasonal component:\n\\[A_t = Y_t - S_t.\\]\nFor example, an observed value of 100 with a seasonal compontent of -3.2 would result in a seasonally adjusted value of 100 - 3.2 = 96.8.\nAlternatively, the decomposition can be multiplicative:\n\\[Y_t = T_t \\cdot S_t \\cdot I_t \\tag{4.2}\\]\nI.e., the observed series is the product of the trend and the seasonal and irregular components. Since these are factors, the goal of seasonal adjustment is to remove seasonality by dividing by the seasonal factor.\n\\[A_t = \\frac{Y_t}{S_t}.\\]\nFor example, an observed value of 100 with a seasonal factor of 1.08 would result in a seasonally adjusted value of 100 / 1.08 = 92.6. In a multiplicative model, values of \\(S_t &gt; 1\\) decrease the observed value, and \\(S_t &lt; 1\\) increase it.\nWhen analyzing seasonal components, the transformation is crucial. For example, monthplot() plots the evolution of the seasonal component for each period over time (shown by the evolving red line; the red bar shows its average). If the model is multiplicative, the seasonal component is a factor ranging from 0.8 to about 1.3. If the model is additive, the seasonal component is a summand ranging from about -100 airpassengers to about +130.\n\nmonthplot(m_log)\nmonthplot(m_none)\n\n\n\n\n\n\n\nFor a multiplicative adjustment, it is sufficient to apply logarithms to the initial series and then re-transform the results following the decomposition. With no transformation, X-13 will perform an additive seasonal adjustment as specified in Equation 4.1. With log transformation, X-13 will perform a multiplicative adjustment as specified in Equation 4.2."
  },
  {
    "objectID": "22-transform.html#sec-auto-transform",
    "href": "22-transform.html#sec-auto-transform",
    "title": "4  Transform",
    "section": "\n4.2 Automated transformation choice",
    "text": "4.2 Automated transformation choice\nX-13 has a built-in statistical test determine the appropriateness of applying logarithmic transformation. The choice is made by comparing the AICc1 value of an ARIMA (0 1 1)(0 1 1) model (or, optionally, a user-specified model) to the log-transformed series and the original series.1 With small sample sizes, a standard AIC test may select models with too many parameters. AICc tackles this problem by correcting for sample size.\nFor most practical purposes, the automatic selection mechanism is quite reliable and can be trusted to make the appropriate choice. However, if your data series contains negative values, logarithmic transformation is not feasible, and the software will automatically adapt its selection process accordingly.\n\n\nTo examine the outcomes of these transformation tests, one can refer to specific statistics: The udg() function grants access to broad array of diagnostic statistics. The qs() function and the AIC(), BIC() and logLik() methods are wrappers that use udg() to access some specific diagnostic statistics. For example, if we want to access the AICc values that were used to determine the appropriateness of the logarithmic model, we use:\n\nm &lt;- seas(AirPassengers)\nudg(m, c(\"aictest.trans.aicc.nolog\", \"aictest.trans.aicc.log\"))\n#&gt; aictest.trans.aicc.nolog   aictest.trans.aicc.log \n#&gt;                1021.1919                 987.3845\n\nThe AICc for the log transformed model is lower than the for the untransformed one. That is why the automated procedure has selected a log transformation, as we have seen previously in Chapter 2."
  },
  {
    "objectID": "22-transform.html#prior-modifications",
    "href": "22-transform.html#prior-modifications",
    "title": "4  Transform",
    "section": "\n4.3 Prior modifications",
    "text": "4.3 Prior modifications\nPrior modifications describe a second, less commonly used transformation in X-13. A prior modification scales each observation for known fixed effects. These effects can be well-known and established, such as the length of a period or leap-year effects, or they can be more subjective such as a modification for a workers’ strike.\nWe can think of prior-modification factors as events or corrections made to your data that are fixed throughout the adjustment process. These prior modification factors can also be permanent (default) or temporary. Permanent modifications are excluded from the final seasonal adjustment. Temporary modifications are removed while calculating seasonal factors but added back to the seasonally adjusted series.\nIn most cirumstances, incorporating external effects in a seasonal adjustment model would be left to the regression part in regARIMA, and will be covered in Chapter 5."
  },
  {
    "objectID": "22-transform.html#transform-options",
    "href": "22-transform.html#transform-options",
    "title": "4  Transform",
    "section": "\n4.4 Transform options",
    "text": "4.4 Transform options\n\n\n\nFrequently used spec arguments in the transform spec\n\n\n\n\n\n\nArguments\nDescription\nExample values\n\n\n\ntransform.function\nTransform function\n\nnone, log, auto\n\n\n\ntransform.aicdiff\nadjust tolerance of AIC test for log transform\n\n-2, 0, 3\n\n\n\nxtrans\nPrior adjustment factor\n\n\n\n\nThe transform spec controls these options. Some primary options within this spec are"
  },
  {
    "objectID": "22-transform.html#case-study-airpassengers",
    "href": "22-transform.html#case-study-airpassengers",
    "title": "4  Transform",
    "section": "\n4.5 Case Study: AirPassengers\n",
    "text": "4.5 Case Study: AirPassengers\n\n\nWhy does AirPassengers seem to follow a multiplicative model of seasonal adjusmtent? The answer is heteroskadasticity, or a varying variance. As the number of air passengers grow over time, so does their seasonality. With just a few people flying, we would expect the seasonal component to be small in absolute numbers. With many people using airplanes, the seasonal component is bigger in absolute numbers. In such a series, it makes more sense describe seasonality in a multiplicative model, and thus to log tranform the series before modeling.\nThis is a characteric of many economic time series, wich often exibit a growth in the trend.\nThis is also a good place to get our first look at the seasonal factors. The monthplot() method offers a convenient way to look at these:\n\nmonthplot(m)\n\n\n\n\nLike the R base monthplot() function that can be applied on any time series (also on quarterly time series!), this groups time series data by months. If you look at the January (J), entry, the blue bars show the evolution of the detrended data from 1949 to 1960. The red bar shows the average seasonal factor over these years. The smooth red lines show the seasonal factors as estimated by the model.\nAs you can see from the plot, there are more passengers during the summer months and fewer in the winter. The seasonal factors change over time. The summer peak becomes more pronounced in later years, while the local peak in February and March disappears over time.\nIf you want to extract the seasonal factor directly into R, you can use the series() function:\nseries(m, \"seats.seasonal\")"
  },
  {
    "objectID": "22-transform.html#case-study-a-more-difficult-decision",
    "href": "22-transform.html#case-study-a-more-difficult-decision",
    "title": "4  Transform",
    "section": "\n4.6 Case Study: A more difficult decision",
    "text": "4.6 Case Study: A more difficult decision\nConsider the situation where you are trying to decide on transform choices for monthly retail grocery store data. The series grocery is part of the seasonalbook package.\n\nlibrary(seasonalbook)\nplot(grocery)\n\n\n\n\nVisual inspection of the series shows no immediate reason to think we need to perform a logarithmic transform. There is possible seasonal heteroskadasity which could be mitigated by taking logs. Perform an X-11 adjustment with all the defaults of seasonal\n\nm &lt;- seas(grocery, x11 = \"\")\nudg(m, c(\"aictest.trans.aicc.nolog\", \"aictest.trans.aicc.log\"))\n#&gt; aictest.trans.aicc.nolog   aictest.trans.aicc.log \n#&gt;                 4202.960                 4201.042\n\nThis is interesting since the AICc for no transformation is lower than the AICc for log transform.\n\ntransformfunction(m)\n#&gt; [1] \"log\"\n\nThe default value for transform.aicdiff is -2, meaning the program slightly prefers log transform, and the difference between the AICc values must exceed 2. In this situation, the difference between the AICc values is -1.917597. Suppose you were to change this option to transform.aicdiff = 0, then the program selects no transform.\n\nm2 &lt;- seas(grocery, x11 = \"\", transform.aicdiff = 2)\ntransformfunction(m2)\n#&gt; [1] \"none\""
  },
  {
    "objectID": "22-transform.html#exercises",
    "href": "22-transform.html#exercises",
    "title": "4  Transform",
    "section": "\n4.7 Exercises",
    "text": "4.7 Exercises\n\n\nUnderstanding log transformations:\n\nPerform a seasonal adjustment on the AirPassengers data using the default settings. Plot the results. Which transformation has been applied?\nThen, perform the same seasonal adjustment but override the transformation function to be \"none\". Plot the results.\nCompare the plots and describe how the transformation affects the seasonally adjusted series.\n\n\n\nInterpreting AICc values:\n\nPerform a seasonal adjustment on the AirPassengers data using the default settings.\nUse the udg() function to access the AICc values for both the log-transformed and the untransformed models. Compare these values and explain why the log transformation was chosen by the automated procedure.\n\n\n\nExploring additive and multiplicative models:\n\nPerform a seasonal adjustment on the AirPassengers data using both additive and multiplicative models by specifying the appropriate transformation functions.\nUse the monthplot() function to visualize the seasonal components for both models. Compare the seasonal components and discuss how they differ between the additive and multiplicative models.\n\n\n\nDeciding on a transformation:\n\nPerform a seasonal adjustment on the grocery data using the default settings.\nCompute the AICc values for both the log-transformed and the untransformed models using the udg() function. Compare these values and explain which transformation would be more appropriate based on the AICc values.\nExperiment with changing the transform.aicdiff option to see how it affects the transformation choice."
  },
  {
    "objectID": "23-regARIMA.html#arima-basics",
    "href": "23-regARIMA.html#arima-basics",
    "title": "5  regARIMA Model",
    "section": "\n5.1 ARIMA Basics",
    "text": "5.1 ARIMA Basics\nThe regARIMA model combines two elements: regression and ARIMA. The ARIMA segment itself is composed of a differencing order (the “I”, for “integrated”) and the ARMA part. This chapter aims to simplify these concepts without getting too technical, providing enough understanding for effective seasonal adjustment.\nARIMA stands for Autoregressive Integrated Moving Average. “Autoregressive” (AR) means the model uses past values of the series to predict the current value. For instance, an AR(1) model uses one lagged value:\n\\[ Y_t = \\phi Y_{t-1} + a_t \\]\nHere, \\(Y_t\\) is the time series, \\(\\phi\\) a coefficient, and \\(\\{a_t\\}\\) an uncorrelated sequence of errors.1\nAn AR(p) model extends this to \\(p\\) lagged values:\n\\[ Y_t = \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + a_t \\]\nwhere now we have \\(p\\) coefficients \\(\\phi_1, \\phi_2, \\ldots, \\phi_p\\) to be estimated.\n\nThe “Moving Average” (MA) part uses past errors of the series for prediction. An MA(1) model looks like:\n\\[ Y_t = a_t + \\theta a_{t-1} \\]\nand uses the current and one lagged error term.2\nAn MA(q) model includes \\(q\\) lagged error terms:\n\\[ Y_t = a_t + \\theta_1 a_{t-1} + \\theta_2 a_{t-2} + \\cdots + \\theta_q a_{t-q} \\].\n\nAn ARMA(p, q) model combines these AR and MA components, using \\(p\\) lagged values of the series and \\(q\\) lagged error terms. In practice, X13’s automatic modeling usually finds appropriate \\(p\\) and \\(q\\) values. However, it is worth paying attention to correctly set the differencing and regression variables for seasonal adjustment."
  },
  {
    "objectID": "23-regARIMA.html#differencing",
    "href": "23-regARIMA.html#differencing",
    "title": "5  regARIMA Model",
    "section": "\n5.2 Differencing",
    "text": "5.2 Differencing\nARMA models are most effective with stationary time series, where both the mean and correlation structure do not vary over time. For non-stationary time series, transforming them into stationary ones is essential, and differencing is a widely used method for this purpose. It is known that differencing a series \\(k\\) times can remove a polynomial trend of degree \\(k\\). Therefore, the first differencing is effective for a series with a linear trend, while the second differencing works for a series with a quadratic trend.\nSeasonal patterns might also require seasonal differencing to achieve stationarity. The orders of differencing for the non-seasonal and seasonal parts are denoted as \\(d\\) and \\(D\\), respectively. Combining these with the stochastic model specification gives the notation SARIMA(p, d, q)(P, D, Q), where \\(p\\), \\(d\\), \\(q\\) are non-seasonal parameters, and \\(P\\), \\(D\\), \\(Q\\) are seasonal.3:3 The “S” in SARIMA stands for seasonal. Since most of the ARIMA models within X-13 are seasonal, we will restrain from using the term and usually refer to an ARIMA model of the structure (p, d, q)(P, D, Q).\n\\[\\text{SARIMA}\\underbrace{(p, d, q)}_{\\text{non-seasonal }}\\underbrace{(P, D, Q)}_{\\text{seasonal}}.\\]\nLet’s apply this to AirPassengers. A log-transformed version of the series looks as follows:\n\nplot(log(AirPassengers))\n\n\n\n\nThis series exhibits a clear increasing trend and seasonal pattern. Let’s call the log-transformed series \\(X_t\\). We can now difference the series to make \\(Y_t = \\Delta X_t = X_t - X_{t-1}\\). Which looks like:\n\nplot(diff(log(AirPassengers)))\n\n\n\n\nThe trend is removed, but some seasonal patterns remain. Seasonal differencing is then applied to the already first differenced series \\(Y_t\\):\n\\[ Z_t = Y_t - Y_{t-12} \\]\nA plot of \\(Z_t\\):\n\nplot(diff(diff(log(AirPassengers)), 12))\n\n\n\n\nNow, both the linear trend and seasonal patterns are removed, leaving a stationary process suitable for modeling with an (0, 0, 1)(0, 0, 1) ARIMA model. When the differencing order for both seasonal and non-seasonal components is included, the model becomes (0, 1, 1)(0, 1, 1), often called the “airline model” after Box and Jenkins’ work.44 The “airline model,” or the ARIMA(0, 1, 1)(0, 1, 1) model, was popularized by Box and Jenkins (1970) through their influential work in the field of time series analysis. This model is often associated with their seminal book “Time Series Analysis: Forecasting and Control.” First published in 1970, this book has been a foundational text in the field of time series analysis. The airline model, named for its application in modeling airline passenger data, exemplifies the application of Seasonal ARIMA modeling in practical scenarios.\nBox, George E. P., and Gwilym M. Jenkins. 1970. Time Series Analysis: Forecasting and Control. San Francisco: Holden-Day."
  },
  {
    "objectID": "23-regARIMA.html#automated-arima-modeling",
    "href": "23-regARIMA.html#automated-arima-modeling",
    "title": "5  regARIMA Model",
    "section": "\n5.3 Automated ARIMA modeling",
    "text": "5.3 Automated ARIMA modeling\nBy default, seas() invokes the automdl spec to perform an automated ARIMA model search.\nUnsurprisingly, the basic call to seas(AirPassengers) opts for the (0, 1, 1)(0, 1, 1) “airline model” that has its name from the series:\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nTechnically, model identification starts with determining the appropriate level of differencing, both seasonal and non-seasonal. Following this, the procedure compares various ARIMA models and opts for one with a low information criterion. The fivebestmdl() function can be used to look into some contenders for ‘good models’. These models are ranked based on their Bayesian Information Criterion (BIC):\n\nfivebestmdl(m)\n#&gt;            arima    bic\n#&gt; 1 (0 1 0)(0 1 1) -4.007\n#&gt; 2 (1 1 1)(0 1 1) -3.986\n#&gt; 3 (0 1 1)(0 1 1) -3.979\n#&gt; 4 (1 1 0)(0 1 1) -3.977\n#&gt; 5 (0 1 2)(0 1 1) -3.970"
  },
  {
    "objectID": "23-regARIMA.html#regression",
    "href": "23-regARIMA.html#regression",
    "title": "5  regARIMA Model",
    "section": "\n5.4 Regression",
    "text": "5.4 Regression\nAfter ARIMA and differencing, the final element of regARIMA is the regression component. The regression component describes the effect of exogenous variables on the residuals of an ARIMA model.\nIf no transformation or intervention is needed, the regARIMA model takes the following form:5\nThe left-hand side of an regARIMA can be transformed and adjusted for subjective interventions. In such cases, the regARIMA formula extends to:\n\\[\nf\\left(\\frac{Y_t}{D_t} \\right) = \\boldsymbol{\\beta}^\\prime {\\mathbf X}_t + Z_t\n\\]\nThe function \\(f\\) represents a transformation, with the logarithmic transformation (\\(f(x) = \\log(x)\\)) being a common choice. \\(D_t\\) represents any interventions applied before transformation or modeling. These interventions are often specific to each time series and are applied based on the unique circumstances of the data. For example, if an event like a soybean farmer strike affects the data series, this intervention can help adjust the data before further analysis.\n\n\\[\nY_t = \\underbrace{\\boldsymbol{\\beta}^\\prime {\\mathbf X}_t}_{\\text{regression}} + \\underbrace{Z_t}_{\\text{ARIMA}}\n\\]\nIn this model, \\(Y_t\\) is the observed time series. The regression component is \\({\\mathbf X}_t\\) and \\(Z_t\\) represents the ARIMA process. The key difference between a regARIMA model and classical linear models is the assumption about \\(Z_t\\). In regARIMA, \\(Z_t\\) is an ARIMA process, where in classic models the error terms are typically assumed to be uncorrelated.\nFor effective seasonal adjustment, it’s crucial to accurately specify the regARIMA model. Often, the automated modeling capabilities of X-13 are sufficient for determining a suitable model. This auto-generated model can also act as a starting point for further refinement of the regARIMA model. The seasonal package incorporates the automatic identification feature by default, and makes the process user-friendly and streamlined."
  },
  {
    "objectID": "23-regARIMA.html#automated-regressor-identification",
    "href": "23-regARIMA.html#automated-regressor-identification",
    "title": "5  regARIMA Model",
    "section": "\n5.5 Automated regressor identification",
    "text": "5.5 Automated regressor identification\nBy default, the seas() command performs various automated regressor tests:\n\nOutlier\nIrregular Holidays (Easter)\nWeekday regressors\n\nFor example, the basic call to seas() reveals the presence of Weekday, Easter and Outlier effects in the AirPassengers data:\n\nsummary(seas(AirPassengers))\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nWe will cover these regressors in more detail in later chapters. The decision whether to include a regressor is typically left to an augmented AICc test, which we already covered in Section 4.2.\nIn production, the general rule is to not use automatic modeling. This implies that if you plan to include seasonal adjustment as part of a regular, large-scale data processing routine (such as monthly operations), it’s not recommended to run automatic model identification each month. A better approach is to use automatic model selection once and then set the chosen model permanently in the specification. The static() function from the seasonal package can automate this process."
  },
  {
    "objectID": "23-regARIMA.html#case-study-airpassengers",
    "href": "23-regARIMA.html#case-study-airpassengers",
    "title": "5  regARIMA Model",
    "section": "\n5.6 Case Study: AirPassengers\n",
    "text": "5.6 Case Study: AirPassengers\n\nOnce again, consider the default seasonal adjustment:\n\nm1 &lt;- seas(AirPassengers, x11 = \"\")\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, x11 = \"\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - Visually significant seasonal and trading day peaks have\n#&gt;   been found in one or more of the estimated spectra.\n\nThis time, we are using the X-11 method, rather than SEATS, which is the default in seasonal. (We will cover the distinction between X-11 and SEATS in the next chapters.) We can see from the summary that X-13 has opted for an (0 1 1)(0 1 1) ARIMA model. The udg() is an accessor function for many statistics, and can be used to extract the model directly:\n\nseasonal::udg(m, \"automdl\")\n#&gt;          automdl \n#&gt; \"(0 1 1)(0 1 1)\"\n\nIf we want to hard-code this model for subsequent runs, and turn off automatic model identification, this can be done via\n\nstatic(m1)\n#&gt; seas(\n#&gt;   x = AirPassengers,\n#&gt;   x11 = \"\",\n#&gt;   regression.variables = c(\"td1coef\", \"easter[1]\", \"ao1951.May\"),\n#&gt;   arima.model = \"(0 1 1)(0 1 1)\",\n#&gt;   regression.aictest = NULL,\n#&gt;   outlier = NULL,\n#&gt;   transform.function = \"log\"\n#&gt; )\n\nIf you run this code in R, you will get the same result as with the original specification.\nseasonal allows you to use all options available in X-13. In the following, we want to explore the use of outlier.span to fine-tune automated outlier detection. With the span option, you can limit the outlier detection to a certain time span. Note from previous chapters that we combine spec names and spec arguments by a dot (.).\nWe also set outlier.critical manually to override the default value that adjusts to the length of the outlier span:\n\nm_span &lt;- seas(\n  AirPassengers,\n  outlier.critical = 4.0,\n  outlier.span = \"1958.jan, \"\n)\nsummary(m_span)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier.critical = 4, outlier.span = \"1958.jan, \")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.002644   0.000604  -4.377 1.20e-05 ***\n#&gt; Easter[1]          0.021321   0.008395   2.540  0.01110 *  \n#&gt; MA-Nonseasonal-01  0.235404   0.083756   2.811  0.00495 ** \n#&gt; MA-Seasonal-12     0.543743   0.074644   7.284 3.23e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 965.3, BIC: 979.2  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.26   Shapiro (normality): 0.9829 .\n\n\nm_nospan &lt;- seas(\n  AirPassengers,\n  outlier.critical = 4.0\n)\nsummary(m_nospan)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier.critical = 4)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nBy limiting the span for outlier detection to the last 3 years, we don’t allow the procedure to detect the additive outlier in 1951. As we can see, small changes in outlier identification can have a substantial effect on the estimated regARIMA parameters."
  },
  {
    "objectID": "23-regARIMA.html#exercises",
    "href": "23-regARIMA.html#exercises",
    "title": "5  regARIMA Model",
    "section": "\n5.7 Exercises",
    "text": "5.7 Exercises\n\n\nPerforming an automated seasonal adjustment:\n\nPerform a seasonal adjustment on the fdeaths data using the default settings.\nPlot the results and summarize the key components of the model.\n\n\n\nInspecting model parameters:\n\nInspect the model chosen for the fdeaths dataset.\nIdentify the degrees of seasonal and non-seasonal differencing.\nDetermine the seasonal and non-seasonal AR and MA orders.\n\n\n\nUsing the static() function:\n\nUse the static() function to extract the static version of the automated model chosen for the fdeaths dataset.\nReplace the automatic procedures in the model call with the static choices made by the automated model.\n\n\n\nBonus: re-estimating using base R:\n\nRe-estimate the seasonal adjustment of fdeaths using the base R arima() function.\nCompare the coefficients from the arima() function with those from the seas() function.\nExplain why the coefficients might differ between the two methods."
  },
  {
    "objectID": "24-x11.html#basics",
    "href": "24-x11.html#basics",
    "title": "6  X-11",
    "section": "\n6.1 Basics",
    "text": "6.1 Basics\nHere, we describe the basic idea behind the seasonal decomposition in X-11. To perform a seasonal adjustment in R, you can use the following code:\n\nm &lt;- seas(AirPassengers, x11 = list())\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - Visually significant seasonal and trading day peaks have\n#&gt;   been found in one or more of the estimated spectra.\n\nAs we have seen in Chapter 3, by providing an empty list, the default SEATS spec is overwritten and X-11 is activated. The line ‘X11 adj.’ in the summary indicates the use of X-11.\nX-11 utilizes predefined moving-average filters on the data. It first estimates a trend and a seasonal component, while ensuring unbiased results at the series’ margins. It also uses extreme value correction to for more robust results.\nTrend component\nEstimating the trend component is the first step of an X-11 decomposition. The trend component is estimated by applying a symmetric moving average over the series. Each point in time is averaged using a set number of observations to the left and right of the series. Because the window is symmetric, we need the series to be extended by forecasts and backcasts.\nOnce the trend component is computed, we can subtract it from the original series to compute a de-trended series.\nSeasonal component\nTo estimate the seasonal component, a seasonal filter is applied to the de-trended series. A seasonal filter is a symmetric moving average that is calculated by taking the mean of the same period across several years. For instance, the average for January would be computed using all the January values from the time series data, February would use all February values, and so on.\n\nAvoid biases\nTo ensure unbiased results at the series’ margins, forecasts from the regARIMA model (Chapter 5) are used to extend the series. The regARIMA model also serves as the foundation of the initial steps in the X-11 algorithm to remove outliers and other regression effects before application of moving-averages.\nExtreme Values\nThe X-11 method is sensitive to outliers. To correct for these, X-11 applies a specialized extreme value correction. This procedure identifies extreme values and replaces them. This results in a robust procedure that can automatically choose filters and identify extreme values without much user intervention.\nGo in circles\nX-11 iteratively refines this process. Each iteration enhances the estimated components by selecting more appropriate filters and managing outliers and regression effects.\nIn the default adjustment from above, a decomposition is run 3 times along with a pre-processing step to fit the regARIMA model. This procedure can be seen in great detail in Ladiray and Quenneville (2012). The overview of each step:\n\nLadiray, Dominique, and Benoit Quenneville. 2012. Seasonal Adjustment with the x-11 Method. Vol. 158. Springer Science & Business Media.\n\nPart A\n\nPrior adjustments including regARIMA modeling of outliers, trading day and moving holiday effects.\n\nPart B\n\nFirst application of seasonal decomposition. Calculate initial extreme value weights.\n\nPart C\n\nSecond estimation of seasonal and trend. Final estimation of extreme value weights.\n\nPart D\n\nFinal estimation of seasonally adjusted series, seasonal factors, trend, irregular. Combined factors incorporate the trading day and moving holiday regression effects estimated in Part A"
  },
  {
    "objectID": "24-x11.html#a-simple-decomposition",
    "href": "24-x11.html#a-simple-decomposition",
    "title": "6  X-11",
    "section": "\n6.2 A Simple Decomposition",
    "text": "6.2 A Simple Decomposition\n Fundamentals\nTo deepen our understanding of the X-11 method, we begin with a manual approach in R. As a basic trend filter, we use a 2x12 moving average. The weights for this filter are distributed as follows: 1/24 for the first and last points, and 1/12 for each of the 11 points in between. We apply these weights to estimate the trend of the AirPassengers series:\n\nobserved &lt;- AirPassengers\nfilter_trend &lt;- c(1/24, rep(1/12, 11), 1/24)\ntrend &lt;- stats::filter(observed, filter = filter_trend, sides = 2)\ntsbox::ts_plot(observed, trend)\n\n\n\n\nAfter obtaining the trend, we estimate the seasonal component of the de-trended series using a 3x3 seasonal filter with weights (1,2,3,2,1)/9, applied consistently across the same season:\n\ndetrended &lt;- observed - trend\nfilter_seas &lt;- c(1, rep(0, 11), 2, rep(0, 11), 3, rep(0, 11), 2, rep(0, 11), 1) / 9\nseasonal &lt;- stats::filter(detrended, filter = filter_seas, sides = 2)\ntsbox::ts_plot(detrended, seasonal)\n\n\n\n\nSubtracting this seasonal estimate provides us with a rudimentary seasonal adjustment:\n\nadjusted &lt;- observed - seasonal\ntsbox::ts_plot(observed, adjusted)\n\n\n\n\nWhile this basic adjustment is insightful, it also reveals limitations, particularly at the series ends, underscoring the necessity for regARIMA modeling to extend forecasts. Another challenge is the interplay between trend and seasonality estimation—accurately estimating one in the presence of the other is complex.\nThese observations pave the way for the X-11 method, which iteratively refines this process. Each iteration enhances the estimated components by selecting more appropriate filters and managing outliers and regression effects."
  },
  {
    "objectID": "24-x11.html#linear-filters",
    "href": "24-x11.html#linear-filters",
    "title": "6  X-11",
    "section": "\n6.3 Linear Filters",
    "text": "6.3 Linear Filters\n Frequency Domain\nTime series analysis in the frequency domain offers a valuable perspective for understanding the behavior of time series data. If you are not familiar with the frequency domain, you may skip these sections.\nFor those interested, the frequency domain representation enhances the comprehension of how a linear filter affects a time series. Since both X-11 and SEATS utilize linear filters, this insight will deepen the understanding of whichever seasonal adjustment procedure is chosen.\nSeasonal adjustment is highly motivated by the study, estimation, and ultimately removal of regular fluctuations in a time series. The words regular fluctuations immediately lead us to trigonometric functions sine and cosine. It turns out, there exist two equivalent representations of a time series. The first, and usually easier for beginners to understand, is the time domain representation. This is expressing how \\(X_t\\) evolves as time \\(t\\) evolves. For example, an MA(1) time domain representation:\n\\[X_t = w_t + \\theta w_{t-1}\\]\nThe second, is a frequency domain representation of a series. Here, \\(X_t\\) is represented as the sum of trigonometric functions. More specifically, the spectral density of \\(X_t\\) is the fourier transform of the acf of the series. \\[f_X(\\nu) = \\sum_{h = - \\infty}^{\\infty} \\gamma(h) e^{-2\\pi i \\nu h}\\] For example, the spectral density of an MA(1) is: \\[f_X(\\nu) = \\sigma^2 \\left( 1 + \\theta^2 + 2\\theta\\cos(2\\pi\\nu) \\right)\\]\nThe important concept here is to understand that these representations are equivalent; meaning, they contain the same information about a time series, such as encoding the ACF function.\n\n\n\n\n\n\nWhere does the term “White Noise” come from?\n\n\n\nThe spectral density of an uncorrelated sequence with variance \\(\\sigma^2\\) is simply \\(f(\\nu) = \\sigma^2\\). Notice this is not a function of any frequencies, but just a constant for any \\(\\nu\\). Hence, it is a stochastic process that equally weights all frequencies in the spectrum. This is precisely where the name white noise comes from, as white light has the same property of reflecting all color bands equally, combining to produce white light.\n\n\nNow that we know we can express a time series either in the time domain or as a sum of sin and cosine curves, we get to the important part for seasonal adjustment - how does a linear filter effect the input series? Assume we want to pass a moving-average linear filter over our data \\(X_t\\) with weights \\(\\ldots, w_{-2}, w_{-1}, w_{0}, w_{1}, w_{2}, \\ldots\\). Assume the output of the linear filter will be \\(Y_t\\) such that \\[Y_t = \\sum_{j = -\\infty}^{\\infty} w_j X_{t+j} =\n\\ldots + w_{-2}X_{t-2} + w_{-1}X_{t-1} +  w_{0}X_{t} + w_{1}X_{t+1} + w_{2}X_{t+2} + \\ldots\\] This type of linear filter can be expressed as a linear operator in terms of the backshift operator \\(B\\) , where \\(BX_t = X_{t-1}\\) and \\(B^{-1}X_t = X_{t+1}\\). \\[W(B) = \\ldots + w_{-2}B^2 + w_{-1}B +  w_{0} + w_{1}B^{-1} + w_{2}B^{-2} + \\ldots\\] and hence \\(Y_t = W(B)X_t\\). We can now express the spectral density of \\(Y_t\\) in terms of the input spectral density \\(X_t\\). \\[f_Y(\\nu) = \\underbrace{\\lvert W(e^{2\\pi i \\nu}) \\rvert^2}_{\\text{Square Gain Function}} f_X(\\nu)\\]\nThere is some mathematical machinery needed when understanding exactly what the square-gain function, \\(\\lvert W(e^{2\\pi i \\nu}) \\rvert^2\\), is. However, for the sake of this text we just know that it tells us exactly the frequencies of \\(X_t\\) that amplified in the output \\(Y_t\\) as well as the frequencies of \\(X_t\\) that will be annihilated (when the square-gain function equals 0).\nLet’s look at an example spectrum for the airline model. Instead of deriving the result, the following code simulates observations from an airline model with \\(\\theta = .5\\) and \\(\\Theta = .9\\). The spectrum is then estimated using a parametric estimator using the spec.ar function. Details of this estimation can be found in Brockwell and Davis (1991).\n\nBrockwell, Peter J., and Richard A. Davis. 1991. Time Series: Theory and Methods. New York: Springer-Verlag.\n\nlibrary(forecast)\n#&gt; Registered S3 method overwritten by 'quantmod':\n#&gt;   method            from\n#&gt;   as.zoo.data.frame zoo\nset.seed(123)\nmodel &lt;- Arima(y = ts(rnorm(1000),freq=12),\n               order=c(0,1,1),\n               seasonal=c(0,1,1),\n               fixed=c(theta=-0.5, Theta=-0.9))\nx &lt;- simulate(model, nsim=10000)\nfx &lt;- spec.ar(x, order = 36, plot = TRUE)\n\n# Pass a trend filter over data\nx_trend &lt;- stats::filter(x, filter = filter_trend, sides = 2)\nfx_trend &lt;- spec.ar(x_trend, na.action = na.pass)\n\n# Remove trend to leave seasonal + irregular\nx_seasonal &lt;- x - x_trend\nfx_seasonal &lt;- spec.ar(x_seasonal, na.action = na.pass)"
  },
  {
    "objectID": "24-x11.html#x-11-filters",
    "href": "24-x11.html#x-11-filters",
    "title": "6  X-11",
    "section": "\n6.4 X-11 Filters",
    "text": "6.4 X-11 Filters\nIn the X-11 method, the choice of moving average filters plays a crucial role in seasonal adjustment. Users have the flexibility to select the length of both the trend and seasonal moving average filters, impacting the stability and responsiveness of the seasonal component. For example, the following model uses a short 3x1 filter to identify the seasonal component:\n\nm_short &lt;- seas(AirPassengers, x11.seasonalma = \"s3x1\")\nplot(m_short)\n\n\n\n\nOn the other hand, the following uses a long 3x9 filter:\n\nm_long &lt;- seas(AirPassengers, x11.seasonalma = \"s3x9\")\nplot(m_long)\n\n\n\n\nGenerally speaking, longer filters imply a more stable seasonal component and shorter filters a more changing seasonal pattern. We can see this by comparing the monthplot() outputs of the estimations.\n\nmonthplot(m_short)\n\n\n\n\nAs you can see, the seasonal component is smoother with the longer filter:\n\nmonthplot(m_long)\n\n\n\n\nLonger filters involve more data points in the calculation of the seasonal component at each time point. Therefore, they typically result in smaller revisions when new data is added to the series. However, these revisions can impact historical data values further back in the time series.\nIn contrast, shorter filters, which use fewer data points, are more likely to produce larger revisions with each new data addition. These revisions, while more significant, extend less far back into the historical data.\nIf a user does not select a filter, the X-11 method defaults to automatic filter selection. To understand the implications of filter length, consider the finite set of options available during an X-11 adjustment. Table 6.1 details the different filters that can be applied to both the seasonal and trend components of the series.\n\n\nTable 6.1: Filters available in X11\n\n\n\n\n\nValue\nDescription\n\n\n\ns3x1\n3×1 moving average\n\n\ns3x3\n3×3 moving average\n\n\ns3x5\n3×5 moving average\n\n\ns3x9\n3×9 moving average\n\n\ns3x15\n3×15 moving average\n\n\nstable\nStable seasonal filter. A single seasonal factor for each calendar month or quarter is generated by calculating the simple average of all the values for each month or quarter (taken after de-trending and outlier adjustment).\n\n\nx11default\nA 3×3 moving average is used to calculate the initial seasonal factors in each iteration, and a 3×5 moving average to calculate the final seasonal factors."
  },
  {
    "objectID": "24-x11.html#extreme-value",
    "href": "24-x11.html#extreme-value",
    "title": "6  X-11",
    "section": "\n6.5 Extreme value",
    "text": "6.5 Extreme value\nAs mentioned above, X-11 is sensitive to outliers, and applies its own extreme value adjustment (see the box for the differences between outliers and extreme values).\n\n\n\n\n\n\nOutliers and Extreme values\n\n\n\nThe terms outlier and extreme value seem interchangeable. In X-13, these refer to very different types of effects. An outlier is identified by the regARIMA model in Part A (see below) of the X-11 method. An extreme value is a value that is large enough to effect the results of a moving-average filter but is not identified by the regARIMA automatic modeling identification. Outliers are prior-adjusted out of the series, while extreme values are replaced within the X-11 procedure.\nBoth types end up in the seasonally adjusted series. Extreme values are assigned to the irregular component and are hence included in the seasonally adjusted series. Outliers get included in Part D (see below) when X-11 calculates the final seasonal factors using the original series including outlier effects.\nWe will discuss extreme values and outliers in more detail in Chapter 10.\n\n\nIn the X-11 method, along with the regressors defined in the regARIMA model (such as additive outliers or level shifts), there’s a distinct process for adjusting extreme values. After an initial trend estimation, X-11 replaces extreme values according to the following procedure:\n\n\n\n\nflowchart LR\n    A(Estimate standard deviation &lt;br&gt; of irregular, sigma)--&gt;B(Compare values to &lt;br&gt; multiples of sigma)\n    B--&gt;C(value smaller than 1.5 sigma)\n    B--&gt;D(value between 1.5 and 2.5 sigma)\n    B--&gt;E(value larger than 2.5 * sigma)\n    C --&gt; F(value unchanged)\n    D --&gt; G(value linearly weighted)\n    E --&gt; H(value fully weighted)\n\n\nFigure 6.1: Default behavior of extreme value replacement procedure.\n\n\n\nDe-trended values (in X-13 parlance, they are sometimes called SI-ratios) are replaced with an average of the two nearest values from the same period. E.g., if January 1958 is considered to be an extreme value, the values of January 1956, 1957, 1959 and 1960 will be used.\nIf a values is larger than the larger limit, it is fully replaced. If a value is smaller than the lower limit, it is not replaced. If a value lies between the limits, it a weighted average between the two surrounding values and the value itself is used.\nNote, that only non-replaced values are used to derive the replacement values. Hence, if a very small limit is used, the values that are used to derive the replacement values may be far way.\nUsers can modify the sigma thresholds (sigmalim) for extreme value conversion within the X-11 specification. Choosing smaller values lead to more extreme values and should typically result in a smoother seasonal component. This option, defined as a two-length vector that specifies when weighting should begin and when full weight of zero should be applied. Between the endpoints of the specified vector, a linear weight will be applied.\nExtreme value choices can significantly influence the seasonal adjustment outcome. For example, the default values for in AirPassengers adjustment look as follows:\n\nm &lt;- seas(AirPassengers, x11 = \"\")\nunmodified_SIratio &lt;- series(m, \"d8\")\nmodified_SIratio   &lt;- series(m, \"d9\")\nseasonal_factors &lt;- series(m, \"d10\")\ntsbox::ts_plot(cbind(unmodified_SIratio, modified_SIratio, seasonal_factors))\n\n\n\n\nAn alternative way to inspect output of X-13 is to use the out() function, which accesses the X-13 HTML output that contains a plethora of information:\n\nout(m)\n\nIf we change x11.sigmalim to c(1, 2), we get the following result:\n\nm_small_limits &lt;- seas(AirPassengers, x11 = \"\", x11.sigmalim = c(1, 2))\nunmodified_SIratio &lt;- series(m_small_limits, \"d8\")\nmodified_SIratio   &lt;- series(m_small_limits, \"d9\")\nseasonal_factors &lt;- series(m_small_limits, \"d10\")\ntsbox::ts_plot(cbind(unmodified_SIratio, modified_SIratio, seasonal_factors))"
  },
  {
    "objectID": "24-x11.html#exercises",
    "href": "24-x11.html#exercises",
    "title": "6  X-11",
    "section": "\n6.6 Exercises",
    "text": "6.6 Exercises\n Exercises\n\n\nPerforming an Automated Seasonal Adjustment with X-11:\n\nUse the seasonal package to perform an automated seasonal adjustment on the fdeaths dataset using the X-11 method.\nPlot the results and summarize the key components of the model.\n\n\n\nInspecting the Seasonal Component with monthplot():\n\nUse the monthplot() function to inspect the seasonal component of the adjusted fdeaths series.\nDescribe the observed seasonal pattern.\n\n\n\nAdjusting Filter Length:\n\nAdjust the seasonal filter length to a longer filter (s3x15) for the fdeaths dataset.\nUse the monthplot() function to compare the seasonal components between the default and longer filter.\nDescribe the differences observed.\n\n\n\nInspecting Extreme Value Adjustment:\n\nUse the out() function to inspect the extreme value adjustment for the fdeaths dataset.\nIdentify the default values for sigmalim used in the adjustment.\n\n\n\nModifying sigmalim Values:\n\nChange the sigmalim values to lower thresholds for the fdeaths dataset.\nPlot the results and use the monthplot() function to see if the changes affect the seasonal component.\nDescribe any differences observed."
  },
  {
    "objectID": "25-seats.html#model-based-decomposition",
    "href": "25-seats.html#model-based-decomposition",
    "title": "7  SEATS",
    "section": "\n7.1 Model based decomposition",
    "text": "7.1 Model based decomposition\nSignal Extraction in ARIMA Time Series, or SEATS, is a method for estimating unobserved components in a time series. It is developed from the work of Cleveland and Tiao (1976), Hillmer and Tiao (1982), Maravall (1986). If applied properly, SEATS seasonal factors are usually more stable than X-11, and the seasonally adjusted series show less revisions than X11 (see Section 7.10 for a more extensive discussion).\n\nCleveland, William P, and George C Tiao. 1976. “Decomposition of Seasonal Time Series: A Model for the Census x-11 Program.” Journal of the American Statistical Association 71 (355): 581–87.\n\nHillmer, S. C., and G. C. Tiao. 1982. “An ARIMA-Model-Based Approach to Seasonal Adjustment.” Journal of the American Statistical Association 77 (377): 63–70. http://www.jstor.org/stable/2287770.\n\nMaravall, Agustin. 1986. “Revisions in ARIMA Signal Extraction.” Journal of the American Statistical Association 81 (395): 736–40. http://www.jstor.org/stable/2289005.\nLike X-11, SEATS applies a series of filters to an observed time series, as described in Chapter 6. Like X-11, SEATS uses a forecast extended series, in order to obtain unbiased results at the margin.\nUnlike X-11, however, SEATS filters are derived from the ARIMA model of the time series. While X-11 filters are predefined and fixed, the SEATS filters are different for each ARIMA model.\nWhile X-11 offers a finite set of filters (in fact, there are seven seasonal filters available), SEATS offers an infinite set of filters. Overall, they cover a broader set of possible filter lengths, which makes SEATS a more flexible option than X-11. The available set filter lengths is the most crucial difference between X-11 and SEATS. At the same time, the additional flexibility may lead at times to filters that are undesirable. As will be shown later on, SEATS sometimes choose a filter that is too narrow, and produces an overly volatile seasonal component.\n\n\n\n\n\n\nComparing X-11 and SEATS filters\n\n\n\nX-11 filters\n\nfinite set of empirically developed moving average filters\nfixed filtering seen as easier to use (less statistical machinery)\nSEATS filters\n\nspecifies stochastic models for unobserved components\nderives seasonal adjustment filters from these models\ninfinite number of possible filter choices\nrequires more statistical machinery\n\n\n\n\n\n\n\n\n\nTODO\n\n\n\nPlots of X-11 filters vs SEATS filters\n\n\nGiven a certain ARIMA model (such as the “Airline” (0 1 1)(0 1 1) which is appropriate for the description of the AirPassengers time series), SEATS decomposes the model into separate models for the trend, the seasonal and the irregular component. This is done by the Canonical Decomposition and will be discussed in Section 7.6.\nFor a given set of ARIMA model parameter, the decomposition of the ARIMA model is almost independent of the data. For each ARIMA specification, there is a unique canonical decomposition. For an “Airline” (0 1 1)(0 1 1) model (with both moving average coefficients not being to close to 1), the trend component can be described with a (0 2 2)(0 0 0) model, while the seasonal sum of seasonal component can be described by a (0 0 11)(0 0 0) model. The parameters of these models can be derived from the parameter estimates of the initial airline model that describes the original series. The irregular component is usually white noise, described by the trivial (0 0 0)(0 0 0) model.\nThe decomposed ARIMA models imply a certain filter, which is derived by the Wiener-Kolmogorov procedure (Section 7.7)."
  },
  {
    "objectID": "25-seats.html#comparing-seats-with-x-11-filters",
    "href": "25-seats.html#comparing-seats-with-x-11-filters",
    "title": "7  SEATS",
    "section": "\n7.2 Comparing SEATS with X-11 filters",
    "text": "7.2 Comparing SEATS with X-11 filters\nIf SEATS and X-11 use similar filters, the final adjustment will be similar. Using the default arguments of seas() on AirPassengers, the adjustment is very similar:\n\nseats &lt;- seas(AirPassengers)\nx11 &lt;- seas(AirPassengers, x11 = list())\ntsbox::ts_plot(final(seats), final(x11))\n\n\n\n\nOthers have looked at comparing SEATS and X-11 filters. In Planas and Depoutot (2002) they show with X11 seasonal filter that is closest to an implied (0 1 1)(0 1 1) “Airline” SEATS model based on the \\(\\Theta\\). As a reminder, \\(\\Theta\\) refers to the seasonal moving average parameter of the ARIMA model.\n\nPlanas, Christophe, and Raoul Depoutot. 2002. “Controlling Revisions in Arima-Model-Based Seasonal Adjustment.” Journal of Time Series Analysis 23 (2): 193–213.\n\n\nFilter\nClosest Seasonal MA\nSeasonal MA Interval\n\n\n\n3x3\n0.364 - 0.400\n0.0 - 0.5\n\n\n3x5\n0.543 - 0.563\n0.51 - 0.74\n\n\n3x9\n0.723 - 0.732\n0.75 - 0.87\n\n\n3x15\n0.824 - 0.828\n0.88 - 1.00\n\n\n\nLet’s consider small vs large values of seasonal \\(\\Theta\\). Values of \\(\\Theta\\) close to zero yield a seasonal adjustment filter that has seasonal factors that change rapidly over time. This provides considerable smoothing and large revisions. These revisions will only last for a small number of years due to the shorter filters.\nValues of \\(\\Theta\\) close to one yield a seasonal adjustment filter that has seasonal factors that change slowly over time. This provides less smoothing but relatively small revisions. Any revisions that do occur will last for a longer period of time due to the longer filters.\nOverall, we may think of SEATS filters as a broader, more flexible set of filters than X-11 filers. While we have just seven filters in X-11, we have an infinite number of filters in SEATS. They cover a larger range of filters spans, ranging from filters that are much narrower than X-11 to filters that are much wider.\nSEATS greatest strength is also its greatest weakness. As we will see in the example below, SEATS sometimes chooses a filter that is very narrow. From a SEATS perspective, this makes sense: Given an ARIMA model with a very weak seasonality, the filter lengths should be chooses narrowly. From a practical perspective, the resulting seasonal component is undesirable. It is too volatile, essentially catching much of the irregular component and making the resulting seasonally adjusted series too smooth."
  },
  {
    "objectID": "25-seats.html#transitory-component",
    "href": "25-seats.html#transitory-component",
    "title": "7  SEATS",
    "section": "\n7.3 Transitory component",
    "text": "7.3 Transitory component\nSometimes SEATS includes a transitory component in its decomposition:\n\\[ X_t = T_t + S_t + R_t + I_t \\]\nThe transitory component captures short, erratic behavior that is not white noise, sometimes associated with awkward frequencies.\n\nThe variation from the transitory component should not contaminate the trend or seasonal, and removing it allows SEATS to obtain smoother, more stable trends and seasonal components.\nIn the final decomposition, the transitory and irregular components are usually combined.\nSEATS does not always estimate a transitory component"
  },
  {
    "objectID": "25-seats.html#quick-refresher-on-arima-models-and-notation",
    "href": "25-seats.html#quick-refresher-on-arima-models-and-notation",
    "title": "7  SEATS",
    "section": "\n7.4 Quick refresher on ARIMA models and notation",
    "text": "7.4 Quick refresher on ARIMA models and notation\nThe remaining of the SEATS section will heavily rely on the auto-regressive and moving-average operators \\(\\phi(B)\\) and \\(\\theta(B)\\) where \\(B X_t = X_{t-1}\\).\nIf \\(X_t\\) follows and ARIMA(\\(p\\), \\(d\\), \\(q\\)) model: \\[\n\\phi(B) X_t = \\theta(B) a_t\n\\]\n\\[\n(1 - \\phi_1 B - \\cdots - \\phi_p B^p)(1-B)^d X_t = (1 + \\theta_1 B + \\cdots \\theta_q B^q) a_t\n\\]\nFor example, in an ARIMA(2,0,1) we are modeling \\(X_t\\) as:\n\\[\nX_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + a_t + \\theta_1 a_{t-1}\n\\]\nand all model information is contained in \\(\\phi(B)\\) and \\(\\theta(B)\\). Moreover, for any specified \\(\\phi(B)\\) and \\(\\theta(B)\\) that satisfy certain causality criteria there exists a unique Wold decomposition \\[\n\\phi(B) X_t = \\theta(B) a_t  \n\\]\n\\[\nX_t = \\frac{\\theta(B)}{\\phi(B)} a_t = \\Psi(B) a_t = \\sum_{k=0}^{\\infty} \\psi_k a_{t-k}\n\\]"
  },
  {
    "objectID": "25-seats.html#seats-assumptions",
    "href": "25-seats.html#seats-assumptions",
    "title": "7  SEATS",
    "section": "\n7.5 SEATS Assumptions",
    "text": "7.5 SEATS Assumptions\n\nThe linearized series can be represented by an ARIMA model which captures the stochastic structure of the series. As a reminder, the linearized series is the series with regression effects removed.\nAfter differencing each with the ARIMA’s differencing polynomial, the components are orthogonal (uncorrelated)\n\nSEATS decomposes the auto-regressive polynomial by its roots associating them with different latent components. For example, roots near seasonal frequencies are associated with the seasonal component and roots near zero are associated with the trend component. \\[\n\\phi(B) = \\phi_T(B) \\cdot \\phi_S(B) \\cdot \\phi_R(B).\n\\]\nHence we have, \\[\nX_t =\n\\frac{\\theta(B)}{\\phi(B)} a_{t} =\n\\frac{\\theta_T(B)}{\\phi_T(B)} a_{T,t} +\n\\frac{\\theta_S(B)}{\\phi_S(B)} a_{S,t}  +\n\\frac{\\theta_R(B)}{\\phi_R(B)} a_{R,t}  + u_t\n\\]\nIf the spectra of all components in non-negative the decomposition is admissible, SEATS finds admissible models for components \\[ \\phi_T(B) T_t = \\theta_T(B) a_{T, t} \\] \\[ \\phi_S(B) S_t = \\theta_S(B) a_{S, t} \\] \\[\\phi_R(B) R_t = \\theta_R(B) a_{R, t} \\]"
  },
  {
    "objectID": "25-seats.html#sec-canonical-decomposition",
    "href": "25-seats.html#sec-canonical-decomposition",
    "title": "7  SEATS",
    "section": "\n7.6 Canonical Decomposition",
    "text": "7.6 Canonical Decomposition\nHowever, there infinite number of models that yield the same aggregate. The choices differ in how white noise is allocated among the components. This is where the Canonical Decomposition comes into play. SEATS uses the method of Pierce, Box-Hillmer, Tiao and Burman:\n\nPut all the white noise into the irregular components\nMaximize the variance of the irregular\nMinimizes the variance of the stationary transforms of the other components\n\nThis is called the Canonical Decomposition. We already stated that both X-11 and SEATS estimate the unobserved components by passing a moving-average filter over the observed data. So how do we use these implied component models to get a linear filter? It should be clear that the filter weights will depend on that arima model is picked \\(X_t = \\Psi(B) a_t\\), and what the implied seasonal model, \\(\\phi_S(B) S_t = \\theta_S(B) a_{S,t} \\Rightarrow S_t = \\Psi(B) a_t\\), is."
  },
  {
    "objectID": "25-seats.html#sec-wiener-kolmogorov-algorithm",
    "href": "25-seats.html#sec-wiener-kolmogorov-algorithm",
    "title": "7  SEATS",
    "section": "\n7.7 Wiener-Kolmogorov Algorithm",
    "text": "7.7 Wiener-Kolmogorov Algorithm\nThe Wiener-Kolmogorov (WK) algorithm outlines the methodology to get the so-called WK filter. This is the filter that is equal to the conditional expectation of the seasonal component conditional on the observed series.\n\\[\\widehat{S}_t = \\underbrace{\\left[ \\frac{\\Sigma_S}{\\Sigma} \\frac{\\Psi_S(B)\\Psi_S(F)}{\\Psi(B)\\Psi(F)} \\right]}_{\\mbox{WK filter weights}} X_t\\] where \\(F=B^{-1}\\) if the forward shift operator such that \\(F X_t = X_{t+1}\\).\nMore than other coefficients, the seasonal MA (\\(\\theta_{12}\\)) influences whether estimated seasonal factors change either slowly over time (\\(\\theta_{12}\\) close to 1) or rapidly over time (\\(\\theta_{12}\\) close to zero)."
  },
  {
    "objectID": "25-seats.html#example-seats-adjustment",
    "href": "25-seats.html#example-seats-adjustment",
    "title": "7  SEATS",
    "section": "\n7.8 Example SEATS adjustment",
    "text": "7.8 Example SEATS adjustment\nLet’s have a look at nominal taxes from Swiss production account.\n\nThe series looks as follows:\n\ntax_n &lt;- ts(c(5512.43723529998, 5302.66127551312, 5637.04650218708, 5407.75865307982, 5254.75041765537, 5883.31044127543, 5465.12983546186, 5296.83011638733, 5577.28917595672, 5634.79857930988, 5832.41514259211, 5640.32968921129, 6066.78258591999, 6222.68082980585, 6504.17063502564, 6074.99091524851, 6580.71692950301, 6274.60948561261, 7157.60005559455, 6944.58546551983, 7448.63554376696, 6976.09702323069, 7818.38121589548, 7289.71620307687, 7768.40193169586, 6942.77891782026, 7578.22907029965, 7077.70301249423, 7410.68364011917, 6927.73248230177, 7087.72613485434, 6926.90090299472, 7336.73867165469, 7108.4949497024, 7145.42480380572, 7154.30815153718, 7498.01519467561, 7559.01824893372, 7156.60513953808, 7639.02255770258, 7569.94029094276, 7515.34158790891, 7732.93688269533, 7551.953334793, 8197.88127458863, 7939.93851007643, 8141.79136494712, 7568.40068251781, 8499.84629558006, 8345.25921525785, 8386.38082590207, 7886.29186614002, 8821.87792569236, 8595.73223990369, 8637.63939154854, 7991.04698685541, 8464.50040108557, 8003.27264004253, 8399.90637539542, 8384.22143621648, 8784.63271925264, 8595.77482962329, 8591.67855177336, 8602.6019974407, 8966.1740189959, 8993.28779502417, 8839.41351045546, 8468.69899389445, 9221.6367572731, 8801.73025651442, 8426.53923852333, 8661.00570414916, 8930.21895672981, 9116.66536122397, 8794.81591614758, 8559.38402031864, 9056.19152051174, 8842.45736626125, 9043.08264307781, 8549.5389771392, 8980.20969432594, 8893.75993928538, 9010.28560160679, 8664.05904218189, 8765.47235867103, 9170.15544669832, 8970.77030836517, 8310.62969865549, 9180.42069018707, 8566.35919301958, 9497.27766001259, 9012.51934200076, 8454.34333463005, 9357.61750287723, 9190.28660347765, 9060.07897285508, 9253.43694298711, 8809.60616470625, 8825.87955511076, 9047.15212801588, 9255.87581159138, 8423.29760776073), start = c(1995, 1), frequency = 4)\n\n# static(seas(tax_n))\n\nm &lt;- seas(\n  x = tax_n,\n  regression.variables = c(\"easter[15]\"),\n  arima.model = \"(0 1 1)(1 0 0)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"none\"\n)\n\nplot(m)\n\n\n\n\nWhile the summary looks fine,\n\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = tax_n, transform.function = \"none\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"easter[15]\"), arima.model = \"(0 1 1)(1 0 0)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Easter[15]        -213.82083   63.50954  -3.367 0.000761 ***\n#&gt; AR-Seasonal-04       0.47697    0.09087   5.249 1.53e-07 ***\n#&gt; MA-Nonseasonal-01    0.63304    0.07859   8.055 7.98e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(1 0 0)  Obs.: 102  Transform: none\n#&gt; AICc:  1442, BIC:  1452  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 17.27   Shapiro (normality): 0.9833\n\nthe seasonal factors seem erratic:\n\nmonthplot(m)\n\n\n\n\nTo me (Christoph), this seems against the very basic idea of seasonal adjustment: We want to collect predictable fluctuations in the seasonal component, not random noise. The other side of the coin is a very smooth seasonal adjustment.\nThese kind of SI-ratios appear in around 10 to 20% of SEATS adjustment and may be the reason why SEATS often seems smoother than X11.\nHow to detect these cases? How to deal with these adjustments?"
  },
  {
    "objectID": "25-seats.html#considerations-when-using-seats-in-x-13",
    "href": "25-seats.html#considerations-when-using-seats-in-x-13",
    "title": "7  SEATS",
    "section": "\n7.9 Considerations when using SEATS in X-13",
    "text": "7.9 Considerations when using SEATS in X-13\nSome model limitations when using SEATS are as follows.\n\nSEATS does not accept missing lag models. Hence, it is acceptable to specify a (0 1 3)(0 1 1) model but unacceptable to specify (0 1 [1 3])(0 1 1).\nThe AR and MA orders (p and q) cannot be greater than 3.\n\nInadmissible decomposition: Sometimes, the estimated values of coefficients make it impossible to estimate components from the estimated ARIMA models. SEATS will usually change the model and re-estimate it in order to get an admissible decomposition. When it is difficult to find an admissible decomposition the airline model is often used as a replacement. This usually gives acceptable results for a broad range of series.\nModel span can have large implications in a SEATS adjustment. This is due to the changing dynamics of long time series and how SEATS derives its filters."
  },
  {
    "objectID": "25-seats.html#sec-comparing",
    "href": "25-seats.html#sec-comparing",
    "title": "7  SEATS",
    "section": "\n7.10 Comparing X-11 and SEATS",
    "text": "7.10 Comparing X-11 and SEATS\nThe Bureau of Labor Statistics formed a group to do a comparison study between X-11 and model-based seasonal adjustments (CITE BLS 2007). The examined a cross section of 87 BLS series with X-11, SEATS, and STAMP using spectral, revisions history, model adequacy and sliding spans diagnostics. They found that SEATS seasonal factors are usually more stable than X-11 and X-11 trend component is usually more stable than SEATS. Also, among series that were seasonal, residual seasonality almost never appears using either method.\nThe only exception being a small number of SEATS runs where model inadequacy for the full span of data was present. This manifested as SEATS having difficulty identifying a usable model for decomposition and falling back on the airline model. They found even in these situations the SEATS seasonal adjustment is usually reasonable.\nOverall, X-11 and SEATS seasonal adjustments are very similar for many series. SEATS adjustments are often smoother than X-11 seasonal adjustments. For some series, the variance can be different based on the month or season. For example, U.S. Housing Starts is more variable in the winter months than in the summer due to the differences in warm and cold winters. ARIMA model-based seasonal adjustment does not handle this situation very well and assumes a constant variance and the SEATS adjustment wont compensate for this.\n\n7.10.1 SEATS filters from seas output\nThe trend filter and seasonal adjustment filter can be extracted from the output of a seasonal run. This is done via the save argument in the seats spec. In the following example the symmetric trend filter is saved and then exported. Note the finite='yes' argument must be specified to save filter weights.\n\nm &lt;- seas(AirPassengers, \n          seats.finite = 'yes',\n          seats.save   = 'ftf', # symmetric finite trend filter\n          out          = TRUE)\nftf_file &lt;- file.path(m$wdir, 'iofile.ftf')\n# reads in filter weights from ftf_file\nw &lt;- read.delim(textConnection(readLines(ftf_file)[-2]),\n                header = TRUE, stringsAsFactors = FALSE)\nplot(-72:71, w[,2], type = \"l\", \n     xlab = \"\", \n     ylab = \"weights\", \n     main = \"SEATS trend filter\")\n\n\n\n\nThe default SEATS output tables do not allow users to save the seasonal filter, only the seasonal adjustment and trend filters. Some additional work can be done to calculate the seasonal filters via the canonical decomposition implied models and the Wiener-Kolmogorov algorithm. The code provided here is a bit complicated and will be improved/modularized in subsequent version of this textbook. It involves outputting the mdc table and the using the grep functions to extract salient features for each model component. The naming conventions for the mdc table follow the Wald decomposition notation where moving average components appear in the numerator and differencing and/or autoregressive components appear in the denominator. The following assumes there are no AR components and anything appearing in the denominator is attributed to the differencing operator.\n\nm &lt;- seas(AirPassengers, \n          outlier = NULL, \n          regression.aictest = NULL,\n          arima.model = '(0 1 1)(0 1 1)',\n          seats.save = 'mdc', \n          out = TRUE)\n\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL, \n#&gt;     out = TRUE, arima.model = \"(0 1 1)(0 1 1)\", seats.save = \"mdc\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; MA-Nonseasonal-01  0.40182    0.07887   5.095 3.49e-07 ***\n#&gt; MA-Seasonal-12     0.55694    0.07626   7.303 2.80e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 987.4, BIC: 995.8  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.04   Shapiro (normality): 0.9886  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant seasonal peak has been\n#&gt;   found in the estimated spectrum of the regARIMA residuals.\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\ndecomp.m &lt;- read.delim(file.path(m$wdir, 'iofile.mdc'), sep = ':',\n                       stringsAsFactors = FALSE, header = FALSE)\nprint(decomp.m)\n#&gt;           V1           V2\n#&gt; 1     ntcnum  3.000000000\n#&gt; 2  tcnum.000  1.000000000\n#&gt; 3  tcnum.001  0.047518134\n#&gt; 4  tcnum.002 -0.952481866\n#&gt; 5     ntcden  3.000000000\n#&gt; 6  tcden.000  1.000000000\n#&gt; 7  tcden.001 -2.000000000\n#&gt; 8  tcden.002  1.000000000\n#&gt; 9      tcvar  0.054007671\n#&gt; 10     nsnum 12.000000000\n#&gt; 11  snum.000  1.000000000\n#&gt; 12  snum.001  1.412938279\n#&gt; 13  snum.002  1.485031335\n#&gt; 14  snum.003  1.412580521\n#&gt; 15  snum.004  1.216865960\n#&gt; 16  snum.005  0.970661608\n#&gt; 17  snum.006  0.704452210\n#&gt; 18  snum.007  0.440934873\n#&gt; 19  snum.008  0.218194121\n#&gt; 20  snum.009  0.009565283\n#&gt; 21  snum.010 -0.126641925\n#&gt; 22  snum.011 -0.415452995\n#&gt; 23     nsden 12.000000000\n#&gt; 24  sden.000  1.000000000\n#&gt; 25  sden.001  1.000000000\n#&gt; 26  sden.002  1.000000000\n#&gt; 27  sden.003  1.000000000\n#&gt; 28  sden.004  1.000000000\n#&gt; 29  sden.005  1.000000000\n#&gt; 30  sden.006  1.000000000\n#&gt; 31  sden.007  1.000000000\n#&gt; 32  sden.008  1.000000000\n#&gt; 33  sden.009  1.000000000\n#&gt; 34  sden.010  1.000000000\n#&gt; 35  sden.011  1.000000000\n#&gt; 36      svar  0.054246235\n#&gt; 37    nsanum  3.000000000\n#&gt; 38 sanum.000  1.000000000\n#&gt; 39 sanum.001 -1.365780650\n#&gt; 40 sanum.002  0.393702700\n#&gt; 41    nsaden  3.000000000\n#&gt; 42 saden.000  1.000000000\n#&gt; 43 saden.001 -2.000000000\n#&gt; 44 saden.002  1.000000000\n#&gt; 45     savar  0.625661730\n#&gt; 46    irrvar  0.297766039\n\n# trend-cycle model\nmacoefs &lt;- decomp.m[grep('^tcnum', decomp.m$V1),'V2'][-1]\ntrend.var &lt;- decomp.m[decomp.m$V1 == 'tcvar','V2']\ntrendDiff &lt;- decomp.m[grep('^tcden', decomp.m$V1),'V2']\n\n# seasonal model\nseasonal.macoefs &lt;- decomp.m[grep('^snum', decomp.m$V1),'V2'][-1]\nseasonal.var &lt;- decomp.m[decomp.m$V1 == 'svar','V2']\nseasonalDiff &lt;- decomp.m[grep('^sden', decomp.m$V1),'V2']\n\n# irregular variance\nirr.var &lt;- decomp.m[decomp.m$V1 == 'irrvar','V2']\n\n# transitory model (usually not needed)\ntrans.macoefs &lt;- decomp.m[grep('^trnum', decomp.m$V1),'V2'][-1]\ntrans.var &lt;- decomp.m[decomp.m$V1 == 'trvar','V2']\ntransDiff &lt;- decomp.m[grep('^trden', decomp.m$V1),'V2']\n\n# seasonally adjusted model\nsadj.macoefs &lt;- decomp.m[grep('^sanum', decomp.m$V1),'V2'][-1]\nsadj.var &lt;- decomp.m[decomp.m$V1 == 'savar','V2']\nsadjDiff &lt;- decomp.m[grep('^saden', decomp.m$V1),'V2']\n\nTo further understand these components the implied trend model is the following:\n\nmacoefs\n#&gt; [1]  0.04751813 -0.95248187\n\nwhich tells us the trend is an MA(2) with coefficients \\(\\theta_1 = 0.04751813\\) and \\(\\theta_2 = -0.95248187\\). The variance of the innovations, \\(\\sigma\\) is\n\ntrend.var\n#&gt; [1] 0.05400767\n\nand the differencing is\n\ntrendDiff\n#&gt; [1]  1 -2  1\n\nwhich is second differencing, i.e. \\(\\delta(B) = 1 - 2B + B^2 = (1-B)^2\\).\nWe can use these component models to apply the WK algorithm and get the seasonal filter weights. The details of this complex operation are omitted here but a plot of the seasonal filter weights is given in Figure ???.\n\n\n\n\n\n\n7.10.2 Reasons for using SEATS or X11\n\n\n\n\n\n\nTODO\n\n\n\nAdd Table with pros and cons\n\n\nFirst off, there does not exist a simple flow chat that tells each individual users whether they should use SEATS or X-11. For most well-behaved series both methods will produce suitable seasonal adjustments that will work for the majority of use cases. The ultimate decision between the two comes down to a few questions.\n\nWhat will you be doing with these seasonal adjustments?\nHow often is your data revised?\nDoes your agency have a policy to freeze data/seasonal adjustment revisions after a fixed period of time?\nHow much time can be devoted to development of initial spec files?\nHow much time can be devoted to maintenance of spec files?\nWhat is your maintenance schedule? (yearly, monthly, etc)\nWhat are the consequences of a poor adjustment?\nWhat are the consequences of large revisions?\nWill your agency be publishing original series, just SA, trends, seasonal factors?\nIs there an emphasis on deep methodological understanding of the procedures?\nIs there an emphasis on training users of released data to have a methodological understanding of the SA process?\n\n\nWhen applied properly (good ARIMA model, filters are not too narrow), it produces a seasonal component that is more stable. This leads to less revisions in the resulting series.\nWhen applied improperly (bad ARIMA model, narrow filters), it produces an unpredictable seasonal component and an overly smooth seasonally adjusted series.\nX-11 is more ‘robust’: If applied without additional checks. If this is desirable it may be a better option.\nIf you check SEATS models carefully, it may produce a more stable adjustment.\n\nTo sum up, whether you should use SEATS or X11 also depends on how much work you are willing to invest in a series."
  },
  {
    "objectID": "30-part-data-problems.html",
    "href": "30-part-data-problems.html",
    "title": "Data Problems",
    "section": "",
    "text": "In part III we look at more in-depth at practical issues with seasonal adjustment. The focus is on concrete solutions to each situation presented. Each subsection will prominently feature a case study dedicated to each problem."
  },
  {
    "objectID": "31-holidays.html#automated-adjustment",
    "href": "31-holidays.html#automated-adjustment",
    "title": "8  Irregular holidays",
    "section": "\n8.1 Automated Adjustment",
    "text": "8.1 Automated Adjustment\nBy default, seas() calls the automated routines to detect Easter effects in a series. For example, the default call detects an Easter effect with a length of one in the air passengers time series:\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nX-13 tests various lengths of an Easter effect and picks the one model with the lowest AICc. Easter[1] indicates that a length of one day has been chosen. I.e., the Easter holiday period is thought to start on Easter day and last for only one day. Alternatively, Easter[8] starts at Easter day and lasts for the eight subsequent days. If we want to enforce an eight-day Easter holiday, we can specify the call as follows:\n\nm_easter_8 &lt;- seas(AirPassengers, regression.variables = \"easter[8]\")\nsummary(m_easter_8)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.variables = \"easter[8]\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0028967  0.0005289  -5.477 4.33e-08 ***\n#&gt; Easter[8]          0.0158629  0.0074253   2.136   0.0327 *  \n#&gt; AO1951.May         0.1008171  0.0206437   4.884 1.04e-06 ***\n#&gt; MA-Nonseasonal-01  0.1215690  0.0858086   1.417   0.1566    \n#&gt; MA-Seasonal-12     0.5036477  0.0770917   6.533 6.44e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 948.8, BIC: 965.4  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.):  26.4   Shapiro (normality): 0.9895\n\nSurprisingly, the 8-day Easter model has a lower AICc than the one-day model. This opens the question of why the one-day model has been chosen in the beginning.\nIncluding holiday effects can have a dramatic effect on a final seasonal adjustment. Consider the monthly retail sales from Hobby, toy, and game stores. The data can be found at the US Census Time Series repository.\n\n\n\n\n\n\nHow to read data from CENSUS into R\n\n\n\n\nget_census_time_series &lt;- function(url) {\n  tf &lt;- tempfile(fileext = \".txt\")\n  download.file(census_url, tf)\n  ans &lt;- readr::read_csv(tf, skip = 6, col_types = cols(\n    Period = col_character(),\n    Value = col_double()\n  ))\n\n  ans |&gt;\n    mutate(\n      month.abb = gsub(\"\\\\-.+$\", \"\", Period),\n      year = gsub(\"^.+\\\\-\", \"\", Period)\n    ) |&gt;\n    left_join(tibble(month.abb, month = seq(month.abb)), by = join_by(month.abb)) |&gt;\n    mutate(time = as.Date(paste(year, month, 1, sep = \"-\"))) |&gt;\n    select(time, value = Value) |&gt;\n    filter(!is.na(value)) |&gt;\n    tsbox::ts_ts()\n}\n\ncensus_url &lt;- \"https://www.census.gov/econ_export/?format=csv&adjusted=true&notAdjusted=false&errorData=false&mode=report&default=&errormode=Dep&charttype=&chartmode=&chartadjn=&submit=GET+DATA&program=MARTS&startYear=1992&endYear=2023&categories%5B0%5D=44X72&dataType=SM&geoLevel=US\"\n\nget_census_time_series(census_url)\n\n\n\n\nts_plot(hobby_toy_game, title = \"Hobby, Toy and Game store monthly sales\")\n\n\n\n\nWe can perform a seasonal adjustment on this series with and without the Easter[8] regressor.\n\nm0 &lt;- seas(hobby_toy_game, x11 = \"\", regression = NULL, outlier = NULL)\nm1 &lt;- seas(hobby_toy_game, x11 = \"\", regression.variables = \"Easter[8]\", outlier = NULL)\nts_dygraphs(\n  ts_c(\n    hobby_toy_game, SA_noEaster = final(m0), SA_withEaster = final(m1)\n  )\n)\n\n\n\n\n\nNotice the large differences during certain Easter periods. For example, the final seasonally adjusted series including an Easter regressor in April 2011 was 1360.52. The final seasonally adjusted values without an Easter regressor was 1449.3, a difference of 89 million dollars which more than 7.5% higher than the original series value."
  },
  {
    "objectID": "31-holidays.html#case-study-chinese-new-year",
    "href": "31-holidays.html#case-study-chinese-new-year",
    "title": "8  Irregular holidays",
    "section": "\n8.2 Case Study: Chinese New Year",
    "text": "8.2 Case Study: Chinese New Year\nThe Lunar New Year is the most important holiday in China and many other Asian countries. Traditionally, the holiday starts on Lunar New Year’s Eve, and lasts until the Lantern Festival on the 15th day of the first month of the lunisolar calendar. The Chinese New Year is celebrated either in January or in February of the Gregorian calendar.\nBecause of its importance, Chinese New Year seriously distorts monthly time series, which are usually reported according to the Gregorian calendar. Unlike Easter, Chinese New Year does not affect quarterly time series, as it always falls in the first quarter.\nX-13-ARIMA-SEATS has a built-in adjustment procedure for the Easter holiday, but not for Chinese New Year. However, all packages allow for the inclusion of user-defined variables, and the Chinese New Year can be modeled as such.\n\n8.2.1 Imports of Goods to China\nChinese imports are included as an example series in seasonalbook, both with and without the official seasonal adjustment.\n\nlibrary(tsbox)\nstopifnot(packageVersion(\"seasonalbook\") &gt;= \"0.0.2\")\nts_plot(imp_cn)\n\n\n\n\nThe series has a very different seasonal pattern before 2000, we focus on the later period. (Adjusting the whole series in one step is possible, but for good results one should manually model the seasonal break.)\n\nimp_cn_2000 &lt;- ts_span(imp_cn, start = 2000)\n\nts_dygraphs() works similar to ts_plot(), but allows for zooming:\n\nts_dygraphs(imp_cn_2000)\n\n\n\n\n\n\n\n\n\n\n\nHow to read data from FRED into R\n\n\n\nfredr provides access to the Federal Reserve of Economic Data (FRED), provided by the Federal Reserve Bank of St. Louis. To use fredr and the FRED API in general, you must first obtain a FRED API key. Take a look at the Documentation for details.\nThe core function in this package is fredr(), which fetches observations for a FRED series.\nWe can use purrr::map_dfr() to download multiple series at once:\n\nlibrary(fredr)\nimp_cn_raw &lt;- purrr::map_dfr(c(\"XTIMVA01CNM667S\", \"XTIMVA01CNM667N\"), fredr)\n\nA bit of tidying:\n\nimp_cn_tidy &lt;-\n  imp_cn_raw |&gt;\n  select(time = date, id = series_id, value) |&gt;\n  mutate(id = recode(\n    id,\n    XTIMVA01CNM667S = \"sa\",\n    XTIMVA01CNM667N = \"nsa\"\n  ))\n\nUse the tsbox package to convert the data frame into ts objects.\n\nlibrary(tsbox)\nimp_cn_sa &lt;- ts_ts(ts_pick(imp_cn_tidy, \"sa\"))\nimp_cn &lt;- ts_ts(ts_pick(imp_cn_tidy, \"nsa\"))\n\nBoth time series are included in the book package.\n\nlibrary(seasonalbook)\nimp_cn_sa\nimp_cn\n\n\n\nseasonal includes the genhol() function, a R version of the equally named software utility by the U.S. Census Bureau. Using the dates of the Chinese New Year as an input, it produces a time series with the deviations from the monthly means. Here we are assuming that the holiday starts on New Year’s Eve and lasts for one week.\n\nreg_cny &lt;- genhol(cny, start = -1, end = 6, center = \"calendar\")\ntsbox::ts_dygraphs(reg_cny)\n\n\n\n\n\nThe center argument normalizes the series by either subtracting the overall average effect (\"mean\") or the average for each period (\"calendar\"). You should use \"calendar\" for Easter or Chinese New Year, but \"mean\" for Ramadan. Without this adjustment (\"none\"), the holiday effect is subtracted, altering the annual value of the series.\n\n8.2.2 Including user-defined regressors\nThe time series reg_cny can be included in the main seasonal adjustment. The automated procedures of X-13ARIMA-SEATS can be applied to the imp series in the following way:\n\nm1 &lt;- seas(\n  imp_cn,\n  xreg = reg_cny,\n  regression.usertype = \"holiday\",\n  x11 = list()\n)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, xreg = reg_cny, regression.usertype = \"holiday\", \n#&gt;     x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg              -0.1763689  0.0126544 -13.937  &lt; 2e-16 ***\n#&gt; Weekday            0.0074166  0.0009114   8.138 4.02e-16 ***\n#&gt; AO1999.Dec        -0.2066833  0.0505465  -4.089 4.33e-05 ***\n#&gt; LS2008.Nov        -0.3898401  0.0528219  -7.380 1.58e-13 ***\n#&gt; MA-Nonseasonal-01  0.4537545  0.0469504   9.665  &lt; 2e-16 ***\n#&gt; MA-Seasonal-12     0.3143759  0.0485684   6.473 9.62e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.693e+04, BIC: 1.695e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.03   Shapiro (normality): 0.9704 ***\nplot(m1)\n\n\n\n\nWith xreg, arbitrary user-defined regressors can be included, regression.usertype = \"holiday\" ensures that the final series does not include the regression effect. We also have chosen X11 as the decomposition method.\nUnsurprisingly, the summary reveals a highly significant Chinese New Year effect. As the automatic model has been estimated on the logarithmic series, the coefficient of -0.17 indicates that New Year in 2023 will lower imports in January, by approximately 0.74 * 17 ~ 13% (compared to average January), and increase it by the same amount in February. The automatic procedure has also detected weekday effects and a level shift during the financial crisis.\n\n8.2.3 Multiple regressors\nWe can do even better by using more than one user-defined regressors, one for the pre-New-Year period and one for the post-New-Year period:\n\npre_cny &lt;- genhol(cny, start = -6, end = -1, frequency = 12, center = \"calendar\")\npost_cny &lt;- genhol(cny, start = 0, end = 6, frequency = 12, center = \"calendar\")\nm2 &lt;- seas(\n  imp_cn,\n  xreg = ts_c(pre_cny, post_cny),\n  regression.usertype = \"holiday\",\n  x11 = list()\n)\nsummary(m2)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, xreg = ts_c(pre_cny, post_cny), regression.usertype = \"holiday\", \n#&gt;     x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg1              0.008910   0.015179   0.587    0.557    \n#&gt; xreg2             -0.186830   0.018563 -10.065  &lt; 2e-16 ***\n#&gt; Weekday            0.007404   0.000906   8.172 3.04e-16 ***\n#&gt; AO1999.Dec        -0.206691   0.050272  -4.111 3.93e-05 ***\n#&gt; LS2008.Nov        -0.388900   0.052698  -7.380 1.58e-13 ***\n#&gt; MA-Nonseasonal-01  0.450334   0.046985   9.585  &lt; 2e-16 ***\n#&gt; MA-Seasonal-12     0.313567   0.048553   6.458 1.06e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.693e+04, BIC: 1.696e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.37   Shapiro (normality): 0.9687 ***\nplot(m2)\n\n\n\n\n\n8.2.4 Compare with official adjustments\nI haven’t done any research on how the officially seasonally adjusted rates are computed, but they seem very close to a default call to seas(). Our models (both m1, but especially m2), does a much better job of adjusting to Chinese New Year.\n\nts_dygraphs(\n  ts_c(\n    cny = ts_span(reg_cny * 1e11 + 1e11, start = 2000, end = 2024),\n    ts_pick(imp_cn_2000, \"sa\"),\n    final(seas(x = imp_cn, x11 = \"\")),\n    final(m2)\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\nReplicate automated Easter adjustment in R\n\n\n\nWe can use R’s arima() function and genhol() to fully replicate X-13’s automated Easter adjustment.\nLet’s build an Easter regressor, using genhol():\n\n# easter regressor\nea &lt;- genhol(easter, start = -1, end = -1, center = \"calendar\")\nea &lt;- window(ea, start = start(AirPassengers), end = end(AirPassengers))\n\nAnd use this in an ARIMA model in R:\n\narima(\n  log(AirPassengers),\n  order = c(0,1,1),\n  seasonal = c(0,1,1),\n  xreg = ea\n)\n#&gt; \n#&gt; Call:\n#&gt; arima(x = log(AirPassengers), order = c(0, 1, 1), seasonal = c(0, 1, 1), xreg = ea)\n#&gt; \n#&gt; Coefficients:\n#&gt;           ma1     sma1      ea\n#&gt;       -0.3772  -0.5493  0.0200\n#&gt; s.e.   0.0930   0.0735  0.0099\n#&gt; \n#&gt; sigma^2 estimated as 0.00131:  log likelihood = 246.65,  aic = -485.29\n\nNow, let’s compare to the results of X-13:\n\nm &lt;- seas(\n  AirPassengers,\n  regression.variables = c(\"easter[1]\"),\n  regression.aictest = NULL\n)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, regression.variables = c(\"easter[1]\"))\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Easter[1]         0.019990   0.009936   2.012   0.0442 *  \n#&gt; MA-Nonseasonal-01 0.377151   0.079753   4.729 2.26e-06 ***\n#&gt; MA-Seasonal-12    0.549333   0.076650   7.167 7.68e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 985.6, BIC: 996.8  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.93   Shapiro (normality): 0.9931  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nNote that R defines the ARIMA model with negative signs before the MA term, X-13 with a positive sign."
  },
  {
    "objectID": "31-holidays.html#case-study-azerbaijani-retail-sales",
    "href": "31-holidays.html#case-study-azerbaijani-retail-sales",
    "title": "8  Irregular holidays",
    "section": "\n8.3 Case Study: Azerbaijani Retail Sales",
    "text": "8.3 Case Study: Azerbaijani Retail Sales\n\nlibrary(cbar.sa)\n#&gt; \n#&gt; Attaching package: 'cbar.sa'\n#&gt; The following object is masked _by_ '.GlobalEnv':\n#&gt; \n#&gt;     m1\n#&gt; The following object is masked from 'package:seasonal':\n#&gt; \n#&gt;     cpi\nlibrary(seasonal)\nlibrary(dplyr)\n\n# manual regressor construction\nramadan_ts_manual &lt;-\n  islamic_calendar |&gt;\n  group_by(y = lubridate::year(date)) |&gt;\n  mutate(ramadan_y = sum(ramadan)) |&gt;\n  ungroup() |&gt;\n  group_by(y = lubridate::year(date), q = lubridate::quarter(date)) |&gt;\n  summarize(time = date[1], value = sum(ramadan) / ramadan_y[1], .groups = \"drop\") |&gt;\n  select(time, value) |&gt;\n  tsbox::ts_ts()\n\n# Careful, this is not centered!\n\n\n# ### automatic regressor construction (experimental)\n\nramadan &lt;-\n  islamic_calendar |&gt;\n  mutate(diff = ramadan - lag(ramadan)) |&gt;\n  mutate(start = (diff == 1)) |&gt;\n  dplyr::filter(start) |&gt;\n  pull(date)\n\n# Q: Can we come up with a defined start date for Ramadan or Muharrem?\nislamic_calendar |&gt;\n  filter(date %in% c(\"2000-11-26\", \"2000-11-27\", \"2000-11-28\"))\n#&gt; [90m# A tibble: 3 × 3[39m\n#&gt;   [1mdate[22m       [1mmuharrem[22m [1mramadan[22m\n#&gt;   [3m[90m&lt;date&gt;[39m[23m        [3m[90m&lt;dbl&gt;[39m[23m   [3m[90m&lt;dbl&gt;[39m[23m\n#&gt; [90m1[39m 2000-11-26        0       0\n#&gt; [90m2[39m 2000-11-27        0       1\n#&gt; [90m3[39m 2000-11-28        0       1\n\n# Q: Is the length of Ramadan uniquely defined?\nramadan_ts_auto &lt;- seasonal::genhol(ramadan, frequency = 4, start = 0, end = 29, center = \"none\")\n\n# Applying the calendar mean adjustment\nramadan_ts &lt;- seasonal::genhol(ramadan, frequency = 4, start = 0, end = 29, center = \"mean\")\n\n\n# Different pattern pre 2008\nplot(trade_tur)\n\nm0 &lt;- seas(trade_tur, x11 = \"\")\nm1 &lt;- seas(\n  trade_tur,\n  xreg = ramadan_ts,\n  regression.usertype = \"holiday\"\n)\nsummary(m0)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = trade_tur, x11 = \"\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; LS2008.2           0.08703    0.01820   4.783 1.73e-06 ***\n#&gt; LS2009.1          -0.09009    0.01820  -4.951 7.38e-07 ***\n#&gt; AO2015.2           0.06888    0.01132   6.087 1.15e-09 ***\n#&gt; AR-Nonseasonal-01  0.29250    0.10936   2.675  0.00748 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (1 1 0)(0 1 0)  Obs.: 82  Transform: log\n#&gt; AICc: 971.7, BIC: 982.6  QS (no seasonality in final):0.5095  \n#&gt; Box-Ljung (no autocorr.): 27.15   Shapiro (normality): 0.9653 *\nsummary(m1)  # xreg insignificant\n#&gt; \n#&gt; Call:\n#&gt; seas(x = trade_tur, xreg = ramadan_ts, regression.usertype = \"holiday\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg               0.01230    0.01058   1.162  0.24526    \n#&gt; LS2008.2           0.08789    0.01804   4.871 1.11e-06 ***\n#&gt; LS2009.1          -0.09371    0.01834  -5.111 3.20e-07 ***\n#&gt; AO2015.2           0.06956    0.01119   6.215 5.14e-10 ***\n#&gt; AR-Nonseasonal-01  0.29861    0.10884   2.744  0.00608 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 1 0)(0 1 0)  Obs.: 82  Transform: log\n#&gt; AICc: 972.7, BIC: 985.6  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.64   Shapiro (normality): 0.9566 *\n\n\n# If we start adjusting from 2008 on, we get a better result\nm2 &lt;- seas(trade_tur, x11 = \"\", series.modelspan = \"2008.01,\")\nm3 &lt;- seas(\n  trade_tur,\n  xreg = ramadan_ts,\n  regression.usertype = \"holiday\",\n  series.modelspan = \"2008.01,\"\n)\nsummary(m2)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = trade_tur, x11 = \"\", series.modelspan = \"2008.01,\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; AO2008.1          -0.127442   0.021218  -6.006 1.90e-09 ***\n#&gt; AO2015.2           0.069109   0.008652   7.988 1.37e-15 ***\n#&gt; LS2020.2          -0.055809   0.014080  -3.964 7.38e-05 ***\n#&gt; AR-Nonseasonal-01  0.368127   0.124057   2.967    0.003 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (1 1 0)(0 1 0)  Obs.: 82  Transform: log\n#&gt; AICc: 739.7, BIC: 748.7  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 25.72   Shapiro (normality): 0.9259 **\nsummary(m3)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = trade_tur, xreg = ramadan_ts, regression.usertype = \"holiday\", \n#&gt;     series.modelspan = \"2008.01,\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg               0.028760   0.008556   3.362 0.000775 ***\n#&gt; AO2008.1          -0.126803   0.018087  -7.011 2.37e-12 ***\n#&gt; LS2012.1          -0.045014   0.011856  -3.797 0.000147 ***\n#&gt; AO2015.2           0.069747   0.007173   9.724  &lt; 2e-16 ***\n#&gt; LS2020.2          -0.054681   0.011856  -4.612 3.99e-06 ***\n#&gt; MA-Nonseasonal-01 -0.404526   0.121835  -3.320 0.000899 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 0)  Obs.: 82  Transform: log\n#&gt; AICc: 726.6, BIC: 738.6  QS (no seasonality in final):0.03671  \n#&gt; Box-Ljung (no autocorr.): 28.13   Shapiro (normality): 0.9629 .\n\ntsbox::ts_plot(\n  delta_perc = (final(m3) - final(m2)) / final(m2)\n)\n\n\n# Applying the calendar mean adjustment\nramadan_pre_ts &lt;- seasonal::genhol(ramadan, frequency = 4, start = -2, end = 0, center = \"mean\")\nlibrary(tsbox)\nm4 &lt;- seas(\n  trade_tur,\n  xreg = cbind(ramadan_pre_ts, ramadan_ts),\n  regression.usertype = \"holiday\",\n  series.modelspan = \"2008.01,\"\n)\n\n# Q: Does the sign makes sense?\nsummary(m4)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = trade_tur, xreg = cbind(ramadan_pre_ts, ramadan_ts), \n#&gt;     regression.usertype = \"holiday\", series.modelspan = \"2008.01,\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg1             -0.010146   0.004235  -2.396   0.0166 *  \n#&gt; xreg2              0.036534   0.008445   4.326 1.52e-05 ***\n#&gt; AO2008.1          -0.131754   0.017178  -7.670 1.72e-14 ***\n#&gt; LS2012.1          -0.042722   0.010156  -4.206 2.59e-05 ***\n#&gt; AO2015.2           0.071251   0.006030  11.817  &lt; 2e-16 ***\n#&gt; LS2020.2          -0.054455   0.010156  -5.362 8.23e-08 ***\n#&gt; MA-Nonseasonal-01 -0.483042   0.116524  -4.145 3.39e-05 ***\n#&gt; MA-Seasonal-04    -0.144730   0.132190  -1.095   0.2736    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 82  Transform: log\n#&gt; AICc: 726.5, BIC:   741  QS (no seasonality in final):0.1123  \n#&gt; Box-Ljung (no autocorr.): 22.75   Shapiro (normality): 0.9542 *"
  },
  {
    "objectID": "31-holidays.html#exercises",
    "href": "31-holidays.html#exercises",
    "title": "8  Irregular holidays",
    "section": "\n8.4 Exercises",
    "text": "8.4 Exercises\n\nGo through seasonal::genhol() documentation and make sure you understand its argument.\nCan you replicate seasonal::genhol(easter, frequency = 4, start = -2, center = \"calendar\") output manually?\nCan you explain why do we need to set center = \"mean\" for Ramadan?\nWhat is the consequence of not specifying regression.usertype = \"holiday\" in a call to seas() when adjusting for moving holidays?"
  },
  {
    "objectID": "32-trading-days.html#sec-user-defined-regressors",
    "href": "32-trading-days.html#sec-user-defined-regressors",
    "title": "9  Trading days",
    "section": "\n9.1 Built-in trading day adjustment",
    "text": "9.1 Built-in trading day adjustment\nIn a default run of seas(), X-13 uses a familiar AICc test to decide between a number of potential trading day adjustments. From the various models, it uses the one with the lowest AICc as the best model. By default, the following models are evaluated:\n\ntd1coef: A single coefficient trading day adjustment\ntd: A six-day coefficient trading day adjustment\n\nThe first model distinguishes between weekdays and weekends, while the second model treats every day as its own. The first model is appropriate for many economic time series, where variables behave differently during the week than during the weekend. In some series, there may be large differences between weekdays, or even between Saturday and Sunday. Retail sales, for example, usually peak towards the end of the week and are weak on Sunday.\nUsing the built-in trading day adjustment in X-13 is straightforward:\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe procedure has opted for a one coefficient model. During weekdays, the number of air passengers was lower during the period of the example series, by about 0.3% (note we are looking at a logarithmic, multiplicative model).\nWe can manipulate the automated model. To enforce a six coefficient model, regression.variables can be specified as \"td\" (as opposed to \"td1coef\"):\n\nm_td &lt;- seas(AirPassengers, regression.variables = \"td\")\nsummary(m_td)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.variables = \"td\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon            -0.001527   0.003458  -0.442   0.6588    \n#&gt; Tue            -0.007677   0.003607  -2.129   0.0333 *  \n#&gt; Wed            -0.001125   0.003465  -0.325   0.7453    \n#&gt; Thu            -0.005350   0.003425  -1.562   0.1183    \n#&gt; Fri             0.004676   0.003447   1.357   0.1749    \n#&gt; Sat             0.003025   0.003568   0.848   0.3965    \n#&gt; Easter[1]       0.017999   0.007246   2.484   0.0130 *  \n#&gt; AO1951.May      0.109256   0.019651   5.560 2.70e-08 ***\n#&gt; MA-Seasonal-12  0.500775   0.077252   6.482 9.03e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 0)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 949.5, BIC: 976.4  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 28.05   Shapiro (normality): 0.9902\n\nNote that the resulting AICc is higher (949.5) than for the one coefficient model (947.3). That is why the automated procedure has opted for the simpler model."
  },
  {
    "objectID": "32-trading-days.html#case-study-hobby-toy-game",
    "href": "32-trading-days.html#case-study-hobby-toy-game",
    "title": "9  Trading days",
    "section": "\n9.2 Case Study: Hobby Toy Game",
    "text": "9.2 Case Study: Hobby Toy Game\n\nm &lt;- seas(hobby_toy_game)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = hobby_toy_game)\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon               -0.009625   0.003358  -2.866 0.004157 ** \n#&gt; Tue                0.014245   0.003276   4.349 1.37e-05 ***\n#&gt; Wed               -0.009167   0.003289  -2.787 0.005326 ** \n#&gt; Thu               -0.001631   0.003258  -0.501 0.616624    \n#&gt; Fri                0.010977   0.003332   3.295 0.000984 ***\n#&gt; Sat                0.011069   0.003316   3.338 0.000843 ***\n#&gt; Easter[8]          0.061462   0.006426   9.564  &lt; 2e-16 ***\n#&gt; AO1996.May        -0.217402   0.025347  -8.577  &lt; 2e-16 ***\n#&gt; AO1996.Dec         0.145309   0.025339   5.735 9.77e-09 ***\n#&gt; MA-Nonseasonal-01  0.377066   0.056405   6.685 2.31e-11 ***\n#&gt; MA-Nonseasonal-02  0.360585   0.056510   6.381 1.76e-10 ***\n#&gt; MA-Seasonal-12     0.326875   0.055259   5.915 3.31e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 282  Transform: log\n#&gt; AICc:  2826, BIC:  2871  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.25   Shapiro (normality): 0.9887 *\n\nstatic(m)\n#&gt; seas(\n#&gt;   x = hobby_toy_game,\n#&gt;   regression.variables = c(\"td\", \"easter[8]\", \"ao1996.May\", \"ao1996.Dec\"),\n#&gt;   arima.model = \"(0 1 2)(0 1 1)\",\n#&gt;   regression.aictest = NULL,\n#&gt;   outlier = NULL,\n#&gt;   transform.function = \"log\"\n#&gt; )\n\nm0 &lt;- seas(\n  x = hobby_toy_game,\n  regression.variables = c(\n  \"td\",\n  \"easter[8]\",\n  \"ao1996.May\",\n  \"ao1996.Dec\"\n  ),\n  arima.model = \"(0 1 2)(0 1 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\nsummary(m0)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = hobby_toy_game, transform.function = \"log\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"td\", \"easter[8]\", \n#&gt;         \"ao1996.May\", \"ao1996.Dec\"), arima.model = \"(0 1 2)(0 1 1)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon               -0.009625   0.003358  -2.866 0.004157 ** \n#&gt; Tue                0.014245   0.003276   4.349 1.37e-05 ***\n#&gt; Wed               -0.009167   0.003290  -2.787 0.005327 ** \n#&gt; Thu               -0.001631   0.003258  -0.501 0.616637    \n#&gt; Fri                0.010977   0.003332   3.295 0.000985 ***\n#&gt; Sat                0.011069   0.003316   3.338 0.000843 ***\n#&gt; Easter[8]          0.061462   0.006426   9.564  &lt; 2e-16 ***\n#&gt; AO1996.May        -0.217403   0.025348  -8.577  &lt; 2e-16 ***\n#&gt; AO1996.Dec         0.145309   0.025339   5.735 9.78e-09 ***\n#&gt; MA-Nonseasonal-01  0.377086   0.056405   6.685 2.30e-11 ***\n#&gt; MA-Nonseasonal-02  0.360597   0.056509   6.381 1.76e-10 ***\n#&gt; MA-Seasonal-12     0.326884   0.055258   5.916 3.31e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 282  Transform: log\n#&gt; AICc:  2826, BIC:  2871  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.25   Shapiro (normality): 0.9887 *\n\nm1 &lt;- seas(\n  x = hobby_toy_game,\n  regression.variables = c(\n  \"td1coef\",\n  \"easter[8]\",\n  \"ao1996.May\",\n  \"ao1996.Dec\"\n  ),\n  arima.model = \"(0 1 2)(0 1 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = hobby_toy_game, transform.function = \"log\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"td1coef\", \"easter[8]\", \n#&gt;         \"ao1996.May\", \"ao1996.Dec\"), arima.model = \"(0 1 2)(0 1 1)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday            0.0005289  0.0005944   0.890    0.374    \n#&gt; Easter[8]          0.0542854  0.0074088   7.327 2.35e-13 ***\n#&gt; AO1996.May        -0.2300586  0.0290640  -7.916 2.46e-15 ***\n#&gt; AO1996.Dec         0.1231689  0.0289604   4.253 2.11e-05 ***\n#&gt; MA-Nonseasonal-01  0.4421089  0.0569371   7.765 8.17e-15 ***\n#&gt; MA-Nonseasonal-02  0.3495768  0.0569694   6.136 8.45e-10 ***\n#&gt; MA-Seasonal-12     0.3571851  0.0551869   6.472 9.65e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 2)(0 1 1)  Obs.: 282  Transform: log\n#&gt; AICc:  2875, BIC:  2904  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 40.88 * Shapiro (normality): 0.9943\n\nlibrary(tsbox)\nts_dygraphs(ts_c(\n  final(m0),\n  final(m1)\n))"
  },
  {
    "objectID": "32-trading-days.html#sec-replicate-x-13-trading-days-adjustment",
    "href": "32-trading-days.html#sec-replicate-x-13-trading-days-adjustment",
    "title": "9  Trading days",
    "section": "\n9.3 Case Study: Replicate X-13 trading days adjustment",
    "text": "9.3 Case Study: Replicate X-13 trading days adjustment\n‘Trading day adjustment’ removes the effect of the weekdays, but does not include holidays, such as Christmas or Easter. These are handled separately (Easter) (Chapter 8) or dealt with standard seasonal adjustment (Christmas).\nSometimes, users may want to specify user-defined trading day regressors, to incorporate country specific trading day patterns. In Section 9.3, we replicate the built-in regressors. These regressors simply use the number of weekdays, and do not pay any reference to a country specific calendar. If you want to deviate from them, a good way is to start with the replicated values, and adjust from there.\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(tsbox)\nlibrary(seasonal)\n\n\n9.3.1 Constructing weekday regressors\nTo construct weekday regressors in R, we use the following code:\n\nlibrary(dplyr)\n\ndates &lt;- seq(as.Date(\"1931-01-01\"), as.Date(\"2030-12-31\"), by = \"day\")\n\nfirst_of_month &lt;- function(x) {\n  as.Date(paste(\n    data.table::year(dates),\n    data.table::month(dates),\n    1,\n    sep = \"-\"\n  ))\n}\n\ntd_m_tbl &lt;-\n  tibble(dates, wd = as.POSIXlt(dates)$wday, name = weekdays(dates)) |&gt;\n  group_by(time = first_of_month(dates)) |&gt;\n  summarize(\n    mon = sum(wd == 1) - sum(wd == 0),\n    tue = sum(wd == 2) - sum(wd == 0),\n    wed = sum(wd == 3) - sum(wd == 0),\n    thu = sum(wd == 4) - sum(wd == 0),\n    fri = sum(wd == 5) - sum(wd == 0),\n    sat = sum(wd == 6) - sum(wd == 0),\n    td1 = sum(wd %in% 1:5) - 5 / 2 * sum(wd %in% c(6, 0))\n  )\n\n\n\n\n\ntime\nmon\ntue\nwed\nthu\nfri\nsat\ntd1\n\n\n\n1931-01-01\n0\n0\n0\n1\n1\n1\n-0.5\n\n\n1931-02-01\n0\n0\n0\n0\n0\n0\n0.0\n\n\n1931-03-01\n0\n0\n-1\n-1\n-1\n-1\n-0.5\n\n\n1931-04-01\n0\n0\n1\n1\n0\n0\n2.0\n\n\n1931-05-01\n-1\n-1\n-1\n-1\n0\n0\n-4.0\n\n\n1931-06-01\n1\n1\n0\n0\n0\n0\n2.0\n\n\n\n\n\nFor each month, td_m_tbl computes the number of specific weekdays, and compares them to the number of Sundays (wd == -) (columns mon to sat). For example, in May 1931, the number of Mondays was 4 while the number of Sundays was 5. The column td1 compares the total number of weekdays with the total number of weekends. The normalization formula is the one used by X-13 and described in the X-13 manual.\n\nTo extract the regressors as ts time series, we use the following code:\n\ntd1nolpyear &lt;-\n  td_m_tbl |&gt;\n  select(time, value = td1) |&gt;\n  ts_ts()\n\ntdnolpyear &lt;-\n  td_m_tbl |&gt;\n  select(-td1) |&gt;\n  ts_long() |&gt;\n  ts_ts()\n\n\n9.3.2 Single coefficient regressor\nIt is straightforward to replicate these values to the automated procedure in X-13:\n\nm_td1coef &lt;- seas(\n  AirPassengers,\n  xreg = td1nolpyear,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.usertype = \"td\"\n)\nsummary(m_td1coef)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, xreg = td1nolpyear, regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.usertype = \"td\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg              -0.0025474  0.0006732  -3.784 0.000154 ***\n#&gt; MA-Nonseasonal-01  0.3292278  0.0813633   4.046 5.20e-05 ***\n#&gt; MA-Seasonal-12     0.5695911  0.0739360   7.704 1.32e-14 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 976.6, BIC: 987.7  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 24.86   Shapiro (normality): 0.9805 *\n\n\nm_td1coef_built_in &lt;- seas(\n  AirPassengers,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.variables = c(\"td1nolpyear\", outlier = NULL)\n)\nsummary(m_td1coef_built_in)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL, \n#&gt;     regression.variables = c(\"td1nolpyear\", outlier = NULL))\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0025474  0.0006732  -3.784 0.000154 ***\n#&gt; MA-Nonseasonal-01  0.3292278  0.0813633   4.046 5.20e-05 ***\n#&gt; MA-Seasonal-12     0.5695911  0.0739360   7.704 1.32e-14 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 976.6, BIC: 987.7  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 24.86   Shapiro (normality): 0.9805 *\n\n\n9.3.3 One coefficient per day\nNote that the baseline is Sunday.\n\nm_td &lt;- seas(\n  AirPassengers,\n  xreg = tdnolpyear,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.usertype = \"td\"\n)\nsummary(m_td)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, xreg = tdnolpyear, regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.usertype = \"td\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; xreg1             -0.004982   0.004731  -1.053 0.292359    \n#&gt; xreg2             -0.004589   0.004762  -0.964 0.335172    \n#&gt; xreg3             -0.001612   0.004745  -0.340 0.734094    \n#&gt; xreg4             -0.003817   0.004680  -0.816 0.414652    \n#&gt; xreg5              0.003958   0.004706   0.841 0.400272    \n#&gt; xreg6              0.003164   0.004829   0.655 0.512342    \n#&gt; MA-Nonseasonal-01  0.298942   0.082193   3.637 0.000276 ***\n#&gt; MA-Seasonal-12     0.579965   0.073855   7.853 4.07e-15 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 983.9, BIC:  1008  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.43   Shapiro (normality): 0.9781 *\n\n\nm_td_built_in &lt;- seas(\n  AirPassengers,\n  regression.aictest = NULL,\n  outlier = NULL,\n  regression.variables = c(\"tdnolpyear\", outlier = NULL)\n)\nsummary(m_td_built_in)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, regression.aictest = NULL, outlier = NULL, \n#&gt;     regression.variables = c(\"tdnolpyear\", outlier = NULL))\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Mon               -0.004982   0.004731  -1.053 0.292359    \n#&gt; Tue               -0.004589   0.004762  -0.964 0.335172    \n#&gt; Wed               -0.001612   0.004745  -0.340 0.734094    \n#&gt; Thu               -0.003817   0.004680  -0.816 0.414652    \n#&gt; Fri                0.003958   0.004706   0.841 0.400272    \n#&gt; Sat                0.003164   0.004829   0.655 0.512342    \n#&gt; MA-Nonseasonal-01  0.298942   0.082193   3.637 0.000276 ***\n#&gt; MA-Seasonal-12     0.579965   0.073855   7.853 4.07e-15 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 983.9, BIC:  1008  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.43   Shapiro (normality): 0.9781 *\n\n\n9.3.4 Is it worth building country specific regressors?\nThe built-in trading day adjustment in X-13 is exclusively based on the calendar to construct regressor variables, meaning it does not consider country-specific holidays like Thanksgiving in the US. These holidays are addressed separately, as discussed in the Chapter 8 section.\nAs previously noted, regular holidays, such as Christmas, typically don’t need special handling. When dealing with irregular holidays, such as Chinese New Year, employing holiday regressors is the preferred approach. Consequently, creating country-specific regressors is generally unnecessary."
  },
  {
    "objectID": "32-trading-days.html#case-study-azerbaijani-consumer-price-index-for-construction",
    "href": "32-trading-days.html#case-study-azerbaijani-consumer-price-index-for-construction",
    "title": "9  Trading days",
    "section": "\n9.4 Case Study: Azerbaijani Consumer price index for construction",
    "text": "9.4 Case Study: Azerbaijani Consumer price index for construction\ntd1coef is significant. But does the series have a seasonal pattern?\n\nlibrary(cbar.sa)\n#&gt; \n#&gt; Attaching package: 'cbar.sa'\n#&gt; The following object is masked _by_ '.GlobalEnv':\n#&gt; \n#&gt;     m1\n#&gt; The following object is masked from 'package:seasonal':\n#&gt; \n#&gt;     cpi\nm0 &lt;- seas(\n  x = cpi_const,\n  regression.variables = c(\"const\", \"ls2009.1\"),\n  arima.model = \"(1 1 0)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"none\"\n)\n#&gt; Model used in SEATS is different: (0 1 1)\nsummary(m0)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = cpi_const, transform.function = \"none\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"const\", \"ls2009.1\"), \n#&gt;     arima.model = \"(1 1 0)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Constant            0.7068     0.1674   4.224 2.40e-05 ***\n#&gt; LS2009.1           -3.5364     0.8613  -4.106 4.02e-05 ***\n#&gt; AR-Nonseasonal-01   0.3144     0.1229   2.558   0.0105 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 1 0)  Obs.: 62  Transform: none\n#&gt; AICc:   169, BIC: 176.8  QS (no seasonality in final):0.7392  \n#&gt; Box-Ljung (no autocorr.): 11.86   Shapiro (normality): 0.9754  \n#&gt; Messages generated by X-13:\n#&gt; Notes:\n#&gt; - Model used for SEATS decomposition is different from the\n#&gt;   model estimated in the regARIMA modeling module of\n#&gt;   X-13ARIMA-SEATS.\n\n\nm1 &lt;- seas(\n  x = cpi_const,\n  regression.variables = c(\"const\", \"td1coef\", \"ls2009.1\"), \n  arima.model = \"(1 1 0)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"none\"\n)\n#&gt; Model used in SEATS is different: (0 1 1)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = cpi_const, transform.function = \"none\", regression.aictest = NULL, \n#&gt;     outlier = NULL, regression.variables = c(\"const\", \"td1coef\", \n#&gt;         \"ls2009.1\"), arima.model = \"(1 1 0)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                   Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Constant            0.7050     0.1736   4.062 4.86e-05 ***\n#&gt; Weekday             0.1262     0.0436   2.896  0.00379 ** \n#&gt; Leap Year          -0.5241     0.2943  -1.781  0.07491 .  \n#&gt; LS2009.1           -3.3119     0.7863  -4.212 2.53e-05 ***\n#&gt; AR-Nonseasonal-01   0.3927     0.1210   3.245  0.00117 ** \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (1 1 0)  Obs.: 62  Transform: none\n#&gt; AICc:   164, BIC: 175.1  QS (no seasonality in final):0.423  \n#&gt; Box-Ljung (no autocorr.): 12.95   Shapiro (normality): 0.9701  \n#&gt; Messages generated by X-13:\n#&gt; Notes:\n#&gt; - Model used for SEATS decomposition is different from the\n#&gt;   model estimated in the regARIMA modeling module of\n#&gt;   X-13ARIMA-SEATS."
  },
  {
    "objectID": "32-trading-days.html#exercises",
    "href": "32-trading-days.html#exercises",
    "title": "9  Trading days",
    "section": "\n9.5 Exercises",
    "text": "9.5 Exercises\n\nWhat is the difference between td1coef and td regressor? When would fit better than the other?\nRun seas() to on AirPassengers using td1coef and td regressors and compare the results.\nConsult X-13ARIMA-SEATS Reference Manual. What other options are available as built-in regressors to model trading days?\nWould it make sense to model both the holiday and trading days effect at the same time?\nExplain the difference among the following arguments: xreg, regression.variables, and regression.usertype. Are these equivalent?\nUse the trade_tur series. Try modeling the holiday and trading days effect simultaneously and compare the results with the individual solutions. Do you get better results?"
  },
  {
    "objectID": "33-outliers.html#introduction",
    "href": "33-outliers.html#introduction",
    "title": "10  Outliers",
    "section": "\n10.1 Introduction",
    "text": "10.1 Introduction\nExceptional data values, or outliers, constitute a problem both for the ARIMA model building as well as for the seasonal filtering. When analyzing time series data, outlier values are common. In some cases, these issues can be linked to actual events in the real world, such as:\n\nthe COVID-19 pandemic\nthe 2008/09 financial market crash\nNatural disasters\nUkraine crisis\n\nThese events can impact the accuracy of seasonal adjustment. As a result, X-13 tries to remove these inconsistencies before performing seasonal adjustment.\nFor example, when running seas() on AirPassengers with default settings, X-13 detects an additive outlier in may 1951. This additive outlier is removed in the regARIMA part but will be readded to the final, seasonally adjusted series.\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe plot() method highlights the outlier values and marks them accordingly:\n\nplot(m)\n\n\n\n\nThe default settings discovered a single, additive outlier. By default, X-13 uses a formula that interpolates critical values for numbers of observations between 3 and 99 (Table 7.22 in the Manual). For standard time series, this results in a critical value around 4.\n\n\nOutlier Span Length\nDefault Critical Value\n\n\n\n1\n1.96\n\n\n2\n2.24\n\n\n48\n3.63\n\n\n96\n3.80\n\n\n120\n3.85\n\n\n240\n3.99\n\n\n360\n4.07\n\n\n\nUsing the outlier.critical argument, we can fine tune the detection process. With outlier.critical = 3, we set a lower bar for the detection of outliers. outlier.critical is the z-value of a particular value that is needed to be classified as an outlier. A value of three means that the z-value must be 3 or larger.\n\nHigher values make it less likely to identify a value as an outlier\nEach outlier type can have a different critical value (typically we use the same for all types)\n\n\nm_high &lt;- seas(AirPassengers, outlier.critical = 3)\nsummary(m_high)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier.critical = 3)\n#&gt; \n#&gt; Coefficients:\n#&gt;                  Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday        -0.0027692  0.0004187  -6.613 3.76e-11 ***\n#&gt; Easter[1]       0.0140649  0.0058438   2.407 0.016092 *  \n#&gt; AO1950.Jan     -0.0629435  0.0174523  -3.607 0.000310 ***\n#&gt; AO1951.May      0.1081042  0.0165482   6.533 6.46e-11 ***\n#&gt; LS1953.Jun     -0.0755237  0.0228402  -3.307 0.000944 ***\n#&gt; AO1954.Feb     -0.0693534  0.0160240  -4.328 1.50e-05 ***\n#&gt; LS1960.Apr      0.0847557  0.0272119   3.115 0.001842 ** \n#&gt; MA-Seasonal-12  0.4967116  0.0749535   6.627 3.43e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 0)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 910.7, BIC: 935.1  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 29.07   Shapiro (normality): 0.9911  \n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nWith outlier.critical = 3, we see additive outliers in January 1950, May 1951 and February 1954. In addition, we also see level shifts in June 1953 and April 1960. Note that all z-values are larger than 3.\nX-13 offers several ways to model outliers. In this chapter, we will focus on two most important types of effects that can occur in time series data: level shifts and additive outliers. By understanding these effects and how to address them, analysts can improve the quality of their analyses and draw more accurate conclusions from the data.\n\nArguments to the `outlier` spec\n\n\n\n\n\n\nArgument\nDescription\nDefault\n\n\n\noutlier.critical\n\nSets the value to which the absolute values of the outlier t-statistics are compared to detect outliers.\nIf only one value is given for this argument, then this critical value is used for all types of outliers. If a list of up to three values is given, different values are used for additive outliers, level shift outliers and temporary change outliers.\n\nObtained by a modification of the asymptotic formula of Ljung (1993) that interpolates critical values for numbers of observations between 3 and 99.\n\n\noutlier.method\n\nDetermines how the program successively adds detected outliers to the model. The choices are \"addone\" or \"addall\".\n\"addone\" calculates t-statistics for each type of outlier specified at all time points.\n\"addall\" follows the same general steps as the addone method, except it adds to the model all outliers with absolute t-statistics exceeding the critical value.\n\n\"addone\".\n\n\noutlier.span\nSpecifies start and end dates of a span of the time series to be searched for outliers. The start and end dates of the span must both lie within the series.\nNone.\n\n\noutlier.types\nSpecifies the types of outliers to detect. The choices are: \"ao\" (additive outliers), \"ls\" (level shifts), \"tc\" (temporary change), \"all\": (detect all three of the above types simultaneously), and \"none\" (turn off outlier detection, but not t-statistics for temporary level shifts).\nThe default is c(\"ao\", \"ls\")."
  },
  {
    "objectID": "33-outliers.html#outlier-effects",
    "href": "33-outliers.html#outlier-effects",
    "title": "10  Outliers",
    "section": "\n10.2 Outlier Effects",
    "text": "10.2 Outlier Effects\nThis section discusses how to adjust a series for different types of outlier effects. Figure Figure 10.1 shows the most common ones.\n\n\n\n\nFigure 10.1: Outlier effects\n\n\n\n\n10.2.1 Level Shift (LS)\nThe first outlier category we look at are level shifts. Level shifts refers to a sudden and sustained change in the underlying level of a time series. There can be various causes of level shifts in time series data, such as changes in concepts or definitions of the survey population, alterations in the method of data collection, shifts in economic behavior, changes in legislation, etc. Level shifts are a problem for seasonal adjustment because they will distort the estimation of the seasonal factors.\nBelow is an example of a manually specified level shift:\n\nm_level_shift &lt;- seas(\n  AirPassengers,\n  regression.variables = \"ls1953.Jun\",\n  outlier = NULL\n)\nsummary(m_level_shift)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier = NULL, regression.variables = \"ls1953.Jun\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; LS1953.Jun        -0.0782358  0.0270308  -2.894 0.003800 ** \n#&gt; Weekday           -0.0024659  0.0006125  -4.026 5.67e-05 ***\n#&gt; Easter[1]          0.0205837  0.0084022   2.450 0.014294 *  \n#&gt; MA-Nonseasonal-01  0.3020780  0.0823400   3.669 0.000244 ***\n#&gt; MA-Seasonal-12     0.5241174  0.0756816   6.925 4.35e-12 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 959.8, BIC: 976.4  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.):  26.8   Shapiro (normality): 0.9807 *\n\nWe use the regression.variables argument to manually specify a level-shift. Since we want to deactivate the automated outlier detection from above, we specify outlier = NULL.\nLevel shifts are a problem for seasonal adjustment because they will distort the estimation of the seasonal factors. Within X-13, the initial trend is calculated by applying a moving average to the series. If there is an abrupt change in the level of the series, the estimates will be distorted. The estimates before the level shift will be underestimated, and those after will be overestimated. As the calculation of the irregular and seasonal components follow on from this initial trend-cycle estimation, they may be distorted as well.\nIf your series has canceling Level Shifts:\n\nAlso called temporary level shifts\nNOT temporary changes\n2 (or more) level shifts whose effects cancel\nCan replace them with additive outliers (over short spans) or use a temporary level shift regressor\n\nWe use, for example, regression.variables = c(TL1953.Jun, TL1953.Sep) argument to manually specify a temporary level-shift.\n\n10.2.2 Additive Outliers (AO)\nAn additive outlier is a data point that falls outside the general pattern of the trend and seasonal component in a time series. Outliers can be caused by random effects, such as an extreme irregular point, or by identifiable factors, such as a strike or bad weather.\nAdditive outliers pose a significant challenge to seasonal adjustment methods, which rely on moving averages. The crux of the problem lies in the inherent sensitivity of averages to the presence of extreme values or outliers. When unusual data points are included, the average can become unrepresentative of the underlying pattern in the series. Without proper adjustments or allowances for outliers, estimates for all the components in a time series can become distorted. As such, addressing additive outliers is critical to maintaining the integrity of seasonal adjustment techniques and ensuring accurate analyses.\nBelow is an example of a manually specified additive outlier:\n\nm_additive_outlier &lt;- seas(\n  AirPassengers,\n  regression.variables = \"ao1954.Feb\",\n  outlier = NULL\n)\nsummary(m_additive_outlier)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers, outlier = NULL, regression.variables = \"ao1954.Feb\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; AO1954.Feb        -0.0733392  0.0217684  -3.369 0.000754 ***\n#&gt; Weekday           -0.0026730  0.0005682  -4.705 2.54e-06 ***\n#&gt; Easter[1]          0.0222881  0.0079155   2.816 0.004866 ** \n#&gt; MA-Nonseasonal-01  0.2014840  0.0844582   2.386 0.017051 *  \n#&gt; MA-Seasonal-12     0.5483430  0.0750706   7.304 2.79e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 956.7, BIC: 973.3  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 32.09   Shapiro (normality): 0.9819 .\n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n\nAgain, we use the regression.variables argument to manually specify an additive outlier. Since we want to deactivate the automated outlier detection from above, we specify outlier = NULL.\n\n10.2.3 Temporary Change Regressor (TL, TC)\nWe use the regression.variables = TCyyyy.mm format for a temporary change.\n\\[ \\begin{cases}\n0 \\qquad &\\mbox{for} ~t &lt; t_0 \\\\\n\\alpha^{t - t_0} \\qquad &\\mbox{for} ~t \\geq t_0\n\\end{cases}\n\\]\nWhere \\(\\alpha\\) is the rate of decay back to the previous level, 0 &lt; \\(\\alpha\\) &lt; 1 (default: 0.7 for monthly and 0.343 for quarterly series)\n\n10.2.4 Ramps (RP, QI, QD)\n\n\n\n\n\nType of ramps\n\n\n\nFigure 10.2: Types of ramp regressors."
  },
  {
    "objectID": "33-outliers.html#manually-identifying-outliers",
    "href": "33-outliers.html#manually-identifying-outliers",
    "title": "10  Outliers",
    "section": "\n10.3 Manually Identifying Outliers",
    "text": "10.3 Manually Identifying Outliers\nX-13 contains an automated outlier detection procedure that works well in most circumstances and can be used as a starting point. Plotting the series may add additional information on whether outliers should be adjusted or not. The identify() method opens a window that allows you to manually identify outliers. Select or deselect outliers by point and click. To quit and return the call, press ESC. Click several times to loop through different outlier types.\n\nm &lt;- seas(\n  AirPassengers\n)\nidentify(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n#&gt; seas(\n#&gt;   x = AirPassengers,\n#&gt;   regression.variables = c(\"td1coef\", \"easter[1]\", \"ao1951.May\"),\n#&gt;   arima.model = \"(0 1 1)(0 1 1)\",\n#&gt;   regression.aictest = NULL,\n#&gt;   outlier = NULL,\n#&gt;   transform.function = \"log\"\n#&gt; )\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;           Weekday          Easter[1]         AO1951.May  MA-Nonseasonal-01  \n#&gt;          -0.00295            0.01777            0.10016            0.11562  \n#&gt;    MA-Seasonal-12  \n#&gt;           0.49736"
  },
  {
    "objectID": "33-outliers.html#when-outliers-are-found",
    "href": "33-outliers.html#when-outliers-are-found",
    "title": "10  Outliers",
    "section": "\n10.4 When Outliers Are Found",
    "text": "10.4 When Outliers Are Found\n\nALWAYS, ALWAYS, ALWAYS check if outliers are reasonable\nHard-code known outliers in production\nUsually a concern only for the most recent part of the series"
  },
  {
    "objectID": "33-outliers.html#exercise",
    "href": "33-outliers.html#exercise",
    "title": "10  Outliers",
    "section": "\n10.5 Exercise",
    "text": "10.5 Exercise\n\nCan you explain the difference between an extreme value and an outlier? Does it makes to remove extreme values? What about outliers?"
  },
  {
    "objectID": "34-seasonal-breaks.html#identifying-a-seasonal-break",
    "href": "34-seasonal-breaks.html#identifying-a-seasonal-break",
    "title": "11  Seasonal breaks",
    "section": "\n11.1 Identifying a seasonal break",
    "text": "11.1 Identifying a seasonal break\nIn a previous case study, we analyzed the imports of goods to China, where we detected a pretty obvious seasonal break.\nChinese imports are included as an example series in seasonal, both with and without the official seasonal adjustment.\n\nlibrary(tsbox)\nstopifnot(packageVersion(\"seasonalbook\") &gt;= \"0.0.2\")\nlibrary(seasonalbook)\nlibrary(seasonal)\n\nts_plot(imp_cn)\n\n\n\n\nAs can be spotted quickly, the series has a very different seasonal pattern before 2000. In our previous example, we simply cut the data and focused on the later period.\n\nts_plot(ts_span(imp_cn, start = 2000))\n\n\n\n\nThe seasonal break is even clearer to spot in the monthplot of the series:\n\nmonthplot(seas(imp_cn))\n\n\n\n\nThis makes it obvious that there were very strong December effects before 2000. We don’t know anything about the series, but we can speculate that prior to 2000, custom receipts were counted at the end of the year, rather than at the date of import.\n\nm = seas(\n  imp_cn,\n  x11 = \"\",\n  regression.variables = c(\"seasonal/2000.1/\"),\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, transform.function = \"log\", regression.aictest = NULL, \n#&gt;     outlier = NULL, x11 = \"\", regression.variables = c(\"seasonal/2000.1/\"))\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Jan               -0.0654535  0.0181009  -3.616 0.000299 ***\n#&gt; Feb               -0.1970206  0.0180950 -10.888  &lt; 2e-16 ***\n#&gt; Mar                0.0356460  0.0181169   1.968 0.049119 *  \n#&gt; Apr                0.0328228  0.0181109   1.812 0.069937 .  \n#&gt; May               -0.0238587  0.0180941  -1.319 0.187307    \n#&gt; Jun                0.0067156  0.0180789   0.371 0.710295    \n#&gt; Jul                0.0354693  0.0180731   1.963 0.049699 *  \n#&gt; Aug                0.0350369  0.0180802   1.938 0.052641 .  \n#&gt; Sep                0.0813043  0.0180989   4.492 7.05e-06 ***\n#&gt; Oct               -0.0441661  0.0181234  -2.437 0.014811 *  \n#&gt; Nov                0.0328833  0.0181436   1.812 0.069926 .  \n#&gt; Jan I             -0.3183942  0.0352764  -9.026  &lt; 2e-16 ***\n#&gt; Feb I             -0.1122450  0.0350760  -3.200 0.001374 ** \n#&gt; Mar I             -0.0295122  0.0350251  -0.843 0.399452    \n#&gt; Apr I             -0.0286242  0.0348917  -0.820 0.412005    \n#&gt; May I              0.0669706  0.0347657   1.926 0.054062 .  \n#&gt; Jun I              0.0165824  0.0347032   0.478 0.632768    \n#&gt; Jul I             -0.0001398  0.0347261  -0.004 0.996788    \n#&gt; Aug I             -0.0354610  0.0348208  -1.018 0.308495    \n#&gt; Sep I             -0.0641267  0.0349392  -1.835 0.066449 .  \n#&gt; Oct I              0.0496035  0.0349988   1.417 0.156398    \n#&gt; Nov I              0.0332059  0.0348833   0.952 0.341142    \n#&gt; Constant           0.0098924  0.0030076   3.289 0.001005 ** \n#&gt; MA-Nonseasonal-01  0.6490499  0.0510055  12.725  &lt; 2e-16 ***\n#&gt; MA-Nonseasonal-02 -0.1976993  0.0507758  -3.894 9.88e-05 ***\n#&gt; MA-Seasonal-12    -0.2451488  0.0506633  -4.839 1.31e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 2)(0 0 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.76e+04, BIC: 1.77e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 25.25   Shapiro (normality): 0.9328 ***\n#&gt; Messages generated by X-13:\n#&gt; Warnings:\n#&gt; - At least one visually significant trading day peak has been\n#&gt;   found in one or more of the estimated spectra.\n#&gt; \n#&gt; Notes:\n#&gt; - Stable seasonal regressors present in the regARIMA model.\n#&gt;   Maximum seasonal difference in automatic model\n#&gt;   identification procedure set to zero.\n\nThe coefficients from the summary are as follows:\n\n\nMonth\nPre 2000 coefficients\nPost 2000 coefficients\n\n\n\nJan\n-0.0654535\n-0.3183942\n\n\nFeb\n-0.1970206\n-0.1122450\n\n\nMar\n0.0356460\n-0.0295122\n\n\nApr\n0.0328228\n-0.0286242\n\n\nMay\n-0.0238587\n0.0669706\n\n\nJun\n0.0067156\n0.0165824\n\n\nJul\n0.0354693\n-0.0001398\n\n\nAug\n0.0350369\n-0.0354610\n\n\nSep\n0.0813043\n-0.0641267\n\n\nOct\n-0.0441661\n0.0496035\n\n\nNov\n0.0328833\n0.0332059\n\n\nDec (derived)\n-0.0294782\n0.3710507\n\n\n\nWe see multiple sign changes and multiple large discrepancies between the two model spans. This is an indication that this series has a change-of-regime. Also as previously indicated the December effect was much different post 2000."
  },
  {
    "objectID": "34-seasonal-breaks.html#restricting-model-span",
    "href": "34-seasonal-breaks.html#restricting-model-span",
    "title": "11  Seasonal breaks",
    "section": "\n11.2 Restricting model span",
    "text": "11.2 Restricting model span\nIn many cases, restricting series.modelspan may be the easiest way to deal with such series.\nWhen restricting the model span, we use only part of the series for model estimation, but still applies seasonal adjustment to the whole series. Thus, the ARIMA model is the same as if we cutted the span of the series before adjustment (as we did in the previous case study):\n\n\nm_modelspan &lt;- seas(\n  imp_cn,\n  series.modelspan = \"2000.jan,\",\n  x11 = list()\n)\nsummary(m_modelspan)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, series.modelspan = \"2000.jan,\", x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; AO2001.Jan        -0.261726   0.043878  -5.965 2.45e-09 ***\n#&gt; AO2004.Feb         0.218728   0.042608   5.133 2.84e-07 ***\n#&gt; LS2008.Nov        -0.327482   0.047759  -6.857 7.03e-12 ***\n#&gt; AO2009.Jan        -0.280528   0.042369  -6.621 3.56e-11 ***\n#&gt; AO2011.Jan         0.153783   0.042806   3.593 0.000328 ***\n#&gt; AO2012.Jan        -0.169644   0.043482  -3.901 9.56e-05 ***\n#&gt; AO2012.Feb         0.174648   0.043120   4.050 5.11e-05 ***\n#&gt; LS2016.Jan        -0.229816   0.047847  -4.803 1.56e-06 ***\n#&gt; Weekday            0.006700   0.000806   8.313  &lt; 2e-16 ***\n#&gt; AR-Nonseasonal-01 -0.426105   0.054515  -7.816 5.44e-15 ***\n#&gt; MA-Seasonal-12     0.794516   0.040311  19.710  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (1 1 0)(0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.258e+04, BIC: 1.262e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 31.39   Shapiro (normality): 0.9949\n\nm_span &lt;- seas(\n  ts_span(imp_cn, \"2000-01\"),\n  x11 = list()\n)\nsummary(m_span)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = ts_span(imp_cn, \"2000-01\"), x11 = list())\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; AO2001.Jan        -0.261726   0.043878  -5.965 2.45e-09 ***\n#&gt; AO2004.Feb         0.218728   0.042608   5.133 2.84e-07 ***\n#&gt; LS2008.Nov        -0.327482   0.047759  -6.857 7.03e-12 ***\n#&gt; AO2009.Jan        -0.280528   0.042369  -6.621 3.56e-11 ***\n#&gt; AO2011.Jan         0.153783   0.042806   3.593 0.000328 ***\n#&gt; AO2012.Jan        -0.169644   0.043482  -3.901 9.56e-05 ***\n#&gt; AO2012.Feb         0.174648   0.043120   4.050 5.11e-05 ***\n#&gt; LS2016.Jan        -0.229816   0.047847  -4.803 1.56e-06 ***\n#&gt; Weekday            0.006700   0.000806   8.313  &lt; 2e-16 ***\n#&gt; AR-Nonseasonal-01 -0.426105   0.054515  -7.816 5.44e-15 ***\n#&gt; MA-Seasonal-12     0.794516   0.040311  19.710  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (1 1 0)(0 1 1)  Obs.: 276  Transform: log\n#&gt; AICc: 1.258e+04, BIC: 1.262e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 31.39   Shapiro (normality): 0.9949\n\nBy using the series.modelspan, we restrict the data used in the ARIMA model, but we sill adjust the whole series. This leads to almost the same seasonally adjusted series in the overlapping period (after 2000).\n\nts_plot(\n  final(m_modelspan),\n  final(m_span)\n)\n\n\n\n\nNote that the ARIMA model that has been chosen is not optimal for the period before 2000. This will affect the backcast of the series, and may lead to slighly sub-optimal results for the first year. Since the interest in the accuracy of the latest data is usually much higher, this seems like a good compromise in many cases."
  },
  {
    "objectID": "34-seasonal-breaks.html#modelling-seasonal-breaks",
    "href": "34-seasonal-breaks.html#modelling-seasonal-breaks",
    "title": "11  Seasonal breaks",
    "section": "\n11.3 Modelling seasonal breaks",
    "text": "11.3 Modelling seasonal breaks\nA way to ‘model’ seasonal breaks to include seasonal dummies before (and possibly after) the supposed break. A seasonal dummy model can be estimated by an appropriate specification of the regression.variables argument. This is done with a so-called change-of-regime regression variable. There are two types of change-of-regime regressors available: full and partial.\nChange of regime regressors are denoted by adding the change date, enclosed in one or two slashes. This designated date divides the series under analysis into two periods: an early span encompassing data prior to the change date, and a late span covering data from this date onwards.\n\nPartial change of regime variables are active only within one of these spans, while remaining zero in the other.\nFull change of regime variables simultaneously estimate the base regression and the partial change of regime regression for the early span.\n\n\n\n\n\n\n\n\nType\nSyntax\nExample\n\n\n\nFull change of regime regressor\nreg/date/\nseasonal/2000.jan/\n\n\nPartial change of regime regressor, zero before change date\nreg//date/\nseasonal//2000.jan/\n\n\nPartial change of regime regressor, zero on and after change date\nreg/date//\nsesaonal/2000.jan//\n\n\n\nTo model the span after 2000, we can either cut the time series input (as we did in the case study), or use the series.span argument:\n\nm1 &lt;- seas(\n  imp_cn,\n  outlier = NULL,\n  x11 = \"\",\n  arima.model = \"(0 1 1)\",\n  transform.function = \"log\",\n  regression.variables = \"seasonal\",\n  series.span = \"2000.jan,\"\n)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, transform.function = \"log\", outlier = NULL, \n#&gt;     x11 = \"\", arima.model = \"(0 1 1)\", regression.variables = \"seasonal\", \n#&gt;     series.span = \"2000.jan,\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Jan               -0.068265   0.013106  -5.209 1.90e-07 ***\n#&gt; Feb               -0.203522   0.013082 -15.558  &lt; 2e-16 ***\n#&gt; Mar                0.033622   0.013063   2.574  0.01006 *  \n#&gt; Apr                0.033961   0.013048   2.603  0.00925 ** \n#&gt; May               -0.023603   0.013039  -1.810  0.07027 .  \n#&gt; Jun                0.008008   0.013033   0.614  0.53896    \n#&gt; Jul                0.039197   0.013035   3.007  0.00264 ** \n#&gt; Aug                0.035561   0.013041   2.727  0.00640 ** \n#&gt; Sep                0.086085   0.013049   6.597 4.19e-11 ***\n#&gt; Oct               -0.042614   0.013063  -3.262  0.00111 ** \n#&gt; Nov                0.033393   0.013083   2.552  0.01070 *  \n#&gt; Weekday            0.006096   0.001137   5.362 8.24e-08 ***\n#&gt; MA-Nonseasonal-01  0.342034   0.056700   6.032 1.62e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)  Obs.: 276  Transform: log\n#&gt; AICc: 1.326e+04, BIC: 1.33e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 27.61   Shapiro (normality): 0.9556 ***\n\nIn order to model the span before 2000, the specification looks as follows:\n\nm2 &lt;- seas(\n  imp_cn,\n  outlier = NULL,\n  x11 = \"\",\n  arima.model = \"(0 1 1)\",\n  transform.function = \"log\",\n  regression.variables = \"seasonal\",\n  series.span = \",1999.dec\"\n)\nsummary(m2)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, transform.function = \"log\", outlier = NULL, \n#&gt;     x11 = \"\", arima.model = \"(0 1 1)\", regression.variables = \"seasonal\", \n#&gt;     series.span = \",1999.dec\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Jan               -0.387506   0.033779 -11.472   &lt;2e-16 ***\n#&gt; Feb               -0.304623   0.033613  -9.063   &lt;2e-16 ***\n#&gt; Mar               -0.001298   0.033535  -0.039   0.9691    \n#&gt; Apr               -0.007866   0.033531  -0.235   0.8145    \n#&gt; May                0.048099   0.033810   1.423   0.1548    \n#&gt; Jun                0.009728   0.033459   0.291   0.7712    \n#&gt; Jul                0.029471   0.033391   0.883   0.3774    \n#&gt; Aug                0.007545   0.033592   0.225   0.8223    \n#&gt; Sep                0.005823   0.033691   0.173   0.8628    \n#&gt; Oct                0.019756   0.033711   0.586   0.5578    \n#&gt; Nov                0.077857   0.033614   2.316   0.0205 *  \n#&gt; Weekday            0.008259   0.003786   2.182   0.0291 *  \n#&gt; MA-Nonseasonal-01  0.670552   0.072772   9.214   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)  Obs.: 96  Transform: log\n#&gt; AICc:  4264, BIC:  4295  QS (no seasonality in final):6.021 *\n#&gt; Box-Ljung (no autocorr.): 45.85 ** Shapiro (normality): 0.9202 ***\n\nNote that we set outlier, arima.model and transform.function such that we can ensure comparability.\nWe can use the regression.variables argument to estimate the whole span in one call:\n\nm3 &lt;- seas(\n  imp_cn,\n  outlier = NULL,\n  x11 = \"\",\n  arima.model = \"(0 1 1)\",\n  transform.function = \"log\",\n  regression.variables = \"seasonal/2000.jan//\", \n)\nsummary(m3)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = imp_cn, transform.function = \"log\", outlier = NULL, \n#&gt;     x11 = \"\", arima.model = \"(0 1 1)\", regression.variables = \"seasonal/2000.jan//\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Jan I             -0.386705   0.034705 -11.143  &lt; 2e-16 ***\n#&gt; Feb I             -0.301462   0.034517  -8.734  &lt; 2e-16 ***\n#&gt; Mar I              0.004075   0.034367   0.119 0.905618    \n#&gt; Apr I             -0.001388   0.034268  -0.040 0.967700    \n#&gt; May I              0.050501   0.034285   1.473 0.140765    \n#&gt; Jun I              0.015335   0.034187   0.449 0.653745    \n#&gt; Jul I              0.033103   0.034199   0.968 0.333078    \n#&gt; Aug I              0.006655   0.034294   0.194 0.846126    \n#&gt; Sep I              0.006256   0.034369   0.182 0.855558    \n#&gt; Oct I              0.012976   0.034397   0.377 0.706007    \n#&gt; Nov I              0.068627   0.034354   1.998 0.045755 *  \n#&gt; Weekday            0.006342   0.001790   3.543 0.000395 ***\n#&gt; MA-Nonseasonal-01  0.559147   0.042527  13.148  &lt; 2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (0 1 1)  Obs.: 372  Transform: log\n#&gt; AICc: 1.779e+04, BIC: 1.785e+04  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 248.8 *** Shapiro (normality): 0.9482 ***\n\nBy default, seasonal outliers are removed from the final series."
  },
  {
    "objectID": "34-seasonal-breaks.html#when-to-model-a-seasonal-break",
    "href": "34-seasonal-breaks.html#when-to-model-a-seasonal-break",
    "title": "11  Seasonal breaks",
    "section": "\n11.4 When to model a seasonal break?",
    "text": "11.4 When to model a seasonal break?\nWhen should we model a seasonal break? When we have enough data after the break (as in the imports of goods to China example), restricting series.modelspan is the easiest way and leads to good results.\nIn some situations you may not be able to restrict the model span. For example if the seasonal break too close to the end of the series or if there is a policy restricting it. In this case, modelling the seasonal break using seasonal regressors may be an option. We apply this technique in the following Case study."
  },
  {
    "objectID": "34-seasonal-breaks.html#case-study-azerbaijani-budget-expenditures",
    "href": "34-seasonal-breaks.html#case-study-azerbaijani-budget-expenditures",
    "title": "11  Seasonal breaks",
    "section": "\n11.5 Case Study: Azerbaijani Budget Expenditures",
    "text": "11.5 Case Study: Azerbaijani Budget Expenditures\n\nlibrary(cbar.sa)\n#&gt; \n#&gt; Attaching package: 'cbar.sa'\n#&gt; The following object is masked _by_ '.GlobalEnv':\n#&gt; \n#&gt;     m1\n#&gt; The following object is masked from 'package:seasonal':\n#&gt; \n#&gt;     cpi\nlibrary(seasonal)\nlibrary(dplyr)\nlibrary(tsbox)\n\n\n# visually not obious seasonal break\nts_plot(budg_exp)\n\n# month plot of detrended series\nmonthplot(budg_exp - ts_trend(budg_exp))\n\nm1 &lt;- seas(\n  x = budg_exp,\n  x11 = \"\",\n  regression.variables = c(\"const\", \"ao2017.4\", \"seasonal/2016.1/\"),\n  arima.model = \"(2 0 0)(1 0 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = budg_exp, transform.function = \"log\", regression.aictest = NULL, \n#&gt;     outlier = NULL, x11 = \"\", regression.variables = c(\"const\", \n#&gt;         \"ao2017.4\", \"seasonal/2016.1/\"), arima.model = \"(2 0 0)(1 0 1)\")\n#&gt; \n#&gt; Coefficients:\n#&gt;                    Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Constant           8.338851   0.390244  21.368  &lt; 2e-16 ***\n#&gt; AO2017.4          -0.336074   0.132358  -2.539 0.011113 *  \n#&gt; 1st               -0.217537   0.038891  -5.594 2.22e-08 ***\n#&gt; 2nd               -0.042023   0.039121  -1.074 0.282732    \n#&gt; 3rd               -0.035355   0.040778  -0.867 0.385942    \n#&gt; 1st I             -0.002449   0.054689  -0.045 0.964286    \n#&gt; 2nd I             -0.016296   0.054168  -0.301 0.763535    \n#&gt; 3rd I             -0.075518   0.055309  -1.365 0.172135    \n#&gt; AR-Nonseasonal-01  0.545723   0.111017   4.916 8.85e-07 ***\n#&gt; AR-Nonseasonal-02  0.417009   0.113237   3.683 0.000231 ***\n#&gt; AR-Seasonal-04    -0.152188   0.354758  -0.429 0.667930    \n#&gt; MA-Seasonal-04    -0.278102   0.373339  -0.745 0.456329    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; X11 adj.  ARIMA: (2 0 0)(1 0 1)  Obs.: 62  Transform: log\n#&gt; AICc:  1022, BIC:  1042  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 30.17   Shapiro (normality): 0.9883\n\n\nm2 &lt;- seas(\n  x = budg_exp,\n  x11 = \"\",\n  series.modelspan = \"2016.1,\",\n  regression.variables = c(\"const\", \"ao2017.4\"),\n  arima.model = \"(2 0 0)(1 1 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)\n\nm3 &lt;- seas(\n  x = budg_exp,\n  x11 = \"\",\n  regression.variables = c(\"const\", \"ao2017.4\", \"seasonal/2016.1//\"),\n  arima.model = \"(2 0 0)(1 1 1)\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  transform.function = \"log\"\n)"
  },
  {
    "objectID": "40-part-other-issues.html",
    "href": "40-part-other-issues.html",
    "title": "Other Issues",
    "section": "",
    "text": "Part IV investigates more holistic issues that practitioners face. The main focus is to give classical methodology to answer their problems. Since these types of issues can be highly specialized, we concentrate on known solutions to the topics."
  },
  {
    "objectID": "41-presence-of-seasonality.html#basic-principle",
    "href": "41-presence-of-seasonality.html#basic-principle",
    "title": "12  Presence of seasonality",
    "section": "\n12.1 Basic Principle",
    "text": "12.1 Basic Principle\nIn general, adjusting a non-seasonal series is less of a problem than not adjusting a seasonal series. So, unless you have good reasons to believe that a series is not-seasonal, adjust it. When in doubt, adjust!\nOf course the final answer is never so simple. For example, the International Monetary Fund (IMF) in their Quarterly National Accounts Manual about seasonal adjustment says, “A series should be seasonally adjusted only when there is evidence of identifiable seasonality. Series with no seasonality or too unstable seasonality should not be seasonally adjusted.” The IMF is attempting to maintain accounting relationship which are of utmost important to their seasonal adjustment policies."
  },
  {
    "objectID": "41-presence-of-seasonality.html#available-tests",
    "href": "41-presence-of-seasonality.html#available-tests",
    "title": "12  Presence of seasonality",
    "section": "\n12.2 Available Tests",
    "text": "12.2 Available Tests\nTo help you to make a good decision, X-13 offers a few formal checks:\n\nThe QS test is the primary test to evaluate seasonality both the original or in the adjusted series. It will be discussed in more detail in Chapter 15.\nThe Identifiable Seasonality Test (IDS) gives a simple yes or no answer to whether a series is seasonal or not. It is available for X11 adjustments only.\nThe M7 statistic applies critical values to the Identifiable Seasonality Test (IDS) and returns a simple yes or no answer.\nF-test for seasonal regressors\n\nWhich tests are preferable, and how should a user decide if the tests are not aligned? Often, this will only happen with marginal cases and hence we suggest following our guiding principle and adjusting your series. More often than not the tests will provide enough evidence to make help make an informed decision about whether a series is seasonal or not."
  },
  {
    "objectID": "41-presence-of-seasonality.html#qs-test",
    "href": "41-presence-of-seasonality.html#qs-test",
    "title": "12  Presence of seasonality",
    "section": "\n12.3 QS Test",
    "text": "12.3 QS Test\nThe QS test has a few advantages compared to the IDS statistics and is generally preferable. It is available both with X11 and SEATS.\nYou can retrieve the results of the QS test by the qs() function. (We will say more about the QS statistic in Chapter 15).\n\nqs(seas(AirPassengers))\n#&gt;                     qs  p-val\n#&gt; qsori        167.64858 0.0000\n#&gt; qsorievadj   203.07731 0.0000\n#&gt; qsrsd          0.00000 1.0000\n#&gt; qssadj         0.00000 1.0000\n#&gt; qssadjevadj    0.00000 1.0000\n#&gt; qsirr          0.00000 1.0000\n#&gt; qsirrevadj     0.00000 1.0000\n#&gt; qssori       115.08988 0.0000\n#&gt; qssorievadj  135.11320 0.0000\n#&gt; qssrsd         0.36904 0.8315\n#&gt; qsssadj        0.00000 1.0000\n#&gt; qsssadjevadj   0.00000 1.0000\n#&gt; qssirr         0.00000 1.0000\n#&gt; qssirrevadj    0.00000 1.0000\n\nThe QS Statistic shows the degree of seasonality in various components of the seasonal adjustment. For our purposes, the first line is the most interesting. It shows that the QS value of the original series is 168, which comes with a p-value of essentially 0. Since the null hypothesis is no seasonality, this p-value can be read as high evidence the series is seasonal.\nIn other words, AirPassengers is a clearly seasonal series, which should not come as a surprise at this point.\nIf you encounter a series with a moderate p-value for the first line, you can also consider the 8th line (the second occurrence of qsori) which again calculates the QS statistic for the original series but restricting the view to the most recent 8 years of data. Since often the more recent data is more crucial to seasonal adjust correctly this additional test can help make the decision."
  },
  {
    "objectID": "41-presence-of-seasonality.html#identifiable-seasonality-test",
    "href": "41-presence-of-seasonality.html#identifiable-seasonality-test",
    "title": "12  Presence of seasonality",
    "section": "\n12.4 Identifiable Seasonality Test",
    "text": "12.4 Identifiable Seasonality Test\nA second test for seasonality is the Identifiable Seasonality Test. It is only available in X11.\nAccording to UK Office for National Statistics (2007), a value lower than 1.150 (monthly series) or lower than 0.900 (quarterly series) indicates that seasonality is clearly present.\n\nUK Office for National Statistics. 2007. Guide to Seasonal Adjustment with x-12-ARIMA. http://www.ons.gov.uk/ons/guide-method/method-quality/general-methodology/time-series-analysis/guide-to-seasonal-adjustment.pdf.\nAt the same time, a value between 1.150 and 1.250 (monthly series) or between 0.900 and 1.050 (quarterly series) indicates that seasonality may be present.\nValues above 1.250 (monthly series) or 1.050 (quarterly series) point to non-seasonal series.\nAs we have stated above, the recommendation is to adjust the series unless you have clear evidence that a series is not seasonal.\nLet’s try AirPassengers:\n\nudg(seas(AirPassengers, x11 = list()), \"f3.m07\")\n#&gt; f3.m07 \n#&gt;  0.203\nudg(seas(AirPassengers, x11 = list()), \"f2.idseasonal\")\n#&gt; f2.idseasonal \n#&gt;         \"yes\"\n\nThe M7 value is way below the critical values. Accordingly, the Identifiable Seasonality Test indicates seasonality in the series."
  },
  {
    "objectID": "41-presence-of-seasonality.html#case-study",
    "href": "41-presence-of-seasonality.html#case-study",
    "title": "12  Presence of seasonality",
    "section": "\n12.5 Case Study",
    "text": "12.5 Case Study\nConsider the following less clear-cut series:\n\nlibrary(tsbox)\nlibrary(seasonal)\n\nx &lt;- ts(\n  c(\n    1070.67782091276, 1074.85048025033, 1057.22943663105, 1054.83329692382,\n    1035.00741277933, 1014.37654341674, 1016.01971482192, 1031.5736998743,\n    1055.97206482734, 1069.14603895638, 1054.70695712307, 1033.65404358999,\n    988.507205808669, 957.755772336067, 936.185046914472, 939.221279279722,\n    962.250799500941, 984.056833428967, 999.390633761089, 1033.68786613334,\n    1055.87289736274, 1097.92353618165, 1114.50822274577, 1148.65763657244,\n    1199.32404772514, 1208.39317300933, 1185.13960320363, 1154.58521771845,\n    1101.7137166423, 1053.89252948544, 996.495317493457, 926.283479008456,\n    850.048912454291, 809.84549670808, 772.216576162406, 784.114051995134,\n    806.261273184001, 820.618967152661, 815.649757299053, 812.501547645406,\n    809.899692888929, 823.778177350232, 811.211453993884, 814.868987237855,\n    829.047528533717, 831.891817984415, 843.653707473654, 895.684951210102,\n    926.544452180194, 949.41125175328, 950.333376822119, 994.228127170556,\n    999.697246815797, 1008.00877350773, 1006.7566419533, 990.419046839283,\n    962.941704204873, 947.541756501729, 929.161895739204, 910.588436791225,\n    1248.42457644542, 1266.67760866087, 1248.78020047598, 1290.47101093513,\n    1328.51898051507, 1356.02796471527, 1363.37837075383, 1398.27679451834,\n    1399.20602270507, 1391.19336700805, 1387.13912745033, 1346.03774501977,\n    1370.73051832038, 1346.29966480321, 1340.09701324613, 1331.07456050929,\n    1321.82409348173, 1343.5116656349, 1366.41043298961, 1363.10871463069,\n    1391.84216974474, 1417.38495449438, 1432.17468812037, 1394.40194160954,\n    1385.72476381292, 1388.23802327199, 1354.10595421438, 1345.15701390051,\n    960.801527083357, 941.027878841707, 887.618178201697, 842.12961787775,\n    795.717159404159, 757.35803147815, 724.93681522789, 716.66515476601,\n    708.682334791168, 689.925785264133, 687.748168972216, 688.809213406042,\n    664.421326451325, 661.822007527535, 687.161046216216, 684.548292412124,\n    713.757983905367, 729.917128362926, 750.569868821847, 745.544259228118,\n    758.516668782925, 758.841495662419, 757.815323362363\n  ),\n  frequency = 4,\n  start = 1995\n)\n\nts_plot(x)\n\n\n\n\nIf we apply standard SEATS seasonal adjustment, this does not seem to do anything:\n\nm &lt;- seas(x)\nplot(m)\n\n\n\n\nWhat do formal statistics say?\n\nqs(m)\n#&gt;                   qs   p-val\n#&gt; qsori        0.00000 1.00000\n#&gt; qsorievadj   0.08751 0.95719\n#&gt; qsrsd        0.00000 1.00000\n#&gt; qssadj       0.00000 1.00000\n#&gt; qssadjevadj  0.08751 0.95719\n#&gt; qsirr        1.81436 0.40366\n#&gt; qsirrevadj   1.81436 0.40366\n#&gt; qssori       0.00000 1.00000\n#&gt; qssorievadj  0.78501 0.67536\n#&gt; qssrsd       0.26233 0.87707\n#&gt; qsssadj      0.00000 1.00000\n#&gt; qsssadjevadj 0.78501 0.67536\n#&gt; qssirr       1.92576 0.38179\n#&gt; qssirrevadj  1.92576 0.38179\n\nLet’s have a look at the first line. A QS value of 0 has a p-value of 1, meaning the Null-Hypothesis of no seasonality in the original value can not be rejected. According to this measure, it is clear that this series has no seasonality.\nIf we want to consider the M7 values, we need to use X11:\n\nm_x11 &lt;- seas(x, x11 = list())\n\nThe QS statistic has to be the same for the unadjusted series but not for the adjusted one:\n\nqs(m_x11)\n#&gt;                   qs   p-val\n#&gt; qsori        0.00000 1.00000\n#&gt; qsorievadj   0.08751 0.95719\n#&gt; qsrsd        0.00000 1.00000\n#&gt; qssadj       0.00000 1.00000\n#&gt; qssadjevadj  0.00000 1.00000\n#&gt; qsirr        0.00000 1.00000\n#&gt; qsirrevadj   0.03306 0.98361\n#&gt; qssori       0.00000 1.00000\n#&gt; qssorievadj  0.78501 0.67536\n#&gt; qssrsd       0.26233 0.87707\n#&gt; qsssadj      0.00000 1.00000\n#&gt; qsssadjevadj 0.00000 1.00000\n#&gt; qssirr       0.00000 1.00000\n#&gt; qssirrevadj  0.08751 0.95719\n\nBecause we use X11, we can now have a look at the M7 value:\n\nudg(m_x11, \"f3.m07\")\n#&gt; f3.m07 \n#&gt;  1.222\n\nIf you look for simple answers, the \"f2.idseasonal\" gives you a simple yes or no answer. From the previous discussion, it should not be surprising that the answer is no.\n\nudg(m_x11, \"f2.idseasonal\")\n#&gt; f2.idseasonal \n#&gt;          \"no\""
  },
  {
    "objectID": "41-presence-of-seasonality.html#f-test-for-seasonality",
    "href": "41-presence-of-seasonality.html#f-test-for-seasonality",
    "title": "12  Presence of seasonality",
    "section": "\n12.6 F-test for seasonality",
    "text": "12.6 F-test for seasonality\nAnother simple yet effective test for seasonality is to include seasonal regressor in your model and then check if they are significant.\n\nm = seas(\n  AirPassengers,\n  x11 = \"\",\n  arima.model = \"(0 1 1)\",\n  regression.variables = \"seasonal\"\n)\n\nFtest = udg(m, \"ftest$Seasonal\") |&gt; round(5)\ncolnames(Ftest) = c(\"Seasonal F-test\")\nrownames(Ftest) = c(\"df1\", \"df2\", \"test_stat\", \"p_value\")\nknitr::kable(Ftest)\n\n\n\n\nSeasonal F-test\n\n\n\ndf1\n11.00000\n\n\ndf2\n130.00000\n\n\ntest_stat\n96.50175\n\n\np_value\n0.00000\n\n\n\n\n\nWe see again that AirPassengers is seasonal.\n\nm = seas(\n  x,\n  x11 = \"\",\n  arima.model = \"(0 1 1)\",\n  regression.variables = \"seasonal\"\n)\n\nFtest = udg(m, \"ftest$Seasonal\") |&gt; round(5)\ncolnames(Ftest) = c(\"Seasonal F-test\")\nrownames(Ftest) = c(\"df1\", \"df2\", \"test_stat\", \"p_value\")\nknitr::kable(Ftest)\n\n\n\n\nSeasonal F-test\n\n\n\ndf1\n3.00000\n\n\ndf2\n99.00000\n\n\ntest_stat\n0.88871\n\n\np_value\n0.44982\n\n\n\n\n\nThe F-test again shows the case study series is not seasonal."
  },
  {
    "objectID": "42-annual-constraining.html#annual-constraining",
    "href": "42-annual-constraining.html#annual-constraining",
    "title": "13  Annual constraining",
    "section": "\n13.1 Annual constraining",
    "text": "13.1 Annual constraining\nThe yearly total of a seasonally adjusted series is usually not exactly equal to the yearly total of the original series. There is no theoretical reason why the annual totals of the original series and the seasonally adjusted series should be the same. For example, the number of trading days may differ in different years, and we would expect a trading day adjusted series to be different at the annual level.\nSometimes, however, it may be useful to apply annual constraining. The reason for this is usually to lower confusion for the end users. To constrain the annual totals, X13 includes a version of the Denton method. Let’s start with a SEATS adjustment of AirPassengers:\n\nm &lt;- seas(AirPassengers)\n\nThe tsbox package can be used to compute annual totals. As for AirPassengers, the annual total is the sum of the monthly values, but it sometimes makes sense to use \"mean\" as an aggregation function:\n\nlibrary(tsbox)\nts_frequency(final(seas(AirPassengers)), aggregate = \"sum\")\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1] 1525.447 1680.069 2051.848 2369.099 2703.072 2870.317 3408.276 3926.282\n#&gt;  [9] 4412.581 4562.307 5131.798 5684.992\nts_frequency(AirPassengers, aggregate = \"sum\")\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1] 1520 1676 2042 2364 2700 2867 3408 3939 4421 4572 5140 5714\n\nAs we can see, there are minor differences between the series. However, in this case, the differences are rather small, and at most as large as half a percentage point:\n\n100 * (ts_frequency(final(seas(AirPassengers)), aggregate = \"sum\") /\nts_frequency(AirPassengers, aggregate = \"sum\") - 1)\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1]  0.358358560  0.242769857  0.482294091  0.215704372  0.113791065\n#&gt;  [6]  0.115709710  0.008105796 -0.322870814 -0.190440290 -0.212002766\n#&gt; [11] -0.159572312 -0.507657103\n\nBy applying force.type = \"regress\", we constrain the annual values to be the same:\n\nts_frequency(final(seas(AirPassengers, force.type = \"regress\")), aggregate = \"sum\")\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1] 1520 1676 2042 2364 2700 2867 3408 3939 4421 4572 5140 5714\nts_frequency(AirPassengers, aggregate = \"sum\")\n#&gt; Time Series:\n#&gt; Start = 1949 \n#&gt; End = 1960 \n#&gt; Frequency = 1 \n#&gt;  [1] 1520 1676 2042 2364 2700 2867 3408 3939 4421 4572 5140 5714"
  },
  {
    "objectID": "42-annual-constraining.html#should-annual-values-be-constrained",
    "href": "42-annual-constraining.html#should-annual-values-be-constrained",
    "title": "13  Annual constraining",
    "section": "\n13.2 Should annual values be constrained?",
    "text": "13.2 Should annual values be constrained?\nAs previously discussed, there isn’t a theoretical justification for enforcing annual constraints. Implementing annual constraints ensures consistency in annual values across both seasonally adjusted and unadjusted series, which can reduce confusion and possibly enhance user satisfaction.\nHere are some guidelines (loosely based on UK Office for National Statistics (2007), Chapter 8.2.2) on deciding whether to apply annual constraints:\n\nUK Office for National Statistics. 2007. Guide to Seasonal Adjustment with x-12-ARIMA. http://www.ons.gov.uk/ons/guide-method/method-quality/general-methodology/time-series-analysis/guide-to-seasonal-adjustment.pdf.\n\nUsage\n\nMost importantly, consider how the data is used, and what is expected by users. For example, if the data are integrated into the National Accounts, they likely require constraining to align with other datasets.\n\nConceptual Appropriateness\n\nAssess if annual constraints are conceptually relevant for your dataset. For example, if your data is a price index, annual constraining is not appropriate.\n\nConsistency\n\nFor series already undergoing seasonal adjustment, a strong justification is needed to alter the constraining approach. Avoid frequently toggling the use of annual constraints to maintain methodological consistency.\n\nImpact Analysis\n\nExamine the differences (or ratios, if using a multiplicative model) between the constrained and unconstrained series in their final forms. If these differences are minor and other considerations support constraining, applying annual constraints may be the more suitable option."
  },
  {
    "objectID": "43-indirect-vs-direct.html#multiple-series-adjustment",
    "href": "43-indirect-vs-direct.html#multiple-series-adjustment",
    "title": "14  Indirect vs direct adjustment",
    "section": "\n14.1 Multiple series adjustment",
    "text": "14.1 Multiple series adjustment\nSince seasonal version 1.8, it is now possible to seasonally adjust multiple series in a single call to seas(). This is done by using the built-in batch mode of X-13. It removes the need for loops or lapply() in such cases and finally brings one missing feature of X-13 to seasonal – the composite spec.\nMultiple adjustments can be performed by supplying multiple time series as an \"mts\" object:\n\nlibrary(seasonal)\nlibrary(tsbox)\n\nm &lt;- seas(cbind(fdeaths, mdeaths), x11 = \"\")\nplot(final(m))\n\n\n\n\nThis will perform two seasonal adjustments, one for fdeaths and one for mdeaths. X-13 spec-argument combinations can be applied in the usual way, such as x11 = \"\". Note that if entered that way, they will apply to both series. The vignette on multiple adjustments describes how to specify options for individual series.\n\n14.1.1 Backend\nX-13 ships with a batch mode that allows multiple adjustments in a single call to X-13. This is now the default in seasonal (multimode = \"x13\"). Alternatively, X-13 can be called for each series (multimode = \"R\"). The results should be usually the same, but switching to multimode = \"R\" may be useful for debugging:\n\nseas(cbind(fdeaths, mdeaths), multimode = \"x13\")\n#&gt; $fdeaths\n#&gt; \n#&gt; Call:\n#&gt; seas(x = cbind(fdeaths, mdeaths), multimode = \"x13\")\n#&gt; \n#&gt; Coefficients:\n#&gt;       Constant      AO1976.Feb  MA-Seasonal-12  \n#&gt;       -0.01578         0.43345         0.63119  \n#&gt; \n#&gt; \n#&gt; $mdeaths\n#&gt; \n#&gt; Call:\n#&gt; seas(x = cbind(fdeaths, mdeaths), multimode = \"x13\")\n#&gt; \n#&gt; Coefficients:\n#&gt;        AO1976.Feb         LS1976.Apr         AO1977.Apr         AO1978.Feb  \n#&gt;            0.3319            -0.1330             0.1957             0.2305  \n#&gt;        AO1979.Dec  MA-Nonseasonal-01     MA-Seasonal-12  \n#&gt;           -0.3149            -0.3854             0.6120  \n#&gt; \n#&gt; \n#&gt; $call\n#&gt; seas(x = cbind(fdeaths, mdeaths), multimode = \"x13\")\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"seas_multi\" \"list\"\nseas(cbind(fdeaths, mdeaths), multimode = \"R\")\n#&gt; $fdeaths\n#&gt; \n#&gt; Call:\n#&gt; seas(x = cbind(fdeaths, mdeaths), multimode = \"R\")\n#&gt; \n#&gt; Coefficients:\n#&gt;       Constant      AO1976.Feb  MA-Seasonal-12  \n#&gt;       -0.01578         0.43345         0.63119  \n#&gt; \n#&gt; \n#&gt; $mdeaths\n#&gt; \n#&gt; Call:\n#&gt; seas(x = cbind(fdeaths, mdeaths), multimode = \"R\")\n#&gt; \n#&gt; Coefficients:\n#&gt;        AO1976.Feb         LS1976.Apr         AO1977.Apr         AO1978.Feb  \n#&gt;            0.3319            -0.1330             0.1957             0.2305  \n#&gt;        AO1979.Dec  MA-Nonseasonal-01     MA-Seasonal-12  \n#&gt;           -0.3149            -0.3854             0.6120  \n#&gt; \n#&gt; \n#&gt; $call\n#&gt; seas(x = cbind(fdeaths, mdeaths), multimode = \"R\")\n#&gt; \n#&gt; attr(,\"class\")\n#&gt; [1] \"seas_multi\" \"list\"\n\nIn general, multimode = \"x13\" is faster. The following comparison on a MacBook Pro shows a modest speed gain, but more significant differences have been observed on other systems:\nmany &lt;- rep(list(fdeaths), 100)\nsystem.time(seas(many, multimode = \"x13\"))\n #   user  system elapsed\n # 13.342   0.406  13.766\nsystem.time(seas(many, multimode = \"R\"))\n #   user  system elapsed\n # 15.819   0.814  16.958\nThe return value of system.time tells you how much time has been used for the operation. The first number measures the time spent in the current session, while ‘elapsed’ measures the overall time, as measured by the clock. system measures the operating system overhead. The distinction between these numbers is not too significant here; simply focus on ‘elapsed’, the details will be more interesting in the parallel examples.\n\n14.1.2 Parallelization\nIn principle, R is single threaded, and operations are normally performed on a single core. While there are many ways to perform parallel operations in R, their details often depend on the platform. So, currently, it is not possible to call parallelized operations directly from seasonal. Here is an example that computes the operations below on an 8 core Mac. The furrrr and the future package save a lot of the complications arising around parallelization.\n\n14.1.2.1 All Platforms\nOn Windows, Mac and Linux, you can use the multisession strategy, which essentially starts a separate session of R for any of the available cores. In the following, we use an 8 core Mac and gain a more than 4 times speed gain.\nlibrary(furrr)\nplan(multisession, workers = 8)\nans &lt;- future_map(many, \\(x) qs(seas(x))[1])\n\n\ndplyr::tibble(\n    ~id,      ~name,                       ~source, ~freq, ~data,\n    \"sdfasd\", \"Airline Passenger Numbers\", \"R\",     12,     AirPassengers\n)\n\n#   user  system elapsed\n#  0.171   0.008   4.081\n\n14.1.2.2 Non-Windows Platforms\nMac and Linux allow forking parallelization, which is easier to set up. Here, multiple cores share the same memory, without having to start separate sessions:\nlibrary(furrr)\nplan(multicore, workers = future::nbrOfWorkers())\nsystem.time(future_map(many, seas))\n\n\n#   user  system elapsed\n# 23.389   1.704   3.508"
  },
  {
    "objectID": "43-indirect-vs-direct.html#the-composite-spec",
    "href": "43-indirect-vs-direct.html#the-composite-spec",
    "title": "14  Indirect vs direct adjustment",
    "section": "\n14.2 The composite spec",
    "text": "14.2 The composite spec\nSupport for the X-13 batch mode makes it finally possible to use the composite spec – the one feature of X-13 that was missing in seasonal. Sometimes, one has to decide whether seasonal adjustment should be performed on a granular level or on an aggregated level. The composite spec helps you to analyze the problem and to compare the direct and the indirect adjustments.\nThe composite argument is a list with an X-13 specification that is applied on the aggregated series. Specification works identically for other series in seas(), including the application of the defaults. If you provide an empty list, the usual defaults of seas() are used. A minimal composite call looks like this:\n\nm_composite &lt;- seas(\n  cbind(mdeaths, fdeaths),\n  composite = list(),\n  series.comptype = \"add\"\n)\n\nThe final() command now returns three series, with one adjustment for each series, and one for the composite (direct) adjustment:\n\nhead(final(m_composite))\n#&gt;       mdeaths  fdeaths composite\n#&gt; [1,] 1566.633 605.9811  2140.037\n#&gt; [2,] 1514.975 538.6371  1932.479\n#&gt; [3,] 1468.244 589.4354  2024.396\n#&gt; [4,] 1678.065 606.7556  2308.137\n#&gt; [5,] 1661.425 599.5486  2276.030\n#&gt; [6,] 1557.990 547.2017  2090.735\n\nYou can verify that the composite refers to the total of mdeaths and fdeaths by running:\n\n\nm_direct &lt;- seas(ldeaths)\n\nwhereldeaths (which is also shipped with R, see ?ldeaths for an explanation on the data) is the sum of mdeaths and fdeaths:\n\nall.equal(ldeaths, mdeaths + fdeaths)\n#&gt; [1] TRUE\n\n\nall.equal(final(m_direct), final(m_composite)[, 'composite'])\n#&gt; [1] TRUE"
  },
  {
    "objectID": "43-indirect-vs-direct.html#indirect-vs-direct-adjustment",
    "href": "43-indirect-vs-direct.html#indirect-vs-direct-adjustment",
    "title": "14  Indirect vs direct adjustment",
    "section": "\n14.3 Indirect vs direct adjustment",
    "text": "14.3 Indirect vs direct adjustment\nThe composite adjustment contains all the information that is needed to analyze the direct vs the indirect adjustment.\n\n\nts_plot(\n  indirect = final(m_composite)[, 'mdeaths'] + final(m_composite)[, 'fdeaths'],\n  direct = final(m_composite)[, 'composite']\n)\n\n\n\n\nWhat we have seen above is an example of indirect vs direct adjustment. How to judge which one is better? Two criteria are often used: smoothness and stability\n\n14.3.1 Built-in tools\nX-13 offers various diagnostics to compare direct and indirect adjustments\n\nSpectral graphs\nSliding spans\n\nSet the same sliding spans length for all components\n\n\nRevisions history\n\nSet the same history span for all components\n\n\nSmoothness measures (Statistics Canada introduced in X-11-ARIMA)\n\n(We don’t use these much)\n\n\n\nSome additional statistics can found in the X-13 output.\n\nout(m_composite)\n\n\n14.3.2 Smoothness\nIn statistical agencies, the choice is often based on characteristics of the adjusted series that many data users find desirable. For comparing direct and indirect adjustm the property most often employed has been smoothness as measured by one or more smoothness measures. We will cover smoothness in more detail in Chapter 15.\n\n14.3.3 Sliding Span\nTo use of a smoothness measure is obviously quite arbitrary. A better way to decide between indirect and direct adjustment may be an examination of the stability of the series, as it can be retrieved from the sliding span spec. We have more to say on sliding spans in Chapter 15 and Chapter 15 and Chapter 16. For now, let’s apply the sliding span specs to our series above and decide based on the returned statistics.\n\n14.3.4 Other considerations\nThe choice between direct and indirect seasonal adjustment may be guided by the expected uses of seasonally adjusted data. For some uses, preserving accounting and aggregation relationships in the data may be crucial, while for other uses, the time-series properties of the derived estimates may be more important.\nThere is no single standard for what’s the best practice. Some countries obtain the seasonally adjusted aggregates as the sum of adjusted components, while others prefer to adjust the totals independently. This can result in discrepancies between the seasonally adjusted total and the sum of the seasonally adjusted component series.\nAccording to Lee (2018), allocating discrepancies on components to achieve consistency should be avoided.\n\nLee, Kwangwon. 2018. “7. Seasonal Adjustment.” In Quarterly National Accounts Manual (2017 Edition). International Monetary Fund.\nIf the differences are insignificant, accounting and aggregation relationships in the seasonally adjusted data should be guaranteed.\nWhen the indirect approach is considered, seasonally adjusted aggregates should be checked to exclude the presence of residual seasonality using the F-test available in X-13.\nX-13 offers various additional diagnostic tools to evaluate the direct and indirect adjustment of aggregates. The program calculates seasonally adjusted aggregates using the direct and indirect approach and provides in output a set of statistics to compare the results (M diagnostics, measures of smoothness, frequency spectrum diagnostics, etc.).\nFurthermore, sliding spans and revision history diagnostics can be requested to assess which of the two approaches provides more stable and reliable seasonally adjusted results."
  },
  {
    "objectID": "50-part-quality-assessment.html",
    "href": "50-part-quality-assessment.html",
    "title": "Quality assessment",
    "section": "",
    "text": "This section focuses on diagnostic tools for seasonal adjustment. This will be written as a stand-alone section as well as a continuance of prior sections. The idea here is that many readers may be interested in checking the quality of their adjustments but not need help performing it.\nSeasonal Adjustment Diagnostics refers to the process of evaluating and assessing the quality of seasonal adjustments made to time series data using the X-13ARIMA-SEATS software. The objectives of these diagnostics are to determine the presence of seasonality in the series, assess the overall quality of the seasonal adjustment, and make decisions regarding adjustments and options. The diagnostics include spectral graphs, stability diagnostics, sliding spans, revisions history, and monitoring and quality diagnostics. The diagnostics involve analyzing the series in the time and frequency domains, examining spectral graphs, and identifying visually significant peaks. Other diagnostic tools include the F test for seasonal regressors and the QS (autocorrelation) test for residual seasonality. Sliding spans diagnostic compares adjustments from overlapping subspans of the series to assess stability. We can use all this information to help make choice about seasonal adjustment options, such as seasonal filter lengths or sigma limits. Let’s look back at our flow chart, with a done box added, to see where seasonal adjustment diagnostics fit in. Notice there are 3 routes the diagnostics could take us; back to seasonal adjustment, to completion, or all the way back to regARIMA modeling.\n\n\n\n\nflowchart TD\n  A[RegARIMA Modeling] --&gt; B(Model Comparison / Diagnostics)\n  B --&gt; A\n  A --&gt; C[Seasonal Adjustment]\n  C --&gt; D{Seasonal Adjustment &lt;br/&gt; Diagnostics}\n  D -.-&gt; C\n  D -.-&gt; A\n  D -.-&gt; E[Done]"
  },
  {
    "objectID": "51-quality-measures.html#summary-statistics",
    "href": "51-quality-measures.html#summary-statistics",
    "title": "15  Quality measures",
    "section": "\n15.1 Summary Statistics",
    "text": "15.1 Summary Statistics\nThe summary of the model gives a glance of a seasonal adjustment process and is a good starting point for the evaluation whether a model is good or bad:\n\nm &lt;- seas(AirPassengers)\nsummary(m)\n#&gt; \n#&gt; Call:\n#&gt; seas(x = AirPassengers)\n#&gt; \n#&gt; Coefficients:\n#&gt;                     Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; Weekday           -0.0029497  0.0005232  -5.638 1.72e-08 ***\n#&gt; Easter[1]          0.0177674  0.0071580   2.482   0.0131 *  \n#&gt; AO1951.May         0.1001558  0.0204387   4.900 9.57e-07 ***\n#&gt; MA-Nonseasonal-01  0.1156204  0.0858588   1.347   0.1781    \n#&gt; MA-Seasonal-12     0.4973600  0.0774677   6.420 1.36e-10 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; SEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 144  Transform: log\n#&gt; AICc: 947.3, BIC: 963.9  QS (no seasonality in final):    0  \n#&gt; Box-Ljung (no autocorr.): 26.65   Shapiro (normality): 0.9908\n\nThe summary gives an overview of the adjustment model and provides diagnostics - we briefly went through its elements in Chapter 2.\nIn the lower part, the summary of the adjustment model shows various quality measures:\n\nThe AICc and BIC information criterion (we use them for model comparison)\n\nAs well as the following statistics:\n\nthe QS Statistic (do we have seasonality in the final series?),\nthe Box-Ljung (do we auto-correlation in the residuals? Is our ARIMA model appropriate?),\nand the Shapiro statistic (are the residuals normally-distributed? Is our ARIMA model appropriate?).\n\nNone of the three statistics shows any significance (indicated by one or several stars), which is a good sign. By now we know that AirPassengers is a series that is easy to adjust and that the automated procedures of X-13 work well on this series, so this should not come as a surprise.\nWe will already discussed the role of information criterion and the statistics in more detail below. Usually, it makes sense to look at the statics if the summary indicates significance on any of them.\nIn addition, looking the estimated seasonal component gives you a good understanding on what actually happened during seasonal adjustment. We will start with visually inspecting the seasonal component of a seasonal adjustment model."
  },
  {
    "objectID": "51-quality-measures.html#residual-seasonality",
    "href": "51-quality-measures.html#residual-seasonality",
    "title": "15  Quality measures",
    "section": "\n15.2 Residual Seasonality",
    "text": "15.2 Residual Seasonality\nThe QS statistic in the summary has not shown any significance, meaning the seasonally adjusted series show no seasonality. This is closely related to the concept of residual seasonality. Residual seasonality plays a crucial role in determining the quality of a seasonal adjustment.\nResidual seasonality refers to the presence of remaining seasonal patterns or fluctuations in the seasonally adjusted series or its residuals. It indicates that the seasonal adjustment may not have fully removed all the seasonal effects from the data. If residual seasonality is present in the adjusted series, it can lead to biased or misleading analysis and forecasts.\nIt implies that there are still systematic patterns or cycles left in the data, which can hinder accurate interpretation and decision-making. There are many ways to test for residual seasonality. Essentially, this mimics what we learned in Chapter 12 but now applied to the final seasonally adjusted series.\nThree prominent ones are:\n\nThe QS-statistic,\nVisual inspection of the spectrum,\nor an F-test for residual seasonality\n\nAdditionally, (Findley, Lytras and Mcelroy 2017) find the most diagnostics must be applied to a subspan of the seasonally adjusted series for best residual seasonality detection. Keep this in mind when doing any analysis of your final seasonal adjustment.\n\n\n\n15.2.1 QS statistic\nWe have already seen the that the QS statistic in model summary is not significant, meaning there is no residual seasonality in the series.\nThe QS statistics check for positive autocorrelation at the seasonal lags. The null hypothesis is that the autocorrelation is zero, indicating no seasonal autocorrelation. Hence, a small p-value indicates residual seasonality.\nLet \\(\\hat{\\gamma}(h)\\) be the estimated autocorrelation function of a differenced time series. The QS statistic for a monthly time series is \\[\nQS = n(n+2)\\left(\\frac{\\hat{\\gamma}(12)^2}{n - 12} + \\frac{\\hat{\\gamma}(24)^2}{n - 24}\\right)\n\\] For a quarterly series replace the 12s and 24s with 4s and 8s. The value QS is approximately chi-squared with 2 degrees of freedom.\nThe seasonal package provides functionality to look at the QS values of various series. We will breakdown what all these tests and p-values are\n\nqs(m)\n#&gt;                     qs  p-val\n#&gt; qsori        167.64858 0.0000\n#&gt; qsorievadj   203.07731 0.0000\n#&gt; qsrsd          0.00000 1.0000\n#&gt; qssadj         0.00000 1.0000\n#&gt; qssadjevadj    0.00000 1.0000\n#&gt; qsirr          0.00000 1.0000\n#&gt; qsirrevadj     0.00000 1.0000\n#&gt; qssori       115.08988 0.0000\n#&gt; qssorievadj  135.11320 0.0000\n#&gt; qssrsd         0.36904 0.8315\n#&gt; qsssadj        0.00000 1.0000\n#&gt; qsssadjevadj   0.00000 1.0000\n#&gt; qssirr         0.00000 1.0000\n#&gt; qssirrevadj    0.00000 1.0000\n\nIn the output table we see 14 rows. The top 7 rows correspond to the QS statistic\n\nOriginal series\nOriginal series, adjusted for extreme values\nModel residuals\nSeasonally adjusted series\nSeasonally adjusted series, adjusted for extreme values\nIrregular series\nIrregular series, adjusted for extreme values\n\nThe next seven rows are simply the exact same statistics calculated on a (possibly) shorter span of the data. The default span used for the second 7 QS statistics is set to be the same as the spectrum uses, 96 observations or 8 years in a monthly series.\nThe value shown in the summary output of the model correspond to the 4th row. If this value does not show any significance, there is usually no significance in the QS statistic of the irregular series.\n\n15.2.2 Frequency Domain (optional): Spectrum\nAnother way to look at residual seasonality is to look at the spectrum.\nWe start with visual inspection of the spectrum of a series. For those unfamiliar with spectral analysis of a time series, the following discussion is intended to be accessible to all trying to perform seasonal adjustment. Hence, we take some liberties with language an interpretation in an effort to make the discussion accessible. For example, we use the term spectrum to refer to the theoretical construct as well as the estimated periodogram.\nWe note here that we will use a parametric AR representation to estimate the spectrum of a process. This is the easiest and most straight forward way to get smooth yet sensible empirical spectral estimates for the everyday user. Peaks in the spectrum indicate significant influence to your series of a sin/cos curve of the corresponding frequency. For example, looking at the spectrum of the AirPassengers series we see large peaks at frequencies 1/12, 2/12, 3/12, …\n\nspec.ar(AirPassengers, order = 13)\n\n\n\n\nWe know that X-11 with automatic modeling and automatic filter identification performs a good seasonal adjustment. If we look at the spectrum of the seasonally adjusted series, the peaks have been removed.\n\nlibrary(seasonal)\nm &lt;- seas(AirPassengers, x11 = \"\")\nspec.ar(final(m))\n\n\n\n\nLet’s intentionally perform a poor seasonal adjustment and see the effect on the spectrum of the seasonally adjusted series.\n\nlibrary(seasonal)\nm &lt;- seas(AirPassengers, transform.function = \"none\", x11 = \"\", x11.seasonalma = 'stable')\nspec.ar(final(m))\n\n\n\n\nHere we see peaks remaining the the final seasonal adjustment. This is a clear indication of lack of quality and something needs to be done to improve the adjustment.\nWhen attempting to eliminate persistent peaks in the spectrum, several strategies can be employed.\nFirst, consider adjusting the model span, particularly when there are indications of changing patterns. Furthermore, it is essential to carefully examine for any missed outliers and thoroughly review instances that are considered “almost” outliers. Additionally, scrutinize the seasonal filters and sigma limits in X-11 or the model in SEATS to ensure they are appropriately set.\nExploring different estimations of the spectrum can also provide insights into potential solutions. Here we used the spec.ar function which utilizes an AIC test to find an appropriate AR(p) model for the series and plots the associated spectrum. This results in a smooth function as apposed to say, spec.pgram which will be much rougher.\nIt is important to acknowledge that sometimes these peaks may be spurious, making it challenging to ascertain their significance. Always try to eliminate peaks at 1/12, 2/12, 3/12, 4/12, or TD 0.348 but be aware that not every situation lends itself to a clear-cut answer.\nWhen employing X-11 seasonal adjustment, it is crucial to consider that peaks observed in the spectrum of the seasonally adjusted series or irregular component, these are more significance than peaks in the spectrum of the model residuals. In the case of indirect adjustments, it is advisable to prioritize the analysis of the seasonally adjusted series."
  },
  {
    "objectID": "51-quality-measures.html#model-appropriateness",
    "href": "51-quality-measures.html#model-appropriateness",
    "title": "15  Quality measures",
    "section": "\n15.3 Model Appropriateness",
    "text": "15.3 Model Appropriateness\nOften a poor seasonal adjustment might be due to a poor fitting regARIMA model. The converse is not always true and does not always need to be rectified if the resulting seasonal adjustment is free of residual seasonality and passes other diagnostic test. Some diagnostics that can be used to test your regARIMA model are:\n\nt-tests on model coefficients (reported in the summary)\nNormality of residuals (reported in the summary as Shapiro)\nSample autocorrelations and partial autocorrelations\nThe Ljung-Box Q statistic\nA spectrum plot of regARIMA residuals"
  },
  {
    "objectID": "51-quality-measures.html#stability-and-smoothness",
    "href": "51-quality-measures.html#stability-and-smoothness",
    "title": "15  Quality measures",
    "section": "\n15.4 Stability and smoothness",
    "text": "15.4 Stability and smoothness\nWe explore two related concepts and their associated specs. First, the stability of a seasonal adjustment which refers to its consistency and reliability over time. It assesses whether the model fits remain consistent as new data becomes available. Stability is important as large revisions are a hindrance in a production cycle of seasonal adjustment. Again, this is a good example of a situation where a user interested in only a single seasonal adjustment (will never adjust this series again) may not care to read this section.\nThe diagnostics provided in other chapters will more adequately aid them to produce a quality seasonal adjustment. However, for those that produce a seasonal adjustment, say monthly, stability is crucial for producing consistent and trustworthy data that can be used for analysis, decision-making, and forecasting. This is discussed in the following subsection.\nSecondly, in the following chapter, we will discuss the history spec and revisions.\n\n15.4.1 Monthplot\nVisually inspecting the seasonal component makes sense almost any adjusmten process. We already looked at the monthplot function in Chapter 4.\n\nmonthplot(m)\n\n\n\n\nThe plot organizes the data by month. Observing the January (J) data, the blue bars represent the evolution of the detrended series from 1949 through 1960. The red bar shows the average seasonal component across these years, while the smooth red line indicates the seasonal component as calculated by the model.\nThe plot reveals a seasonal pattern where passenger numbers increase during summer months and decrease in winter. Over time, the intensity of the seasonal factors evolves, with the summer peak intensifying and the February and March peak diminishing.\nSince the red lines are relatively smooth, the seasonal component is stable and predictable, as indicative for a good seasonal adjustment.\n\n15.4.2 Sliding spans\nThe sliding span spec and diagnostics provide descriptive information about how seasonal adjustments and their month-to-month changes vary when the data span used to calculate them is changed systematically. Quoting the seminal paper (Findley, et al 1990) “A minimal requirement of the output of any smoothing or adjustment procedure is stability: Appending or deleting a small number of series values should not substantially change the smoothed values-otherwise, what reliable interpretation can they have?” When comparing two neighboring spans, the extent of their differences depends on whether one starts and ends a year later than the other. The default length of the data span is determined by the length of the seasonal filter used for the adjustment.\n\n\n\n\ngantt\n    title Example of four 8-year spans starting in January 2000\n    dateFormat  YYYY-MM-DD\n    section Full Data \n    First Span       :a1, 2000-01-01, 2920d\n    Second Span     :a2, 2001-01-01, 2920d\n    Third Span :a3, 2002-01-01, 2920d\n    Fourth Span :a4, 2003-01-01, 2920d\n\n\n\n\n\nFor series where all seasonally adjusted values are positive, two important sliding spans statistics, A(%) and MM(%), are viewed as follows. Let \\(A_t^{(j)}\\) be the seasonally adjusted value at time \\(t\\) calculated from data in span \\(j\\). Then A(%) denotes the percent of month such that: \\[\n\\frac{\\max_j A_t^{(j)} - \\min_j A_t^{(j)}}{\\min_j A_t^{(j)}} &gt; .03\n\\] MM(%) denotes the percent of months the seasonally adjusted month-to-month percent change” is unstable, which is defined as: \\[\n\\max_j \\frac{A_t^{(j)}}{A_{t-1}^{(j)}} -\n\\min_j \\frac{A_t^{(j)}}{A_{t-1}^{(j)}} &gt; 0.03\n\\]\nThe 0.03 on the right hand side comes from the default cutoff. Some of the other defaults are as follows\n\n\n\n\n\n\n\nSeries\nDefault cutoff\nspec option\n\n\n\nSeasonal factors and seasonally adjusted series\n3%\ncutseas = 3.0\n\n\nmonth-to-month and year-to-year change\n3%\ncutchng = 3.0\n\n\ntrading day factors\n2%\ncuttd = 2.0\n\n\n\nThe recommendation provided in the X13 manual indicate A(%) &gt; 15 is problematic and A(%) &gt; 25 should not be used. MM(%) &gt; 35 is problematic and MM(%) &gt; 40 should not be used. Why a different ranges? Sometimes, the causes of high values in A(%) or MM(%) can be identified and determined to be relatively unproblematic. This is particularly true when the months with unstable adjustments or changes are predominantly concentrated in a well-known problematic period that occurred several years ago or in one or two specific calendar months each year. These months are typically acknowledged by all data users as potentially troublesome, such as winter months in datasets known to be highly sensitive to variations in winter weather conditions. The sliding spans output is instrumental in identifying such concentrations, making it effortless to spot these patterns.\n\nm &lt;- seas(AirPassengers,\n          slidingspans.numspans = 4)\n# Seasonal Factors - Percentage of months flagged as unstable\nSF &lt;- udg(m, \"s2.a.per\")\nrow.names(SF) &lt;-\n  c(\"Number of months flagged\", \n    \"Total number of months\", \n    \"Percent\")\ncolnames(SF) &lt;- \"seasonal factors\"\nknitr::kable(SF)\n\n\n\n\nseasonal factors\n\n\n\nNumber of months flagged\n1.000\n\n\nTotal number of months\n96.000\n\n\nPercent\n1.042\n\n\n\n\n# Month-to-Month Changes in SA Series - Percentage of months flagged as unstable\nM2M &lt;- udg(m, \"s2.d.per\")\nrow.names(M2M) &lt;-\n  c(\"Number of months flagged\", \n    \"Total number of months\", \n    \"Percent\")\ncolnames(M2M) &lt;- \"Month-to-Month Changes in SA Series\"\nknitr::kable(M2M)\n\n\n\n\nMonth-to-Month Changes in SA Series\n\n\n\nNumber of months flagged\n0\n\n\nTotal number of months\n95\n\n\nPercent\n0\n\n\n\n\n\nLet’s return to our example where we intentionally make a poor seasonal adjustment. Now we need to take a log transform which will certainly improve the results from the prior run.\n\nm &lt;-\n  seas(\n    AirPassengers,\n    transform.function = \"log\",\n    x11 = \"\",\n    x11.seasonalma = 'stable',\n    slidingspans.numspans = 4\n  )\n# Seasonal Factors - Percentage of months flagged as unstable\nSF &lt;- udg(m, \"s2.a.per\")\nrow.names(SF) &lt;-\n  c(\"Number of months flagged\", \n    \"Total number of months\", \n    \"Percent\")\ncolnames(SF) &lt;- \"seasonal factors\"\nknitr::kable(SF)\n\n\n\n\nseasonal factors\n\n\n\nNumber of months flagged\n20.000\n\n\nTotal number of months\n120.000\n\n\nPercent\n16.667\n\n\n\n\n# Month-to-Month Changes in SA Series - Percentage of months flagged as unstable\nM2M &lt;- udg(m, \"s2.d.per\")\nrow.names(M2M) &lt;-\n  c(\"Number of months flagged\", \n    \"Total number of months\", \n    \"Percent\")\ncolnames(M2M) &lt;- \"Month-to-Month Changes in SA Series\"\nknitr::kable(M2M)\n\n\n\n\nMonth-to-Month Changes in SA Series\n\n\n\nNumber of months flagged\n14.000\n\n\nTotal number of months\n119.000\n\n\nPercent\n11.765\n\n\n\n\n\nWe see the A(%) value of 16.667 falls squarely in the problematic range. If we were to lower the cutoff threshold we could expect to get even more values being flagged yielding a higher percentage.\n\nm &lt;-\n  seas(\n    AirPassengers,\n    transform.function = \"log\",\n    x11 = \"\",\n    x11.seasonalma = 'stable',\n    slidingspans.numspans = 4,\n    slidingspans.cutseas = 2.0\n  )\n# Seasonal Factors - Percentage of months flagged as unstable\nSF &lt;- udg(m, \"s2.a.per\")\nrow.names(SF) &lt;-\n  c(\"Number of months flagged\", \"Total number of months\", \"Percent\")\ncolnames(SF) &lt;- \"seasonal factors\"\nknitr::kable(SF)\n\n\n\n\nseasonal factors\n\n\n\nNumber of months flagged\n30\n\n\nTotal number of months\n120\n\n\nPercent\n25\n\n\n\n\n# Month-to-Month Changes in SA Series - Percentage of months flagged as unstable\nM2M &lt;- udg(m, \"s2.d.per\")\nrow.names(M2M) &lt;-\n  c(\"Number of months flagged\", \"Total number of months\", \"Percent\")\ncolnames(M2M) &lt;- \"Month-to-Month Changes in SA Series\"\nknitr::kable(M2M)\n\n\n\n\nMonth-to-Month Changes in SA Series\n\n\n\nNumber of months flagged\n14.000\n\n\nTotal number of months\n119.000\n\n\nPercent\n11.765\n\n\n\n\n\nWe can also examine the series provided to us\n\nold_sa &lt;- seas(\n  x = old,\n  transform.function = \"log\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  arima.model = \"(1 1 1)(0 1 1)\",\n  x11 = \"\",\n  regression.variables = \"ls2008.4\",\n  slidingspans = \"\"\n)\nauto_sa &lt;- seas(\n  x = old,\n  x11 = \"\",\n  slidingspans = \"\"\n)\nSF &lt;- udg(old_sa, \"s2.a.per\") |&gt; cbind(udg(auto_sa, \"s2.a.per\"))\nrow.names(SF) &lt;- c(\"Number of months flagged\", \"Total number of months\", \"Percent\")\ncolnames(SF) &lt;- c(\"old_sa\", \"auto_sa\")\nknitr::kable(SF, caption = \"Seasonal Factors\")\n\n\nSeasonal Factors\n\n\nold_sa\nauto_sa\n\n\n\nNumber of months flagged\n3.000\n3.000\n\n\nTotal number of months\n39.000\n39.000\n\n\nPercent\n7.692\n7.692\n\n\n\n\n# Month-to-Month Changes in SA Series - Percentage of months flagged as unstable\nM2M &lt;- udg(old_sa, \"s2.d.per\") |&gt; cbind(udg(auto_sa, \"s2.a.per\"))\nrow.names(M2M) &lt;- c(\"Number of months flagged\", \"Total number of months\", \"Percent\")\ncolnames(M2M) &lt;- c(\"old_sa\", \"auto_sa\")\nknitr::kable(M2M, caption = \"Month-to-Month Changes in SA Series\")\n\n\nMonth-to-Month Changes in SA Series\n\n\nold_sa\nauto_sa\n\n\n\nNumber of months flagged\n6.000\n3.000\n\n\nTotal number of months\n38.000\n39.000\n\n\nPercent\n15.789\n7.692\n\n\n\n\n\nSome overall guidance for using modifications to a failing sliding span diagnostic can be summarized as follows:\n\nTry raising X-11 sigma limits\nLook at regARIMA model\nDon’t use sliding spans to choose seasonal filters as they tend to favor longer filters."
  },
  {
    "objectID": "52-revisions.html#history-spec",
    "href": "52-revisions.html#history-spec",
    "title": "16  Revisions",
    "section": "\n16.1 History Spec",
    "text": "16.1 History Spec\nThe program conducts multiple runs, iterating over a sequence of expanding intervals, effectively simulating the passage of time. Our preference lies with the approach that generates smaller revisions, assuming the final adjustments resulting from different options or methods are equally satisfactory without any remaining seasonal or calendar effects. Instead of referring to them as history diagnostics, we use the term “revisions history” to describe these measurements, as they quantify the magnitudes of adjustments made by incorporating series values. It’s important to note that these diagnostics do not include any changes or revisions to the underlying series values themselves.\nWe can look at any of the following estimates produced by the program\n\n\n\n\n\n\nVariable to specify\nvalue\n\n\n\n\nsadj (default)\nseasonally adjusted series\n\n\nsadjchng\nperiod-to-period changes in the seasonally adjusted series\n\n\ntrend\ntrend\n\n\ntrendchng\nperiod-to-period changes in the trend\n\n\nseasonal\nfinal and projected seasonal factors\n\n\naic\nAICCs and maximum log likelihoods for the regARIMA model\n\n\nfcst\nforecasts and evolving mean square forecast errors\n\n\narma\nestimated AR and MA coefficients\n\n\ntd\ntrading day regression coefficients\n\n\n\n\n# We need to use out() to view the history tables. \n# Currently not much support in seasonal for thest tables\n# X13graph produces a nice suite of graphics if intersted in the history spec and\n#.   the associated revisions\nold_sa &lt;- seas(\n  x = old,\n  transform.function = \"log\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  arima.model = \"(1 1 1)(0 1 1)\",\n  x11 = \"\",\n  regression.variables = \"ls2008.4\",\n  history = \"\"\n  # history.estimates = c(\"fcst\")\n)\nauto_sa &lt;- seas(\n  x = old,\n  x11 = \"\",\n  history = \"\"\n  # history.estimates = c(\"fcst\")\n)\n# out(old_sa)\n# out(auto_sa)\n\nNote, as the history run progresses towards its end, the gap between the concurrent series and the final series diminishes, leading to a decrease in the average revision across years. Keep this in mind when looking at history output:\n\nNo specific pass/fail thresholds are recommended\nLook for large differences\nDon’t use for selecting seasonal filters as the diagnostic tends to prefer longer filters"
  },
  {
    "objectID": "52-revisions.html#using-history-spec-to-compare-forecasts",
    "href": "52-revisions.html#using-history-spec-to-compare-forecasts",
    "title": "16  Revisions",
    "section": "\n16.2 Using History Spec to compare forecasts",
    "text": "16.2 Using History Spec to compare forecasts\nThe outline of what happenes when history.estimates = c(\"fcst\") is added to a seasonal adjustment run:\n\nTruncate the series at time point \\(t_0\\).\nApply the regARIMA model and generate forecasts for \\(h\\) steps ahead.\nGenerate forecasts for one step ahead and one year ahead.\nInclude the data point at time point \\((t_0 + 1)\\).\nRepeat the model fitting process and forecasting.\n\nTo make a decision between two model we can apply the following logic to our differences in sum of square forecast error plot.\n\\[\nSSE^{(1, 2)}_{h, N}\n=\n\\sum_{t = t_0}^{N-h}\n\\left[\n(Y_{t+h} - \\widehat{Y}^{(1)}_{t_h|t})^2 -\n(Y_{t+h} - \\widehat{Y}^{(2)}_{t_h|t})^2\n\\right]\n\\]\n\nFor a persistently decreasing value (negative slope) with increasing N, prefer Model 1.\nIf there are persistently better forecasts from Model 1 (consistently summing negative values, indicating smaller errors), prefer Model 1.\nIn the case of a stair-stepping down pattern, prefer Model 1.\nFor a persistently increasing value (positive slope) with increasing N, prefer Model 2.\nIf there is a stair-stepping up pattern, prefer Model 2.\n\nEach line on the plot is a seperate comparison of two models.\n\nIf one line is inconclusive, the other line can indicate model preference\nWeight seasonal forecasts more\nWeight most-recent result more\n\n\nold_sa &lt;- seas(\n  x = old,\n  transform.function = \"log\",\n  regression.aictest = NULL,\n  outlier = NULL,\n  arima.model = \"(1 1 1)(0 1 1)\",\n  x11 = \"\",\n  regression.variables = \"ls2008.4\",\n  history.estimates = c(\"fcst\")\n)\nauto_sa &lt;- seas(\n  x = old,\n  x11 = \"\",\n  history.estimates = c(\"fcst\")\n)\nh1 &lt;- series(old_sa, \"fce\")\nh2 &lt;- series(auto_sa, \"fce\")\ndiff1 &lt;- h1[,1] - h2[,1]\ndiff12 &lt;- h1[,2] - h2[,2]\nsdiff1 &lt;- (diff1 * length(diff1)) / h2[length(h2[,1]),1]\nsdiff12 &lt;- (diff12 * length(diff12)) / h2[length(h2[,2]),2]\nts_plot(ts_c(sdiff1, sdiff12), title = \"Squared Forecast Error Differences, Fixed - Auto\")\nabline(h=0, col = \"grey\")\n\n\n\n\n\nm1 = seas(AirPassengers, x11 = \"\", history.estimates = c(\"fcst\"))\nm2 = seas(AirPassengers, x11 = \"\",  arima.model = \"(0 0 1)(0 0 0)\", history.estimates = c(\"fcst\"))\nh1 &lt;- series(m1, \"fce\")\nh2 &lt;- series(m2, \"fce\")\ndiff1 &lt;- h1[,1] - h2[,1]\ndiff12 &lt;- h1[,2] - h2[,2]\nsdiff1 &lt;- (diff1 * length(diff1)) / h2[length(h2[,1]),1]\nsdiff12 &lt;- (diff12 * length(diff12)) / h2[length(h2[,2]),2]\nts_plot(ts_c(sdiff1, sdiff12), title = \"Squared Forecast Error Differences, good - bad\")\nabline(h=0, col = \"grey\")\n\n\n\n\nThere are no specific pass/fail levels recommended for these results, indicating that there are no predetermined thresholds to determine success or failure. Instead, a comparison approach is suggested, particularly when significant differences emerge among the results. For example, it is expected that the disparity between the concurrent series and the final series diminishes gradually. Therefore, it is reasonable to anticipate a decrease in the average revision across years as the process nears completion. In such cases, it becomes crucial to thoroughly analyze and understand the reasons behind these disparities. Additionally, it is advised to exercise caution when utilizing these results as the sole basis for selecting a seasonal filter. Other factors and considerations should be taken into account to make an informed decision. It is worth noting that the diagnostic tends to favor longer filters, implying that the analysis tends to lean towards recommending seasonal filters with larger spans. However, it is important to weigh this tendency against other relevant factors and requirements specific to the context at hand to make the most appropriate choice."
  },
  {
    "objectID": "52-revisions.html#what-to-do-with-revisions",
    "href": "52-revisions.html#what-to-do-with-revisions",
    "title": "16  Revisions",
    "section": "\n16.3 What to do with Revisions",
    "text": "16.3 What to do with Revisions\nRevisions occur due to various factors including changes in the original series, late respondents, historical corrections, method or classification/definition changes in the original series, adding new observations, and the introduction of new values. These revisions can result in adjustments to model parameters, forecasts, potentially leading to changes in extreme values, as well as adjustments in seasonal and trend filter values.\nIf you data itself changes then a suggestion is to revise one or two previous values beyond where the original series has changed. You can also revise the same month/quarter a year ago.\nIf your data has remained constant and the only source of revision is seasonal adjustment, it is advised to set a policy for within year release and any annual review of your procedure and stick with it. For example, only revise the past 2 observations when a new value becomes available. During annual review revise the last full year."
  }
]